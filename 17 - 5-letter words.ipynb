{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad73c97",
   "metadata": {},
   "source": [
    "# One-Letter Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8afbb61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the csv files\n",
    "GTCAP = open('GTCAP.csv')\n",
    "AGI = open('AGI.csv')\n",
    "SM = open('SM.csv')\n",
    "MER = open('MER.csv')\n",
    "ALI = open('ALI.csv')\n",
    "SECB = open('SECB.csv')\n",
    "MBT = open('MBT.csv')\n",
    "TEL = open('TEL.csv')\n",
    "URC = open('URC.csv')\n",
    "PGOLD = open('PGOLD.csv')\n",
    "\n",
    "#initialize the lists\n",
    "Date_GTCAP = []\n",
    "ClosePrice_GTCAP = []\n",
    "Date_AGI = []\n",
    "ClosePrice_AGI = []\n",
    "Date_SM = []\n",
    "ClosePrice_SM = []\n",
    "Date_MER = []\n",
    "ClosePrice_MER = []\n",
    "Date_ALI = []\n",
    "ClosePrice_ALI = []\n",
    "Date_SECB = []\n",
    "ClosePrice_SECB = []\n",
    "Date_MBT = []\n",
    "ClosePrice_MBT = []\n",
    "Date_TEL = []\n",
    "ClosePrice_TEL = []\n",
    "Date_URC = []\n",
    "ClosePrice_URC = []\n",
    "Date_PGOLD = []\n",
    "ClosePrice_PGOLD = []\n",
    "\n",
    "#skip the header line\n",
    "GTCAP.readline()\n",
    "AGI.readline()\n",
    "SM.readline()\n",
    "MER.readline()\n",
    "ALI.readline()\n",
    "SECB.readline()\n",
    "MBT.readline()\n",
    "TEL.readline()\n",
    "URC.readline()\n",
    "PGOLD.readline()\n",
    "\n",
    "#go through the files line by line\n",
    "for line in GTCAP:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_GTCAP.append(sline[0])\n",
    "    ClosePrice_GTCAP.append(float(sline[1]))\n",
    "    \n",
    "for line in AGI:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_AGI.append(sline[0])\n",
    "    ClosePrice_AGI.append(float(sline[1]))\n",
    "    \n",
    "for line in SM:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_SM.append(sline[0])\n",
    "    ClosePrice_SM.append(float(sline[1]))\n",
    "    \n",
    "for line in MER:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_MER.append(sline[0])\n",
    "    ClosePrice_MER.append(float(sline[1]))\n",
    "    \n",
    "for line in ALI:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_ALI.append(sline[0])\n",
    "    ClosePrice_ALI.append(float(sline[1]))\n",
    "    \n",
    "for line in SECB:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_SECB.append(sline[0])\n",
    "    ClosePrice_SECB.append(float(sline[1]))\n",
    "    \n",
    "for line in MBT:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_MBT.append(sline[0])\n",
    "    ClosePrice_MBT.append(float(sline[1]))\n",
    "    \n",
    "for line in TEL:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_TEL.append(sline[0])\n",
    "    ClosePrice_TEL.append(float(sline[1]))\n",
    "    \n",
    "for line in URC:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_URC.append(sline[0])\n",
    "    ClosePrice_URC.append(float(sline[1]))\n",
    "        \n",
    "for line in PGOLD:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_PGOLD.append(sline[0])\n",
    "    ClosePrice_PGOLD.append(float(sline[1]))\n",
    "\n",
    "\n",
    "#close files\n",
    "GTCAP.close()\n",
    "AGI.close()\n",
    "SM.close()\n",
    "MER.close()\n",
    "ALI.close()\n",
    "SECB.close()\n",
    "MBT.close()\n",
    "TEL.close()\n",
    "URC.close()\n",
    "PGOLD.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "840f7b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd0cf71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates into datetime structure\n",
    "for n in range(len(Date_GTCAP)):\n",
    "    Date_GTCAP[n] = datetime.datetime.strptime(Date_GTCAP[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_AGI)):\n",
    "    Date_AGI[n] = datetime.datetime.strptime(Date_AGI[n], '%m/%d/%y').date()\n",
    "    \n",
    "for n in range(len(Date_SM)):\n",
    "    Date_SM[n] = datetime.datetime.strptime(Date_SM[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_MER)):\n",
    "    Date_MER[n] = datetime.datetime.strptime(Date_MER[n], '%m/%d/%y').date()\n",
    "    \n",
    "for n in range(len(Date_ALI)):\n",
    "    Date_ALI[n] = datetime.datetime.strptime(Date_ALI[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_SECB)):\n",
    "    Date_SECB[n] = datetime.datetime.strptime(Date_SECB[n], '%m/%d/%y').date()\n",
    "    \n",
    "for n in range(len(Date_MBT)):\n",
    "    Date_MBT[n] = datetime.datetime.strptime(Date_MBT[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_TEL)):\n",
    "    Date_TEL[n] = datetime.datetime.strptime(Date_TEL[n], '%m/%d/%y').date()\n",
    "    \n",
    "for n in range(len(Date_URC)):\n",
    "    Date_URC[n] = datetime.datetime.strptime(Date_URC[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_PGOLD)):\n",
    "    Date_PGOLD[n] = datetime.datetime.strptime(Date_PGOLD[n], '%m/%d/%y').date()\n",
    "    \n",
    "# save Date and ClosePrice\n",
    "np.save('GTCAPDate.npy', Date_GTCAP)\n",
    "np.save('GTCAPClosePrice.npy', ClosePrice_GTCAP)\n",
    "np.save('AGIDate.npy', Date_AGI)\n",
    "np.save('AGIClosePrice.npy', ClosePrice_AGI)\n",
    "np.save('SMDate.npy', Date_SM)\n",
    "np.save('SMClosePrice.npy', ClosePrice_SM)\n",
    "np.save('MERDate.npy', Date_MER)\n",
    "np.save('MERClosePrice.npy', ClosePrice_MER)\n",
    "np.save('ALIDate.npy', Date_ALI)\n",
    "np.save('ALIClosePrice.npy', ClosePrice_ALI)\n",
    "np.save('SECBDate.npy', Date_SECB)\n",
    "np.save('SECBClosePrice.npy', ClosePrice_SECB)\n",
    "np.save('MBTDate.npy', Date_MBT)\n",
    "np.save('MBTClosePrice.npy', ClosePrice_MBT)\n",
    "np.save('TELDate.npy', Date_TEL)\n",
    "np.save('TELClosePrice.npy', ClosePrice_TEL)\n",
    "np.save('URCDate.npy', Date_URC)\n",
    "np.save('URCClosePrice.npy', ClosePrice_URC)\n",
    "np.save('PGOLDDate.npy', Date_PGOLD)\n",
    "np.save('PGOLDClosePrice.npy', ClosePrice_PGOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d00fcad",
   "metadata": {},
   "source": [
    "# Five-letter Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d0b3ef",
   "metadata": {},
   "source": [
    "# 241 (Q) MER - (E) ALI - (V) TEL - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64835619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_241 = max(min(Date_MER), min(Date_ALI), min(Date_TEL), min(Date_URC), min(Date_PGOLD))\n",
    "end_241 = min(max(Date_MER), max(Date_ALI), max(Date_TEL), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "MER_241_1 = Date_MER.index(start_241)\n",
    "MER_241_2 = Date_MER.index(end_241)\n",
    "\n",
    "ALI_241_1 = Date_ALI.index(start_241)\n",
    "ALI_241_2 = Date_ALI.index(end_241)\n",
    "\n",
    "TEL_241_1 = Date_TEL.index(start_241)\n",
    "TEL_241_2 = Date_TEL.index(end_241)\n",
    "\n",
    "URC_241_1 = Date_URC.index(start_241)\n",
    "URC_241_2 = Date_URC.index(end_241)\n",
    "\n",
    "PGOLD_241_1 = Date_PGOLD.index(start_241)\n",
    "PGOLD_241_2 = Date_PGOLD.index(end_241)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "Q241 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_241_1:MER_241_2])\n",
    "E241 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_241_1:ALI_241_2])\n",
    "V241 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_241_1:TEL_241_2])\n",
    "ε241 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_241_1:URC_241_2])\n",
    "W241 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_241_1:PGOLD_241_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "Q241 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "E241 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "V241 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε241 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W241 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1002098",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_241 = []\n",
    "st_241 = []\n",
    "n = 1\n",
    "while n < len(Q241):\n",
    "    sc_241 = ''\n",
    "    if Q241[n] > Q241[n-1]:\n",
    "        sc_241 = sc_241 + 'Q'\n",
    "    if E241[n] > E241[n-1]:\n",
    "        sc_241 = sc_241 + 'E'\n",
    "    if V241[n] > V241[n-1]:\n",
    "        sc_241 = sc_241 + 'V'\n",
    "    if ε241[n] > ε241[n-1]:\n",
    "        sc_241 = sc_241 + 'ε'\n",
    "    if W241[n] > W241[n-1]:\n",
    "        sc_241 = sc_241 + 'W'\n",
    "    if len(sc_241) > 0:\n",
    "        st_241.append(sc_241)\n",
    "    else:\n",
    "        STC_241.append(st_241)\n",
    "        st_241 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_241 = STC_241.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_241 = [ st_241 for st_241 in STC_241 if len(st_241) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_241 = len(Q241)\n",
    "lmax_241 = 0\n",
    "for st_241 in STC_241:\n",
    "    if len(st_241) < lmin_241:\n",
    "        lmin_241 = len(st_241)\n",
    "    if len(st_241) > lmax_241:\n",
    "        lmax_241 = len(st_241)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_241 = [ st_241 for st_241 in STC_241 if len(st_241) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_241 = []\n",
    "for n in range(len(STC5_241)):\n",
    "    tc_241 = [ u for u in STC5_241[n][0] ]\n",
    "    for k in range(1, len(STC5_241[n])):\n",
    "        tc_241 = [ u+v for u in tc_241 for v in STC5_241[n][k] ]\n",
    "    TC5_241 = TC5_241 + tc_241\n",
    "setTC5_241 = list(set(TC5_241))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_241 = [ TC5_241.count(setTC5_241[l]) for l in range(len(setTC5_241)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_241 = [ [] for l in range(len(setTC5_241)) ]\n",
    "for s in range(241):\n",
    "    STC5null_241 = [ list(st_241) for st_241 in STC5_241]\n",
    "    for st_241 in STC5null_241:\n",
    "        np.random.shuffle(st_241)\n",
    "    TC5null_241= []\n",
    "    for n in range(len(STC5null_241)):\n",
    "        tc_241 = [ u for u in STC5null_241[n][0] ]\n",
    "        for k in range(1, len(STC5null_241[n])):\n",
    "            tc_241 = [ u+v for u in tc_241 for v in STC5null_241[n][k] ]\n",
    "        TC5null_241= TC5null_241+ tc_241\n",
    "    for l in range(len(setTC5_241)):\n",
    "        if TC5null_241.count(setTC5_241[l]) > 0:\n",
    "            fTC5null_241[l].append(TC5null_241.count(setTC5_241[l]))\n",
    "        else:\n",
    "            fTC5null_241[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de89be09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "QEEεE\n",
      "QεEεE\n",
      "QVQW\n",
      "QQεεE\n",
      "QEεεW\n",
      "EVVW\n",
      "εEEW\n",
      "εVεεE\n",
      "WQεWW\n",
      "QεεWE\n",
      "QεεVE\n",
      "QVVW\n",
      "WεεVW\n",
      "QεEεW\n",
      "WVEεW\n",
      "WVεEW\n",
      "εWVε\n",
      "QEEεW\n",
      "WEεEW\n",
      "QWεEE\n",
      "QVEW\n",
      "WEεW\n",
      "QVQε\n",
      "QEEEE\n",
      "QWεεE\n",
      "QEWVQ\n",
      "QεEWE\n",
      "QEεVV\n",
      "QεεQW\n",
      "εVVW\n",
      "εVVE\n",
      "WεεεW\n",
      "WεEεW\n",
      "QWεεW\n",
      "εEεEE\n",
      "QEεVε\n",
      "QEεEE\n",
      "QVεεW\n",
      "εWVW\n",
      "WεEVW\n",
      "εEVW\n",
      "εEεW\n",
      "QεVQE\n",
      "WεεWW\n",
      "QWQW\n",
      "QEεεE\n",
      "QεQεQ\n",
      "WVεεW\n",
      "WεEEW\n",
      "QVVεE\n",
      "QEεWE\n",
      "QVVεW\n",
      "QεVεW\n",
      "QVεQW\n",
      "QWεWE\n",
      "WVεWW\n",
      "QεεεE\n",
      "WVVεW\n",
      "WVVEW\n",
      "WVVQW\n",
      "QVεεE\n",
      "QεεεW\n",
      "QVεWE\n",
      "WεEWW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_241)):\n",
    "    if sum(freq >= fTC5_241[l] for freq in fTC5null_241[l]) < 5:\n",
    "        print(setTC5_241[l], fTC5_241[l], sum(freq >= fTC5_241[l] for freq in fTC5null_241[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1129fb25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "QEεεW\n",
      "QεεWE\n",
      "QεEεW\n",
      "QWεεE\n",
      "εVVW\n",
      "QEεEE\n",
      "εWVW\n",
      "WεEVW\n",
      "QEεεE\n",
      "WVεεW\n",
      "QEεWE\n",
      "QWεWE\n",
      "QεεεE\n",
      "QVεεE\n",
      "QεεεW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_241)):\n",
    "    if sum(freq >= fTC5_241[l] for freq in fTC5null_241[l]) < 1:\n",
    "        print(setTC5_241[l], fTC5_241[l], sum(freq >= fTC5_241[l] for freq in fTC5null_241[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5a65f9",
   "metadata": {},
   "source": [
    "# 242 (Q) MER - (Z) SECB - (T) MBT - (V) TEL - (ε) URC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b98badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_242 = max(min(Date_MER), min(Date_SECB), min(Date_MBT), min(Date_TEL), min(Date_URC))\n",
    "end_242 = min(max(Date_MER), max(Date_SECB), max(Date_MBT), max(Date_TEL), max(Date_URC))\n",
    "\n",
    "#shorten the closing prices\n",
    "MER_242_1 = Date_MER.index(start_242)\n",
    "MER_242_2 = Date_MER.index(end_242)\n",
    "\n",
    "SECB_242_1 = Date_SECB.index(start_242)\n",
    "SECB_242_2 = Date_SECB.index(end_242)\n",
    "\n",
    "MBT_242_1 = Date_MBT.index(start_242)\n",
    "MBT_242_2 = Date_MBT.index(end_242)\n",
    "\n",
    "TEL_242_1 = Date_TEL.index(start_242)\n",
    "TEL_242_2 = Date_TEL.index(end_242)\n",
    "\n",
    "URC_242_1 = Date_URC.index(start_242)\n",
    "URC_242_2 = Date_URC.index(end_242)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "Q242 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_242_1:MER_242_2])\n",
    "Z242 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_242_1:SECB_242_2])\n",
    "T242 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_242_1:MBT_242_2])\n",
    "V242 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_242_1:TEL_242_2])\n",
    "ε242 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_242_1:URC_242_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "Q242 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z242 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T242 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V242 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε242 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "132260f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_242 = []\n",
    "st_242 = []\n",
    "n = 1\n",
    "while n < len(Q242):\n",
    "    sc_242 = ''\n",
    "    if Q242[n] > Q242[n-1]:\n",
    "        sc_242 = sc_242 + 'Q'\n",
    "    if Z242[n] > Z242[n-1]:\n",
    "        sc_242 = sc_242 + 'Z'\n",
    "    if T242[n] > T242[n-1]:\n",
    "        sc_242 = sc_242 + 'T'\n",
    "    if V242[n] > V242[n-1]:\n",
    "        sc_242 = sc_242 + 'V'\n",
    "    if ε242[n] > ε242[n-1]:\n",
    "        sc_242 = sc_242 + 'ε'\n",
    "    if len(sc_242) > 0:\n",
    "        st_242.append(sc_242)\n",
    "    else:\n",
    "        STC_242.append(st_242)\n",
    "        st_242 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_242 = STC_242.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_242 = [ st_242 for st_242 in STC_242 if len(st_242) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_242 = len(Q242)\n",
    "lmax_242 = 0\n",
    "for st_242 in STC_242:\n",
    "    if len(st_242) < lmin_242:\n",
    "        lmin_242 = len(st_242)\n",
    "    if len(st_242) > lmax_242:\n",
    "        lmax_242 = len(st_242)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_242 = [ st_242 for st_242 in STC_242 if len(st_242) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_242 = []\n",
    "for n in range(len(STC5_242)):\n",
    "    tc_242 = [ u for u in STC5_242[n][0] ]\n",
    "    for k in range(1, len(STC5_242[n])):\n",
    "        tc_242 = [ u+v for u in tc_242 for v in STC5_242[n][k] ]\n",
    "    TC5_242 = TC5_242 + tc_242\n",
    "setTC5_242 = list(set(TC5_242))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_242 = [ TC5_242.count(setTC5_242[l]) for l in range(len(setTC5_242)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_242 = [ [] for l in range(len(setTC5_242)) ]\n",
    "for s in range(242):\n",
    "    STC5null_242 = [ list(st_242) for st_242 in STC5_242]\n",
    "    for st_242 in STC5null_242:\n",
    "        np.random.shuffle(st_242)\n",
    "    TC5null_242= []\n",
    "    for n in range(len(STC5null_242)):\n",
    "        tc_242 = [ u for u in STC5null_242[n][0] ]\n",
    "        for k in range(1, len(STC5null_242[n])):\n",
    "            tc_242 = [ u+v for u in tc_242 for v in STC5null_242[n][k] ]\n",
    "        TC5null_242= TC5null_242+ tc_242\n",
    "    for l in range(len(setTC5_242)):\n",
    "        if TC5null_242.count(setTC5_242[l]) > 0:\n",
    "            fTC5null_242[l].append(TC5null_242.count(setTC5_242[l]))\n",
    "        else:\n",
    "            fTC5null_242[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "523b7e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "VQZT\n",
      "ZεVVZ\n",
      "TZεεε\n",
      "TεεTε\n",
      "TQVTQ\n",
      "εVV\n",
      "Vεεεε\n",
      "QεVVV\n",
      "ZTεV\n",
      "TZZTε\n",
      "ZεVTZ\n",
      "εVQ\n",
      "εVZ\n",
      "ZQεQ\n",
      "Tεεεε\n",
      "VZεεε\n",
      "ZQZT\n",
      "TZεTQ\n",
      "ZεVVT\n",
      "VQVZQ\n",
      "TZεTε\n",
      "ZQTQ\n",
      "ZεεQ\n",
      "TQQTQ\n",
      "Zεεε\n",
      "VQVZV\n",
      "QVVZT\n",
      "VVZTε\n",
      "VZVZε\n",
      "QQVVV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_242)):\n",
    "    if sum(freq >= fTC5_242[l] for freq in fTC5null_242[l]) < 5:\n",
    "        print(setTC5_242[l], fTC5_242[l], sum(freq >= fTC5_242[l] for freq in fTC5null_242[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3c05a2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "VQZT\n",
      "TZZTε\n",
      "εVQ\n",
      "εVZ\n",
      "ZQεQ\n",
      "VVZTε\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_242)):\n",
    "    if sum(freq >= fTC5_242[l] for freq in fTC5null_242[l]) < 1:\n",
    "        print(setTC5_242[l], fTC5_242[l], sum(freq >= fTC5_242[l] for freq in fTC5null_242[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e20086",
   "metadata": {},
   "source": [
    "# 243 (Q) MER - (Z) SECB - (T) MBT - (V) TEL - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02b5a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_243 = max(min(Date_MER), min(Date_SECB), min(Date_MBT), min(Date_TEL), min(Date_PGOLD))\n",
    "end_243 = min(max(Date_MER), max(Date_SECB), max(Date_MBT), max(Date_TEL), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "MER_243_1 = Date_MER.index(start_243)\n",
    "MER_243_2 = Date_MER.index(end_243)\n",
    "\n",
    "SECB_243_1 = Date_SECB.index(start_243)\n",
    "SECB_243_2 = Date_SECB.index(end_243)\n",
    "\n",
    "MBT_243_1 = Date_MBT.index(start_243)\n",
    "MBT_243_2 = Date_MBT.index(end_243)\n",
    "\n",
    "TEL_243_1 = Date_TEL.index(start_243)\n",
    "TEL_243_2 = Date_TEL.index(end_243)\n",
    "\n",
    "PGOLD_243_1 = Date_PGOLD.index(start_243)\n",
    "PGOLD_243_2 = Date_PGOLD.index(end_243)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "Q243 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_243_1:MER_243_2])\n",
    "Z243 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_243_1:SECB_243_2])\n",
    "T243 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_243_1:MBT_243_2])\n",
    "V243 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_243_1:TEL_243_2])\n",
    "W243 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_243_1:PGOLD_243_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "Q243 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z243 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T243 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V243 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "W243 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b91f397",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_243 = []\n",
    "st_243 = []\n",
    "n = 1\n",
    "while n < len(Q243):\n",
    "    sc_243 = ''\n",
    "    if Q243[n] > Q243[n-1]:\n",
    "        sc_243 = sc_243 + 'Q'\n",
    "    if Z243[n] > Z243[n-1]:\n",
    "        sc_243 = sc_243 + 'Z'\n",
    "    if T243[n] > T243[n-1]:\n",
    "        sc_243 = sc_243 + 'T'\n",
    "    if V243[n] > V243[n-1]:\n",
    "        sc_243 = sc_243 + 'V'\n",
    "    if W243[n] > W243[n-1]:\n",
    "        sc_243 = sc_243 + 'W'\n",
    "        st_243.append(sc_243)\n",
    "    else:\n",
    "        STC_243.append(st_243)\n",
    "        st_243 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_243 = STC_243.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_243 = [ st_243 for st_243 in STC_243 if len(st_243) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_243 = len(Q243)\n",
    "lmax_243 = 0\n",
    "for st_243 in STC_243:\n",
    "    if len(st_243) < lmin_243:\n",
    "        lmin_243 = len(st_243)\n",
    "    if len(st_243) > lmax_243:\n",
    "        lmax_243 = len(st_243)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_243 = [ st_243 for st_243 in STC_243 if len(st_243) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_243 = []\n",
    "for n in range(len(STC5_243)):\n",
    "    tc_243 = [ u for u in STC5_243[n][0] ]\n",
    "    for k in range(1, len(STC5_243[n])):\n",
    "        tc_243 = [ u+v for u in tc_243 for v in STC5_243[n][k] ]\n",
    "    TC5_243 = TC5_243 + tc_243\n",
    "setTC5_243 = list(set(TC5_243))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_243 = [ TC5_243.count(setTC5_243[l]) for l in range(len(setTC5_243)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_243 = [ [] for l in range(len(setTC5_243)) ]\n",
    "for s in range(243):\n",
    "    STC5null_243 = [ list(st_243) for st_243 in STC5_243]\n",
    "    for st_243 in STC5null_243:\n",
    "        np.random.shuffle(st_243)\n",
    "    TC5null_243= []\n",
    "    for n in range(len(STC5null_243)):\n",
    "        tc_243 = [ u for u in STC5null_243[n][0] ]\n",
    "        for k in range(1, len(STC5null_243[n])):\n",
    "            tc_243 = [ u+v for u in tc_243 for v in STC5null_243[n][k] ]\n",
    "        TC5null_243= TC5null_243+ tc_243\n",
    "    for l in range(len(setTC5_243)):\n",
    "        if TC5null_243.count(setTC5_243[l]) > 0:\n",
    "            fTC5null_243[l].append(TC5null_243.count(setTC5_243[l]))\n",
    "        else:\n",
    "            fTC5null_243[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60578b26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "TWWQT\n",
      "TVVT\n",
      "WVVT\n",
      "WTVT\n",
      "QZVW\n",
      "WWVT\n",
      "WZVT\n",
      "ZZWQW\n",
      "ZVWQW\n",
      "TVWQT\n",
      "WZVV\n",
      "TWQQT\n",
      "WQTZ\n",
      "WQTT\n",
      "TZTQT\n",
      "WWVV\n",
      "WQTQ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_243)):\n",
    "    if sum(freq >= fTC5_243[l] for freq in fTC5null_243[l]) < 5:\n",
    "        print(setTC5_243[l], fTC5_243[l], sum(freq >= fTC5_243[l] for freq in fTC5null_243[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "944a6276",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "WTVT\n",
      "WZVT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_243)):\n",
    "    if sum(freq >= fTC5_243[l] for freq in fTC5null_243[l]) < 1:\n",
    "        print(setTC5_243[l], fTC5_243[l], sum(freq >= fTC5_243[l] for freq in fTC5null_243[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c08b8",
   "metadata": {},
   "source": [
    "# 244 (Q) MER - (Z) SECB - (T) MBT - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bebce468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_244 = max(min(Date_MER), min(Date_SECB), min(Date_MBT), min(Date_URC), min(Date_PGOLD))\n",
    "end_244 = min(max(Date_MER), max(Date_SECB), max(Date_MBT), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "MER_244_1 = Date_MER.index(start_244)\n",
    "MER_244_2 = Date_MER.index(end_244)\n",
    "\n",
    "SECB_244_1 = Date_SECB.index(start_244)\n",
    "SECB_244_2 = Date_SECB.index(end_244)\n",
    "\n",
    "MBT_244_1 = Date_MBT.index(start_244)\n",
    "MBT_244_2 = Date_MBT.index(end_244)\n",
    "\n",
    "URC_244_1 = Date_URC.index(start_244)\n",
    "URC_244_2 = Date_URC.index(end_244)\n",
    "\n",
    "PGOLD_244_1 = Date_PGOLD.index(start_244)\n",
    "PGOLD_244_2 = Date_PGOLD.index(end_244)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "Q244 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_244_1:MER_244_2])\n",
    "Z244 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_244_1:SECB_244_2])\n",
    "T244 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_244_1:MBT_244_2])\n",
    "ε244 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_244_1:URC_244_2])\n",
    "W244 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_244_1:PGOLD_244_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "Q244 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z244 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T244 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε244 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W244 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f60d5174",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_244 = []\n",
    "st_244 = []\n",
    "n = 1\n",
    "while n < len(Q244):\n",
    "    sc_244 = ''\n",
    "    if Q244[n] > Q244[n-1]:\n",
    "        sc_244 = sc_244 + 'Q'\n",
    "    if Z244[n] > Z244[n-1]:\n",
    "        sc_244 = sc_244 + 'Z'\n",
    "    if T244[n] > T244[n-1]:\n",
    "        sc_244 = sc_244 + 'T'\n",
    "    if ε244[n] > ε244[n-1]:\n",
    "        sc_244 = sc_244 + 'ε'\n",
    "    if W244[n] > W244[n-1]:\n",
    "        sc_244 = sc_244 + 'W'\n",
    "        st_244.append(sc_244)\n",
    "    else:\n",
    "        STC_244.append(st_244)\n",
    "        st_244 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_244 = STC_244.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_244 = [ st_244 for st_244 in STC_244 if len(st_244) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_244 = len(Q244)\n",
    "lmax_244 = 0\n",
    "for st_244 in STC_244:\n",
    "    if len(st_244) < lmin_244:\n",
    "        lmin_244 = len(st_244)\n",
    "    if len(st_244) > lmax_244:\n",
    "        lmax_244 = len(st_244)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_244 = [ st_244 for st_244 in STC_244 if len(st_244) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_244 = []\n",
    "for n in range(len(STC5_244)):\n",
    "    tc_244 = [ u for u in STC5_244[n][0] ]\n",
    "    for k in range(1, len(STC5_244[n])):\n",
    "        tc_244 = [ u+v for u in tc_244 for v in STC5_244[n][k] ]\n",
    "    TC5_244 = TC5_244 + tc_244\n",
    "setTC5_244 = list(set(TC5_244))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_244 = [ TC5_244.count(setTC5_244[l]) for l in range(len(setTC5_244)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_244 = [ [] for l in range(len(setTC5_244)) ]\n",
    "for s in range(244):\n",
    "    STC5null_244 = [ list(st_244) for st_244 in STC5_244]\n",
    "    for st_244 in STC5null_244:\n",
    "        np.random.shuffle(st_244)\n",
    "    TC5null_244= []\n",
    "    for n in range(len(STC5null_244)):\n",
    "        tc_244 = [ u for u in STC5null_244[n][0] ]\n",
    "        for k in range(1, len(STC5null_244[n])):\n",
    "            tc_244 = [ u+v for u in tc_244 for v in STC5null_244[n][k] ]\n",
    "        TC5null_244= TC5null_244+ tc_244\n",
    "    for l in range(len(setTC5_244)):\n",
    "        if TC5null_244.count(setTC5_244[l]) > 0:\n",
    "            fTC5null_244[l].append(TC5null_244.count(setTC5_244[l]))\n",
    "        else:\n",
    "            fTC5null_244[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b8e0a26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "WεTQ\n",
      "TWWQT\n",
      "ZεWQW\n",
      "ZεεQW\n",
      "ZZWQW\n",
      "TWQQT\n",
      "WQTZ\n",
      "WQTT\n",
      "TZTQT\n",
      "WQTQ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_244)):\n",
    "    if sum(freq >= fTC5_244[l] for freq in fTC5null_244[l]) < 5:\n",
    "        print(setTC5_244[l], fTC5_244[l], sum(freq >= fTC5_244[l] for freq in fTC5null_244[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be54d0c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "ZεWQW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_244)):\n",
    "    if sum(freq >= fTC5_244[l] for freq in fTC5null_244[l]) < 1:\n",
    "        print(setTC5_244[l], fTC5_244[l], sum(freq >= fTC5_244[l] for freq in fTC5null_244[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d004627c",
   "metadata": {},
   "source": [
    "# 245 (Q) MER - (Z) SECB - (V) TEL - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c39a148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_245 = max(min(Date_MER), min(Date_SECB), min(Date_TEL), min(Date_URC), min(Date_PGOLD))\n",
    "end_245 = min(max(Date_MER), max(Date_SECB), max(Date_TEL), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "MER_245_1 = Date_MER.index(start_245)\n",
    "MER_245_2 = Date_MER.index(end_245)\n",
    "\n",
    "SECB_245_1 = Date_SECB.index(start_245)\n",
    "SECB_245_2 = Date_SECB.index(end_245)\n",
    "\n",
    "TEL_245_1 = Date_TEL.index(start_245)\n",
    "TEL_245_2 = Date_TEL.index(end_245)\n",
    "\n",
    "URC_245_1 = Date_URC.index(start_245)\n",
    "URC_245_2 = Date_URC.index(end_245)\n",
    "\n",
    "PGOLD_245_1 = Date_PGOLD.index(start_245)\n",
    "PGOLD_245_2 = Date_PGOLD.index(end_245)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "Q245 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_245_1:MER_245_2])\n",
    "Z245 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_245_1:SECB_245_2])\n",
    "V245 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_245_1:TEL_245_2])\n",
    "ε245 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_245_1:URC_245_2])\n",
    "W245 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_245_1:PGOLD_245_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "Q245 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z245 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "V245 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε245 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W245 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87a924d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_245 = []\n",
    "st_245 = []\n",
    "n = 1\n",
    "while n < len(Q245):\n",
    "    sc_245 = ''\n",
    "    if Q245[n] > Q245[n-1]:\n",
    "        sc_245 = sc_245 + 'Q'\n",
    "    if Z245[n] > Z245[n-1]:\n",
    "        sc_245 = sc_245 + 'Z'\n",
    "    if V245[n] > V245[n-1]:\n",
    "        sc_245 = sc_245 + 'V'\n",
    "    if ε245[n] > ε245[n-1]:\n",
    "        sc_245 = sc_245 + 'ε'\n",
    "    if W245[n] > W245[n-1]:\n",
    "        sc_245 = sc_245 + 'W'\n",
    "        st_245.append(sc_245)\n",
    "    else:\n",
    "        STC_245.append(st_245)\n",
    "        st_245 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_245 = STC_245.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_245 = [ st_245 for st_245 in STC_245 if len(st_245) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_245 = len(Q245)\n",
    "lmax_245 = 0\n",
    "for st_245 in STC_245:\n",
    "    if len(st_245) < lmin_245:\n",
    "        lmin_245 = len(st_245)\n",
    "    if len(st_245) > lmax_245:\n",
    "        lmax_245 = len(st_245)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_245 = [ st_245 for st_245 in STC_245 if len(st_245) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_245 = []\n",
    "for n in range(len(STC5_245)):\n",
    "    tc_245 = [ u for u in STC5_245[n][0] ]\n",
    "    for k in range(1, len(STC5_245[n])):\n",
    "        tc_245 = [ u+v for u in tc_245 for v in STC5_245[n][k] ]\n",
    "    TC5_245 = TC5_245 + tc_245\n",
    "setTC5_245 = list(set(TC5_245))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_245 = [ TC5_245.count(setTC5_245[l]) for l in range(len(setTC5_245)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_245 = [ [] for l in range(len(setTC5_245)) ]\n",
    "for s in range(245):\n",
    "    STC5null_245 = [ list(st_245) for st_245 in STC5_245]\n",
    "    for st_245 in STC5null_245:\n",
    "        np.random.shuffle(st_245)\n",
    "    TC5null_245= []\n",
    "    for n in range(len(STC5null_245)):\n",
    "        tc_245 = [ u for u in STC5null_245[n][0] ]\n",
    "        for k in range(1, len(STC5null_245[n])):\n",
    "            tc_245 = [ u+v for u in tc_245 for v in STC5null_245[n][k] ]\n",
    "        TC5null_245= TC5null_245+ tc_245\n",
    "    for l in range(len(setTC5_245)):\n",
    "        if TC5null_245.count(setTC5_245[l]) > 0:\n",
    "            fTC5null_245[l].append(TC5null_245.count(setTC5_245[l]))\n",
    "        else:\n",
    "            fTC5null_245[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61afe604",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "VQWεε\n",
      "ZεWQW\n",
      "QZVW\n",
      "ZεεQW\n",
      "εZVW\n",
      "ZεVεZ\n",
      "VεWεε\n",
      "ZZWQW\n",
      "ZVWQW\n",
      "ZεWQV\n",
      "WZVV\n",
      "VεWQV\n",
      "WWVV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_245)):\n",
    "    if sum(freq >= fTC5_245[l] for freq in fTC5null_245[l]) < 5:\n",
    "        print(setTC5_245[l], fTC5_245[l], sum(freq >= fTC5_245[l] for freq in fTC5null_245[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbaab2d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "ZεWQW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_245)):\n",
    "    if sum(freq >= fTC5_245[l] for freq in fTC5null_245[l]) < 1:\n",
    "        print(setTC5_245[l], fTC5_245[l], sum(freq >= fTC5_245[l] for freq in fTC5null_245[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd06f7ce",
   "metadata": {},
   "source": [
    "# 246 (Q) MER - (T) MBT - (V) TEL - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d97d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_246 = max(min(Date_MER), min(Date_MBT), min(Date_TEL), min(Date_URC), min(Date_PGOLD))\n",
    "end_246 = min(max(Date_MER), max(Date_MBT), max(Date_TEL), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "MER_246_1 = Date_MER.index(start_246)\n",
    "MER_246_2 = Date_MER.index(end_246)\n",
    "\n",
    "MBT_246_1 = Date_MBT.index(start_246)\n",
    "MBT_246_2 = Date_MBT.index(end_246)\n",
    "\n",
    "TEL_246_1 = Date_TEL.index(start_246)\n",
    "TEL_246_2 = Date_TEL.index(end_246)\n",
    "\n",
    "URC_246_1 = Date_URC.index(start_246)\n",
    "URC_246_2 = Date_URC.index(end_246)\n",
    "\n",
    "PGOLD_246_1 = Date_PGOLD.index(start_246)\n",
    "PGOLD_246_2 = Date_PGOLD.index(end_246)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "Q246 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_246_1:MER_246_2])\n",
    "T246 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_246_1:MBT_246_2])\n",
    "V246 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_246_1:TEL_246_2])\n",
    "ε246 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_246_1:URC_246_2])\n",
    "W246 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_246_1:PGOLD_246_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "Q246 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "T246 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V246 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε246 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W246 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cc3297a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_246 = []\n",
    "st_246 = []\n",
    "n = 1\n",
    "while n < len(Q246):\n",
    "    sc_246 = ''\n",
    "    if Q246[n] > Q246[n-1]:\n",
    "        sc_246 = sc_246 + 'Q'\n",
    "    if T246[n] > T246[n-1]:\n",
    "        sc_246 = sc_246 + 'T'\n",
    "    if V246[n] > V246[n-1]:\n",
    "        sc_246 = sc_246 + 'V'\n",
    "    if ε246[n] > ε246[n-1]:\n",
    "        sc_246 = sc_246 + 'ε'\n",
    "    if W246[n] > W246[n-1]:\n",
    "        sc_246 = sc_246 + 'W'\n",
    "        st_246.append(sc_246)\n",
    "    else:\n",
    "        STC_246.append(st_246)\n",
    "        st_246 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_246 = STC_246.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_246 = [ st_246 for st_246 in STC_246 if len(st_246) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_246 = len(Q246)\n",
    "lmax_246 = 0\n",
    "for st_246 in STC_246:\n",
    "    if len(st_246) < lmin_246:\n",
    "        lmin_246 = len(st_246)\n",
    "    if len(st_246) > lmax_246:\n",
    "        lmax_246 = len(st_246)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_246 = [ st_246 for st_246 in STC_246 if len(st_246) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_246 = []\n",
    "for n in range(len(STC5_246)):\n",
    "    tc_246 = [ u for u in STC5_246[n][0] ]\n",
    "    for k in range(1, len(STC5_246[n])):\n",
    "        tc_246 = [ u+v for u in tc_246 for v in STC5_246[n][k] ]\n",
    "    TC5_246 = TC5_246 + tc_246\n",
    "setTC5_246 = list(set(TC5_246))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_246 = [ TC5_246.count(setTC5_246[l]) for l in range(len(setTC5_246)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_246 = [ [] for l in range(len(setTC5_246)) ]\n",
    "for s in range(246):\n",
    "    STC5null_246 = [ list(st_246) for st_246 in STC5_246]\n",
    "    for st_246 in STC5null_246:\n",
    "        np.random.shuffle(st_246)\n",
    "    TC5null_246= []\n",
    "    for n in range(len(STC5null_246)):\n",
    "        tc_246 = [ u for u in STC5null_246[n][0] ]\n",
    "        for k in range(1, len(STC5null_246[n])):\n",
    "            tc_246 = [ u+v for u in tc_246 for v in STC5null_246[n][k] ]\n",
    "        TC5null_246= TC5null_246+ tc_246\n",
    "    for l in range(len(setTC5_246)):\n",
    "        if TC5null_246.count(setTC5_246[l]) > 0:\n",
    "            fTC5null_246[l].append(TC5null_246.count(setTC5_246[l]))\n",
    "        else:\n",
    "            fTC5null_246[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60c134c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "εWVT\n",
      "WεTQ\n",
      "VQWεε\n",
      "TWWQT\n",
      "εVVT\n",
      "TVVT\n",
      "WVVT\n",
      "WTVT\n",
      "VVWTε\n",
      "WWVT\n",
      "εTVT\n",
      "TVTεW\n",
      "VεWεε\n",
      "TVWQT\n",
      "TWQQT\n",
      "QVTεW\n",
      "WQTT\n",
      "VεWQV\n",
      "VεTεε\n",
      "WWVV\n",
      "WQTQ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_246)):\n",
    "    if sum(freq >= fTC5_246[l] for freq in fTC5null_246[l]) < 5:\n",
    "        print(setTC5_246[l], fTC5_246[l], sum(freq >= fTC5_246[l] for freq in fTC5null_246[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30530427",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "εVVT\n",
      "WTVT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_246)):\n",
    "    if sum(freq >= fTC5_246[l] for freq in fTC5null_246[l]) < 1:\n",
    "        print(setTC5_246[l], fTC5_246[l], sum(freq >= fTC5_246[l] for freq in fTC5null_246[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a3bd38",
   "metadata": {},
   "source": [
    "# 247 (E) ALI - (Z) SECB - (T) MBT - (V) TEL - (ε) URC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52a7af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_247 = max(min(Date_ALI), min(Date_SECB), min(Date_MBT), min(Date_TEL), min(Date_URC))\n",
    "end_247 = min(max(Date_ALI), max(Date_SECB), max(Date_MBT), max(Date_TEL), max(Date_URC))\n",
    "\n",
    "#shorten the closing prices\n",
    "ALI_247_1 = Date_ALI.index(start_247)\n",
    "ALI_247_2 = Date_ALI.index(end_247)\n",
    "\n",
    "SECB_247_1 = Date_SECB.index(start_247)\n",
    "SECB_247_2 = Date_SECB.index(end_247)\n",
    "\n",
    "MBT_247_1 = Date_MBT.index(start_247)\n",
    "MBT_247_2 = Date_MBT.index(end_247)\n",
    "\n",
    "TEL_247_1 = Date_TEL.index(start_247)\n",
    "TEL_247_2 = Date_TEL.index(end_247)\n",
    "\n",
    "URC_247_1 = Date_URC.index(start_247)\n",
    "URC_247_2 = Date_URC.index(end_247)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "E247 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_247_1:ALI_247_2])\n",
    "Z247 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_247_1:SECB_247_2])\n",
    "T247 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_247_1:MBT_247_2])\n",
    "V247 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_247_1:TEL_247_2])\n",
    "ε247 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_247_1:URC_247_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "E247 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z247 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T247 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V247 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε247 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95804d31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_247 = []\n",
    "st_247 = []\n",
    "n = 1\n",
    "while n < len(E247):\n",
    "    sc_247 = ''\n",
    "    if E247[n] > E247[n-1]:\n",
    "        sc_247 = sc_247 + 'E'\n",
    "    if Z247[n] > Z247[n-1]:\n",
    "        sc_247 = sc_247 + 'Z'\n",
    "    if T247[n] > T247[n-1]:\n",
    "        sc_247 = sc_247 + 'T'\n",
    "    if V247[n] > V247[n-1]:\n",
    "        sc_247 = sc_247 + 'V'\n",
    "    if ε247[n] > ε247[n-1]:\n",
    "        sc_247 = sc_247 + 'ε'\n",
    "        st_247.append(sc_247)\n",
    "    else:\n",
    "        STC_247.append(st_247)\n",
    "        st_247 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_247 = STC_247.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_247 = [ st_247 for st_247 in STC_247 if len(st_247) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_247 = len(E247)\n",
    "lmax_247 = 0\n",
    "for st_247 in STC_247:\n",
    "    if len(st_247) < lmin_247:\n",
    "        lmin_247 = len(st_247)\n",
    "    if len(st_247) > lmax_247:\n",
    "        lmax_247 = len(st_247)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_247 = [ st_247 for st_247 in STC_247 if len(st_247) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_247 = []\n",
    "for n in range(len(STC5_247)):\n",
    "    tc_247 = [ u for u in STC5_247[n][0] ]\n",
    "    for k in range(1, len(STC5_247[n])):\n",
    "        tc_247 = [ u+v for u in tc_247 for v in STC5_247[n][k] ]\n",
    "    TC5_247 = TC5_247 + tc_247\n",
    "setTC5_247 = list(set(TC5_247))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_247 = [ TC5_247.count(setTC5_247[l]) for l in range(len(setTC5_247)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_247 = [ [] for l in range(len(setTC5_247)) ]\n",
    "for s in range(247):\n",
    "    STC5null_247 = [ list(st_247) for st_247 in STC5_247]\n",
    "    for st_247 in STC5null_247:\n",
    "        np.random.shuffle(st_247)\n",
    "    TC5null_247= []\n",
    "    for n in range(len(STC5null_247)):\n",
    "        tc_247 = [ u for u in STC5null_247[n][0] ]\n",
    "        for k in range(1, len(STC5null_247[n])):\n",
    "            tc_247 = [ u+v for u in tc_247 for v in STC5null_247[n][k] ]\n",
    "        TC5null_247= TC5null_247+ tc_247\n",
    "    for l in range(len(setTC5_247)):\n",
    "        if TC5null_247.count(setTC5_247[l]) > 0:\n",
    "            fTC5null_247[l].append(TC5null_247.count(setTC5_247[l]))\n",
    "        else:\n",
    "            fTC5null_247[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60db8628",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "EZεVV\n",
      "EZT\n",
      "TZZεT\n",
      "εεVε\n",
      "TVEε\n",
      "TVZε\n",
      "εVVε\n",
      "TZεεT\n",
      "EZε\n",
      "ZEVZ\n",
      "EεεεV\n",
      "EZTVV\n",
      "εZε\n",
      "TZεVT\n",
      "TTVε\n",
      "EZεVε\n",
      "VZε\n",
      "EZεVT\n",
      "εZεVV\n",
      "EVε\n",
      "ETε\n",
      "VTε\n",
      "EEεEε\n",
      "TEVε\n",
      "εZεVT\n",
      "εTVε\n",
      "ZεVZ\n",
      "εEVε\n",
      "EEεEV\n",
      "TVVε\n",
      "ZZεVT\n",
      "VVε\n",
      "ZVVZ\n",
      "TεVε\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_247)):\n",
    "    if sum(freq >= fTC5_247[l] for freq in fTC5null_247[l]) < 5:\n",
    "        print(setTC5_247[l], fTC5_247[l], sum(freq >= fTC5_247[l] for freq in fTC5null_247[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff657875",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "εVVε\n",
      "EZε\n",
      "TZεVT\n",
      "VZε\n",
      "ZZεVT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_247)):\n",
    "    if sum(freq >= fTC5_247[l] for freq in fTC5null_247[l]) < 1:\n",
    "        print(setTC5_247[l], fTC5_247[l], sum(freq >= fTC5_247[l] for freq in fTC5null_247[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a7941c",
   "metadata": {},
   "source": [
    "# 248 (E) ALI - (Z) SECB - (T) MBT - (V) TEL - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38fafe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_248 = max(min(Date_ALI), min(Date_SECB), min(Date_MBT), min(Date_TEL), min(Date_PGOLD))\n",
    "end_248 = min(max(Date_ALI), max(Date_SECB), max(Date_MBT), max(Date_TEL), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "ALI_248_1 = Date_ALI.index(start_248)\n",
    "ALI_248_2 = Date_ALI.index(end_248)\n",
    "\n",
    "SECB_248_1 = Date_SECB.index(start_248)\n",
    "SECB_248_2 = Date_SECB.index(end_248)\n",
    "\n",
    "MBT_248_1 = Date_MBT.index(start_248)\n",
    "MBT_248_2 = Date_MBT.index(end_248)\n",
    "\n",
    "TEL_248_1 = Date_TEL.index(start_248)\n",
    "TEL_248_2 = Date_TEL.index(end_248)\n",
    "\n",
    "PGOLD_248_1 = Date_PGOLD.index(start_248)\n",
    "PGOLD_248_2 = Date_PGOLD.index(end_248)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "E248 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_248_1:ALI_248_2])\n",
    "Z248 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_248_1:SECB_248_2])\n",
    "T248 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_248_1:MBT_248_2])\n",
    "V248 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_248_1:TEL_248_2])\n",
    "W248 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_248_1:PGOLD_248_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "E248 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z248 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T248 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V248 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "W248 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6bf5ecf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_248 = []\n",
    "st_248 = []\n",
    "n = 1\n",
    "while n < len(E248):\n",
    "    sc_248 = ''\n",
    "    if E248[n] > E248[n-1]:\n",
    "        sc_248 = sc_248 + 'E'\n",
    "    if Z248[n] > Z248[n-1]:\n",
    "        sc_248 = sc_248 + 'Z'\n",
    "    if T248[n] > T248[n-1]:\n",
    "        sc_248 = sc_248 + 'T'\n",
    "    if V248[n] > V248[n-1]:\n",
    "        sc_248 = sc_248 + 'V'\n",
    "    if W248[n] > W248[n-1]:\n",
    "        sc_248 = sc_248 + 'W'\n",
    "        st_248.append(sc_248)\n",
    "    else:\n",
    "        STC_248.append(st_248)\n",
    "        st_248 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_248 = STC_248.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_248 = [ st_248 for st_248 in STC_248 if len(st_248) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_248 = len(E248)\n",
    "lmax_248 = 0\n",
    "for st_248 in STC_248:\n",
    "    if len(st_248) < lmin_248:\n",
    "        lmin_248 = len(st_248)\n",
    "    if len(st_248) > lmax_248:\n",
    "        lmax_248 = len(st_248)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_248 = [ st_248 for st_248 in STC_248 if len(st_248) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_248 = []\n",
    "for n in range(len(STC5_248)):\n",
    "    tc_248 = [ u for u in STC5_248[n][0] ]\n",
    "    for k in range(1, len(STC5_248[n])):\n",
    "        tc_248 = [ u+v for u in tc_248 for v in STC5_248[n][k] ]\n",
    "    TC5_248 = TC5_248 + tc_248\n",
    "setTC5_248 = list(set(TC5_248))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_248 = [ TC5_248.count(setTC5_248[l]) for l in range(len(setTC5_248)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_248 = [ [] for l in range(len(setTC5_248)) ]\n",
    "for s in range(248):\n",
    "    STC5null_248 = [ list(st_248) for st_248 in STC5_248]\n",
    "    for st_248 in STC5null_248:\n",
    "        np.random.shuffle(st_248)\n",
    "    TC5null_248= []\n",
    "    for n in range(len(STC5null_248)):\n",
    "        tc_248 = [ u for u in STC5null_248[n][0] ]\n",
    "        for k in range(1, len(STC5null_248[n])):\n",
    "            tc_248 = [ u+v for u in tc_248 for v in STC5null_248[n][k] ]\n",
    "        TC5null_248= TC5null_248+ tc_248\n",
    "    for l in range(len(setTC5_248)):\n",
    "        if TC5null_248.count(setTC5_248[l]) > 0:\n",
    "            fTC5null_248[l].append(TC5null_248.count(setTC5_248[l]))\n",
    "        else:\n",
    "            fTC5null_248[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e882285",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "TVVT\n",
      "WVVT\n",
      "VZWEV\n",
      "EZVV\n",
      "WTVT\n",
      "WETT\n",
      "WWVT\n",
      "EWVT\n",
      "WZVT\n",
      "ZZZWE\n",
      "EZVT\n",
      "WZVV\n",
      "TZWEE\n",
      "EVVT\n",
      "WWVV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_248)):\n",
    "    if sum(freq >= fTC5_248[l] for freq in fTC5null_248[l]) < 5:\n",
    "        print(setTC5_248[l], fTC5_248[l], sum(freq >= fTC5_248[l] for freq in fTC5null_248[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0d10e11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "WTVT\n",
      "WZVT\n",
      "EZVT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_248)):\n",
    "    if sum(freq >= fTC5_248[l] for freq in fTC5null_248[l]) < 1:\n",
    "        print(setTC5_248[l], fTC5_248[l], sum(freq >= fTC5_248[l] for freq in fTC5null_248[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd05a08",
   "metadata": {},
   "source": [
    "# 249 (E) ALI - (Z) SECB - (T) MBT - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dde7b94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_249 = max(min(Date_ALI), min(Date_SECB), min(Date_MBT), min(Date_URC), min(Date_PGOLD))\n",
    "end_249 = min(max(Date_ALI), max(Date_SECB), max(Date_MBT), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "ALI_249_1 = Date_ALI.index(start_249)\n",
    "ALI_249_2 = Date_ALI.index(end_249)\n",
    "\n",
    "SECB_249_1 = Date_SECB.index(start_249)\n",
    "SECB_249_2 = Date_SECB.index(end_249)\n",
    "\n",
    "MBT_249_1 = Date_MBT.index(start_249)\n",
    "MBT_249_2 = Date_MBT.index(end_249)\n",
    "\n",
    "URC_249_1 = Date_URC.index(start_249)\n",
    "URC_249_2 = Date_URC.index(end_249)\n",
    "\n",
    "PGOLD_249_1 = Date_PGOLD.index(start_249)\n",
    "PGOLD_249_2 = Date_PGOLD.index(end_249)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "E249 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_249_1:ALI_249_2])\n",
    "Z249 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_249_1:SECB_249_2])\n",
    "T249 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_249_1:MBT_249_2])\n",
    "ε249 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_249_1:URC_249_2])\n",
    "W249 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_249_1:PGOLD_249_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "E249 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z249 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T249 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε249 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W249 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "451c0fbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_249 = []\n",
    "st_249 = []\n",
    "n = 1\n",
    "while n < len(E249):\n",
    "    sc_249 = ''\n",
    "    if E249[n] > E249[n-1]:\n",
    "        sc_249 = sc_249 + 'E'\n",
    "    if Z249[n] > Z249[n-1]:\n",
    "        sc_249 = sc_249 + 'Z'\n",
    "    if T249[n] > T249[n-1]:\n",
    "        sc_249 = sc_249 + 'T'\n",
    "    if ε249[n] > ε249[n-1]:\n",
    "        sc_249 = sc_249 + 'ε'\n",
    "    if W249[n] > W249[n-1]:\n",
    "        sc_249 = sc_249 + 'W'\n",
    "        st_249.append(sc_249)\n",
    "    else:\n",
    "        STC_249.append(st_249)\n",
    "        st_249 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_249 = STC_249.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_249 = [ st_249 for st_249 in STC_249 if len(st_249) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_249 = len(E249)\n",
    "lmax_249 = 0\n",
    "for st_249 in STC_249:\n",
    "    if len(st_249) < lmin_249:\n",
    "        lmin_249 = len(st_249)\n",
    "    if len(st_249) > lmax_249:\n",
    "        lmax_249 = len(st_249)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_249 = [ st_249 for st_249 in STC_249 if len(st_249) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_249 = []\n",
    "for n in range(len(STC5_249)):\n",
    "    tc_249 = [ u for u in STC5_249[n][0] ]\n",
    "    for k in range(1, len(STC5_249[n])):\n",
    "        tc_249 = [ u+v for u in tc_249 for v in STC5_249[n][k] ]\n",
    "    TC5_249 = TC5_249 + tc_249\n",
    "setTC5_249 = list(set(TC5_249))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_249 = [ TC5_249.count(setTC5_249[l]) for l in range(len(setTC5_249)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_249 = [ [] for l in range(len(setTC5_249)) ]\n",
    "for s in range(249):\n",
    "    STC5null_249 = [ list(st_249) for st_249 in STC5_249]\n",
    "    for st_249 in STC5null_249:\n",
    "        np.random.shuffle(st_249)\n",
    "    TC5null_249= []\n",
    "    for n in range(len(STC5null_249)):\n",
    "        tc_249 = [ u for u in STC5null_249[n][0] ]\n",
    "        for k in range(1, len(STC5null_249[n])):\n",
    "            tc_249 = [ u+v for u in tc_249 for v in STC5null_249[n][k] ]\n",
    "        TC5null_249= TC5null_249+ tc_249\n",
    "    for l in range(len(setTC5_249)):\n",
    "        if TC5null_249.count(setTC5_249[l]) > 0:\n",
    "            fTC5null_249[l].append(TC5null_249.count(setTC5_249[l]))\n",
    "        else:\n",
    "            fTC5null_249[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "febd311d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "EεEZ\n",
      "ZεWEE\n",
      "TεεEW\n",
      "ZεZEE\n",
      "WETT\n",
      "ZZZWE\n",
      "TZWEE\n",
      "TεZEE\n",
      "TεWEE\n",
      "TεεEE\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_249)):\n",
    "    if sum(freq >= fTC5_249[l] for freq in fTC5null_249[l]) < 5:\n",
    "        print(setTC5_249[l], fTC5_249[l], sum(freq >= fTC5_249[l] for freq in fTC5null_249[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "681094be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "ZεWEE\n",
      "TεWEE\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_249)):\n",
    "    if sum(freq >= fTC5_249[l] for freq in fTC5null_249[l]) < 1:\n",
    "        print(setTC5_249[l], fTC5_249[l], sum(freq >= fTC5_249[l] for freq in fTC5null_249[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a42e249",
   "metadata": {},
   "source": [
    "# 250 (E) ALI - (Z) SECB - (V) TEL - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e275503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_250 = max(min(Date_ALI), min(Date_SECB), min(Date_TEL), min(Date_URC), min(Date_PGOLD))\n",
    "end_250 = min(max(Date_ALI), max(Date_SECB), max(Date_TEL), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "ALI_250_1 = Date_ALI.index(start_250)\n",
    "ALI_250_2 = Date_ALI.index(end_250)\n",
    "\n",
    "SECB_250_1 = Date_SECB.index(start_250)\n",
    "SECB_250_2 = Date_SECB.index(end_250)\n",
    "\n",
    "TEL_250_1 = Date_TEL.index(start_250)\n",
    "TEL_250_2 = Date_TEL.index(end_250)\n",
    "\n",
    "URC_250_1 = Date_URC.index(start_250)\n",
    "URC_250_2 = Date_URC.index(end_250)\n",
    "\n",
    "PGOLD_250_1 = Date_PGOLD.index(start_250)\n",
    "PGOLD_250_2 = Date_PGOLD.index(end_250)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "E250 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_250_1:ALI_250_2])\n",
    "Z250 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_250_1:SECB_250_2])\n",
    "V250 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_250_1:TEL_250_2])\n",
    "ε250 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_250_1:URC_250_2])\n",
    "W250 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_250_1:PGOLD_250_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "E250 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z250 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "V250 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε250 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W250 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe6d17c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_250 = []\n",
    "st_250 = []\n",
    "n = 1\n",
    "while n < len(E250):\n",
    "    sc_250 = ''\n",
    "    if E250[n] > E250[n-1]:\n",
    "        sc_250 = sc_250 + 'E'\n",
    "    if Z250[n] > Z250[n-1]:\n",
    "        sc_250 = sc_250 + 'Z'\n",
    "    if V250[n] > V250[n-1]:\n",
    "        sc_250 = sc_250 + 'V'\n",
    "    if ε250[n] > ε250[n-1]:\n",
    "        sc_250 = sc_250 + 'ε'\n",
    "    if W250[n] > W250[n-1]:\n",
    "        sc_250 = sc_250 + 'W'\n",
    "        st_250.append(sc_250)\n",
    "    else:\n",
    "        STC_250.append(st_250)\n",
    "        st_250 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_250 = STC_250.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_250 = [ st_250 for st_250 in STC_250 if len(st_250) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_250 = len(E250)\n",
    "lmax_250 = 0\n",
    "for st_250 in STC_250:\n",
    "    if len(st_250) < lmin_250:\n",
    "        lmin_250 = len(st_250)\n",
    "    if len(st_250) > lmax_250:\n",
    "        lmax_250 = len(st_250)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_250 = [ st_250 for st_250 in STC_250 if len(st_250) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_250 = []\n",
    "for n in range(len(STC5_250)):\n",
    "    tc_250 = [ u for u in STC5_250[n][0] ]\n",
    "    for k in range(1, len(STC5_250[n])):\n",
    "        tc_250 = [ u+v for u in tc_250 for v in STC5_250[n][k] ]\n",
    "    TC5_250 = TC5_250 + tc_250\n",
    "setTC5_250 = list(set(TC5_250))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_250 = [ TC5_250.count(setTC5_250[l]) for l in range(len(setTC5_250)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_250 = [ [] for l in range(len(setTC5_250)) ]\n",
    "for s in range(250):\n",
    "    STC5null_250 = [ list(st_250) for st_250 in STC5_250]\n",
    "    for st_250 in STC5null_250:\n",
    "        np.random.shuffle(st_250)\n",
    "    TC5null_250= []\n",
    "    for n in range(len(STC5null_250)):\n",
    "        tc_250 = [ u for u in STC5null_250[n][0] ]\n",
    "        for k in range(1, len(STC5null_250[n])):\n",
    "            tc_250 = [ u+v for u in tc_250 for v in STC5null_250[n][k] ]\n",
    "        TC5null_250= TC5null_250+ tc_250\n",
    "    for l in range(len(setTC5_250)):\n",
    "        if TC5null_250.count(setTC5_250[l]) > 0:\n",
    "            fTC5null_250[l].append(TC5null_250.count(setTC5_250[l]))\n",
    "        else:\n",
    "            fTC5null_250[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07ee0b2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "VεEEV\n",
      "EεEZ\n",
      "ZεWEE\n",
      "VZWEV\n",
      "EZVV\n",
      "ZεZEE\n",
      "εZVW\n",
      "ZεVεZ\n",
      "ZZZWE\n",
      "VεWεε\n",
      "EεEEV\n",
      "WZVV\n",
      "EεVV\n",
      "VεWEV\n",
      "WWVV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_250)):\n",
    "    if sum(freq >= fTC5_250[l] for freq in fTC5null_250[l]) < 5:\n",
    "        print(setTC5_250[l], fTC5_250[l], sum(freq >= fTC5_250[l] for freq in fTC5null_250[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30848b64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "ZεWEE\n",
      "EεVV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_250)):\n",
    "    if sum(freq >= fTC5_250[l] for freq in fTC5null_250[l]) < 1:\n",
    "        print(setTC5_250[l], fTC5_250[l], sum(freq >= fTC5_250[l] for freq in fTC5null_250[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61f95bb",
   "metadata": {},
   "source": [
    "# 251 (E) ALI - (T) MBT - (V) TEL - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf9957e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_251 = max(min(Date_ALI), min(Date_MBT), min(Date_TEL), min(Date_URC), min(Date_PGOLD))\n",
    "end_251 = min(max(Date_ALI), max(Date_MBT), max(Date_TEL), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "ALI_251_1 = Date_ALI.index(start_251)\n",
    "ALI_251_2 = Date_ALI.index(end_251)\n",
    "\n",
    "MBT_251_1 = Date_MBT.index(start_251)\n",
    "MBT_251_2 = Date_MBT.index(end_251)\n",
    "\n",
    "TEL_251_1 = Date_TEL.index(start_251)\n",
    "TEL_251_2 = Date_TEL.index(end_251)\n",
    "\n",
    "URC_251_1 = Date_URC.index(start_251)\n",
    "URC_251_2 = Date_URC.index(end_251)\n",
    "\n",
    "PGOLD_251_1 = Date_PGOLD.index(start_251)\n",
    "PGOLD_251_2 = Date_PGOLD.index(end_251)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "E251 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_251_1:ALI_251_2])\n",
    "T251 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_251_1:MBT_251_2])\n",
    "V251 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_251_1:TEL_251_2])\n",
    "ε251 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_251_1:URC_251_2])\n",
    "W251 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_251_1:PGOLD_251_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "E251 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "T251 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V251 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε251 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W251 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5749faef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_251 = []\n",
    "st_251 = []\n",
    "n = 1\n",
    "while n < len(E251):\n",
    "    sc_251 = ''\n",
    "    if E251[n] > E251[n-1]:\n",
    "        sc_251 = sc_251 + 'E'\n",
    "    if T251[n] > T251[n-1]:\n",
    "        sc_251 = sc_251 + 'T'\n",
    "    if V251[n] > V251[n-1]:\n",
    "        sc_251 = sc_251 + 'V'\n",
    "    if ε251[n] > ε251[n-1]:\n",
    "        sc_251 = sc_251 + 'ε'\n",
    "    if W251[n] > W251[n-1]:\n",
    "        sc_251 = sc_251 + 'W'\n",
    "        st_251.append(sc_251)\n",
    "    else:\n",
    "        STC_251.append(st_251)\n",
    "        st_251 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_251 = STC_251.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_251 = [ st_251 for st_251 in STC_251 if len(st_251) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_251 = len(E251)\n",
    "lmax_251 = 0\n",
    "for st_251 in STC_251:\n",
    "    if len(st_251) < lmin_251:\n",
    "        lmin_251 = len(st_251)\n",
    "    if len(st_251) > lmax_251:\n",
    "        lmax_251 = len(st_251)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_251 = [ st_251 for st_251 in STC_251 if len(st_251) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_251 = []\n",
    "for n in range(len(STC5_251)):\n",
    "    tc_251 = [ u for u in STC5_251[n][0] ]\n",
    "    for k in range(1, len(STC5_251[n])):\n",
    "        tc_251 = [ u+v for u in tc_251 for v in STC5_251[n][k] ]\n",
    "    TC5_251 = TC5_251 + tc_251\n",
    "setTC5_251 = list(set(TC5_251))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_251 = [ TC5_251.count(setTC5_251[l]) for l in range(len(setTC5_251)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_251 = [ [] for l in range(len(setTC5_251)) ]\n",
    "for s in range(251):\n",
    "    STC5null_251 = [ list(st_251) for st_251 in STC5_251]\n",
    "    for st_251 in STC5null_251:\n",
    "        np.random.shuffle(st_251)\n",
    "    TC5null_251= []\n",
    "    for n in range(len(STC5null_251)):\n",
    "        tc_251 = [ u for u in STC5null_251[n][0] ]\n",
    "        for k in range(1, len(STC5null_251[n])):\n",
    "            tc_251 = [ u+v for u in tc_251 for v in STC5null_251[n][k] ]\n",
    "        TC5null_251= TC5null_251+ tc_251\n",
    "    for l in range(len(setTC5_251)):\n",
    "        if TC5null_251.count(setTC5_251[l]) > 0:\n",
    "            fTC5null_251[l].append(TC5null_251.count(setTC5_251[l]))\n",
    "        else:\n",
    "            fTC5null_251[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aae068e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "εWVT\n",
      "VεEEV\n",
      "εVVT\n",
      "TVVT\n",
      "TεεEW\n",
      "WVVT\n",
      "WTVT\n",
      "VVWTε\n",
      "WETT\n",
      "WWVT\n",
      "EWVT\n",
      "εTVT\n",
      "TVTεW\n",
      "VεWεε\n",
      "EεEEV\n",
      "EVVT\n",
      "EεVV\n",
      "TεWEE\n",
      "VεWEV\n",
      "VεTεε\n",
      "WWVV\n",
      "EεVT\n",
      "TεεEE\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_251)):\n",
    "    if sum(freq >= fTC5_251[l] for freq in fTC5null_251[l]) < 5:\n",
    "        print(setTC5_251[l], fTC5_251[l], sum(freq >= fTC5_251[l] for freq in fTC5null_251[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "622fe7e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "εVVT\n",
      "WTVT\n",
      "EεVV\n",
      "TεWEE\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_251)):\n",
    "    if sum(freq >= fTC5_251[l] for freq in fTC5null_251[l]) < 1:\n",
    "        print(setTC5_251[l], fTC5_251[l], sum(freq >= fTC5_251[l] for freq in fTC5null_251[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a62ab",
   "metadata": {},
   "source": [
    "# 252 (Z) SECB - (T) MBT - (V) TEL - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18a55a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_252 = max(min(Date_SECB), min(Date_MBT), min(Date_TEL), min(Date_URC), min(Date_PGOLD))\n",
    "end_252 = min(max(Date_SECB), max(Date_MBT), max(Date_TEL), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "SECB_252_1 = Date_SECB.index(start_252)\n",
    "SECB_252_2 = Date_SECB.index(end_252)\n",
    "\n",
    "MBT_252_1 = Date_MBT.index(start_252)\n",
    "MBT_252_2 = Date_MBT.index(end_252)\n",
    "\n",
    "TEL_252_1 = Date_TEL.index(start_252)\n",
    "TEL_252_2 = Date_TEL.index(end_252)\n",
    "\n",
    "URC_252_1 = Date_URC.index(start_252)\n",
    "URC_252_2 = Date_URC.index(end_252)\n",
    "\n",
    "PGOLD_252_1 = Date_PGOLD.index(start_252)\n",
    "PGOLD_252_2 = Date_PGOLD.index(end_252)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "Z252 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_252_1:SECB_252_2])\n",
    "T252 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_252_1:MBT_252_2])\n",
    "V252 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_252_1:TEL_252_2])\n",
    "ε252 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_252_1:URC_252_2])\n",
    "W252 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_252_1:PGOLD_252_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "Z252 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T252 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V252 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε252 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W252 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d0a3d31c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_252 = []\n",
    "st_252 = []\n",
    "n = 1\n",
    "while n < len(Z252):\n",
    "    sc_252 = ''\n",
    "    if Z252[n] > Z252[n-1]:\n",
    "        sc_252 = sc_252 + 'Z'\n",
    "    if T252[n] > T252[n-1]:\n",
    "        sc_252 = sc_252 + 'T'\n",
    "    if V252[n] > V252[n-1]:\n",
    "        sc_252 = sc_252 + 'V'\n",
    "    if ε252[n] > ε252[n-1]:\n",
    "        sc_252 = sc_252 + 'ε'\n",
    "    if W252[n] > W252[n-1]:\n",
    "        sc_252 = sc_252 + 'W'\n",
    "        st_252.append(sc_252)\n",
    "    else:\n",
    "        STC_252.append(st_252)\n",
    "        st_252 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_252 = STC_252.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_252 = [ st_252 for st_252 in STC_252 if len(st_252) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_252 = len(Z252)\n",
    "lmax_252 = 0\n",
    "for st_252 in STC_252:\n",
    "    if len(st_252) < lmin_252:\n",
    "        lmin_252 = len(st_252)\n",
    "    if len(st_252) > lmax_252:\n",
    "        lmax_252 = len(st_252)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_252 = [ st_252 for st_252 in STC_252 if len(st_252) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_252 = []\n",
    "for n in range(len(STC5_252)):\n",
    "    tc_252 = [ u for u in STC5_252[n][0] ]\n",
    "    for k in range(1, len(STC5_252[n])):\n",
    "        tc_252 = [ u+v for u in tc_252 for v in STC5_252[n][k] ]\n",
    "    TC5_252 = TC5_252 + tc_252\n",
    "setTC5_252 = list(set(TC5_252))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_252 = [ TC5_252.count(setTC5_252[l]) for l in range(len(setTC5_252)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_252 = [ [] for l in range(len(setTC5_252)) ]\n",
    "for s in range(252):\n",
    "    STC5null_252 = [ list(st_252) for st_252 in STC5_252]\n",
    "    for st_252 in STC5null_252:\n",
    "        np.random.shuffle(st_252)\n",
    "    TC5null_252= []\n",
    "    for n in range(len(STC5null_252)):\n",
    "        tc_252 = [ u for u in STC5null_252[n][0] ]\n",
    "        for k in range(1, len(STC5null_252[n])):\n",
    "            tc_252 = [ u+v for u in tc_252 for v in STC5null_252[n][k] ]\n",
    "        TC5null_252= TC5null_252+ tc_252\n",
    "    for l in range(len(setTC5_252)):\n",
    "        if TC5null_252.count(setTC5_252[l]) > 0:\n",
    "            fTC5null_252[l].append(TC5null_252.count(setTC5_252[l]))\n",
    "        else:\n",
    "            fTC5null_252[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b83d1f11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "εWVT\n",
      "εVVT\n",
      "TVVT\n",
      "WVVT\n",
      "WTVT\n",
      "VVWTε\n",
      "WWVT\n",
      "WZVT\n",
      "εZVT\n",
      "εTVT\n",
      "εZVW\n",
      "ZεVεZ\n",
      "TVTεW\n",
      "VεWεε\n",
      "WZVV\n",
      "VεTεε\n",
      "WWVV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_252)):\n",
    "    if sum(freq >= fTC5_252[l] for freq in fTC5null_252[l]) < 5:\n",
    "        print(setTC5_252[l], fTC5_252[l], sum(freq >= fTC5_252[l] for freq in fTC5null_252[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22916bb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "εVVT\n",
      "WTVT\n",
      "WZVT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_252)):\n",
    "    if sum(freq >= fTC5_252[l] for freq in fTC5null_252[l]) < 1:\n",
    "        print(setTC5_252[l], fTC5_252[l], sum(freq >= fTC5_252[l] for freq in fTC5null_252[l]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
