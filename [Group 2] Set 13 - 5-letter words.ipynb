{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad73c97",
   "metadata": {},
   "source": [
    "# One-Letter Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc40866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the csv files\n",
    "GTCAP = open('GTCAP.csv')\n",
    "AGI = open('AGI.csv')\n",
    "SM = open('SM.csv')\n",
    "MER = open('MER.csv')\n",
    "ALI = open('ALI.csv')\n",
    "SECB = open('SECB.csv')\n",
    "MBT = open('MBT.csv')\n",
    "TEL = open('TEL.csv')\n",
    "URC = open('URC.csv')\n",
    "PGOLD = open('PGOLD.csv')\n",
    "\n",
    "#initialize the lists\n",
    "Date_GTCAP = []\n",
    "ClosePrice_GTCAP = []\n",
    "Date_AGI = []\n",
    "ClosePrice_AGI = []\n",
    "Date_SM = []\n",
    "ClosePrice_SM = []\n",
    "Date_MER = []\n",
    "ClosePrice_MER = []\n",
    "Date_ALI = []\n",
    "ClosePrice_ALI = []\n",
    "Date_SECB = []\n",
    "ClosePrice_SECB = []\n",
    "Date_MBT = []\n",
    "ClosePrice_MBT = []\n",
    "Date_TEL = []\n",
    "ClosePrice_TEL = []\n",
    "Date_URC = []\n",
    "ClosePrice_URC = []\n",
    "Date_PGOLD = []\n",
    "ClosePrice_PGOLD = []\n",
    "\n",
    "#skip the header line\n",
    "GTCAP.readline()\n",
    "AGI.readline()\n",
    "SM.readline()\n",
    "MER.readline()\n",
    "ALI.readline()\n",
    "SECB.readline()\n",
    "MBT.readline()\n",
    "TEL.readline()\n",
    "URC.readline()\n",
    "PGOLD.readline()\n",
    "\n",
    "#go through the files line by line\n",
    "for line in GTCAP:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_GTCAP.append(sline[0])\n",
    "    ClosePrice_GTCAP.append(float(sline[1]))\n",
    "    \n",
    "for line in AGI:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_AGI.append(sline[0])\n",
    "    ClosePrice_AGI.append(float(sline[1]))\n",
    "    \n",
    "for line in SM:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_SM.append(sline[0])\n",
    "    ClosePrice_SM.append(float(sline[1]))\n",
    "    \n",
    "for line in MER:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_MER.append(sline[0])\n",
    "    ClosePrice_MER.append(float(sline[1]))\n",
    "    \n",
    "for line in ALI:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_ALI.append(sline[0])\n",
    "    ClosePrice_ALI.append(float(sline[1]))\n",
    "    \n",
    "for line in SECB:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_SECB.append(sline[0])\n",
    "    ClosePrice_SECB.append(float(sline[1]))\n",
    "    \n",
    "for line in MBT:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_MBT.append(sline[0])\n",
    "    ClosePrice_MBT.append(float(sline[1]))\n",
    "    \n",
    "for line in TEL:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_TEL.append(sline[0])\n",
    "    ClosePrice_TEL.append(float(sline[1]))\n",
    "    \n",
    "for line in URC:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_URC.append(sline[0])\n",
    "    ClosePrice_URC.append(float(sline[1]))\n",
    "        \n",
    "for line in PGOLD:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_PGOLD.append(sline[0])\n",
    "    ClosePrice_PGOLD.append(float(sline[1]))\n",
    "\n",
    "\n",
    "#close files\n",
    "GTCAP.close()\n",
    "AGI.close()\n",
    "SM.close()\n",
    "MER.close()\n",
    "ALI.close()\n",
    "SECB.close()\n",
    "MBT.close()\n",
    "TEL.close()\n",
    "URC.close()\n",
    "PGOLD.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f08815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c5fa0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates into datetime structure\n",
    "for n in range(len(Date_GTCAP)):\n",
    "    Date_GTCAP[n] = datetime.datetime.strptime(Date_GTCAP[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_AGI)):\n",
    "    Date_AGI[n] = datetime.datetime.strptime(Date_AGI[n], '%m/%d/%y').date()\n",
    "    \n",
    "for n in range(len(Date_SM)):\n",
    "    Date_SM[n] = datetime.datetime.strptime(Date_SM[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_MER)):\n",
    "    Date_MER[n] = datetime.datetime.strptime(Date_MER[n], '%m/%d/%y').date()\n",
    "    \n",
    "for n in range(len(Date_ALI)):\n",
    "    Date_ALI[n] = datetime.datetime.strptime(Date_ALI[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_SECB)):\n",
    "    Date_SECB[n] = datetime.datetime.strptime(Date_SECB[n], '%m/%d/%y').date()\n",
    "    \n",
    "for n in range(len(Date_MBT)):\n",
    "    Date_MBT[n] = datetime.datetime.strptime(Date_MBT[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_TEL)):\n",
    "    Date_TEL[n] = datetime.datetime.strptime(Date_TEL[n], '%m/%d/%y').date()\n",
    "    \n",
    "for n in range(len(Date_URC)):\n",
    "    Date_URC[n] = datetime.datetime.strptime(Date_URC[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_PGOLD)):\n",
    "    Date_PGOLD[n] = datetime.datetime.strptime(Date_PGOLD[n], '%m/%d/%y').date()\n",
    "    \n",
    "# save Date and ClosePrice\n",
    "np.save('GTCAPDate.npy', Date_GTCAP)\n",
    "np.save('GTCAPClosePrice.npy', ClosePrice_GTCAP)\n",
    "np.save('AGIDate.npy', Date_AGI)\n",
    "np.save('AGIClosePrice.npy', ClosePrice_AGI)\n",
    "np.save('SMDate.npy', Date_SM)\n",
    "np.save('SMClosePrice.npy', ClosePrice_SM)\n",
    "np.save('MERDate.npy', Date_MER)\n",
    "np.save('MERClosePrice.npy', ClosePrice_MER)\n",
    "np.save('ALIDate.npy', Date_ALI)\n",
    "np.save('ALIClosePrice.npy', ClosePrice_ALI)\n",
    "np.save('SECBDate.npy', Date_SECB)\n",
    "np.save('SECBClosePrice.npy', ClosePrice_SECB)\n",
    "np.save('MBTDate.npy', Date_MBT)\n",
    "np.save('MBTClosePrice.npy', ClosePrice_MBT)\n",
    "np.save('TELDate.npy', Date_TEL)\n",
    "np.save('TELClosePrice.npy', ClosePrice_TEL)\n",
    "np.save('URCDate.npy', Date_URC)\n",
    "np.save('URCClosePrice.npy', ClosePrice_URC)\n",
    "np.save('PGOLDDate.npy', Date_PGOLD)\n",
    "np.save('PGOLDClosePrice.npy', ClosePrice_PGOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d00fcad",
   "metadata": {},
   "source": [
    "# Five-letter Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b428d0",
   "metadata": {},
   "source": [
    "# 181 (C) AGI - (Q) MER - (V) TEL - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0197215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_181 = max(min(Date_AGI), min(Date_MER), min(Date_TEL), min(Date_URC), min(Date_PGOLD))\n",
    "end_181 = min(max(Date_AGI), max(Date_MER), max(Date_TEL), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_181_1 = Date_AGI.index(start_181)\n",
    "AGI_181_2 = Date_AGI.index(end_181)\n",
    "\n",
    "MER_181_1 = Date_MER.index(start_181)\n",
    "MER_181_2 = Date_MER.index(end_181)\n",
    "\n",
    "TEL_181_1 = Date_TEL.index(start_181)\n",
    "TEL_181_2 = Date_TEL.index(end_181)\n",
    "\n",
    "URC_181_1 = Date_URC.index(start_181)\n",
    "URC_181_2 = Date_URC.index(end_181)\n",
    "\n",
    "PGOLD_181_1 = Date_PGOLD.index(start_181)\n",
    "PGOLD_181_2 = Date_PGOLD.index(end_181)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C181 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_181_1:AGI_181_2])\n",
    "Q181 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_181_1:MER_181_2])\n",
    "V181 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_181_1:TEL_181_2])\n",
    "ε181 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_181_1:URC_181_2])\n",
    "W181 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_181_1:PGOLD_181_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C181 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q181 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "V181 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε181 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W181 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d72890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_181 = []\n",
    "st_181 = []\n",
    "n = 1\n",
    "while n < len(C181):\n",
    "    sc_181 = ''\n",
    "    if C181[n] > C181[n-1]:\n",
    "        sc_181 = sc_181 + 'C'\n",
    "    if Q181[n] > Q181[n-1]:\n",
    "        sc_181 = sc_181 + 'Q'\n",
    "    if V181[n] > V181[n-1]:\n",
    "        sc_181 = sc_181 + 'V'\n",
    "    if ε181[n] > ε181[n-1]:\n",
    "        sc_181 = sc_181 + 'ε'\n",
    "    if W181[n] > W181[n-1]:\n",
    "        sc_181 = sc_181 + 'W'\n",
    "    if len(sc_181) > 0:\n",
    "        st_181.append(sc_181)\n",
    "    else:\n",
    "        STC_181.append(st_181)\n",
    "        st_181 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_181 = STC_181.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_181 = [ st_181 for st_181 in STC_181 if len(st_181) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_181 = len(C181)\n",
    "lmax_181 = 0\n",
    "for st_181 in STC_181:\n",
    "    if len(st_181) < lmin_181:\n",
    "        lmin_181 = len(st_181)\n",
    "    if len(st_181) > lmax_181:\n",
    "        lmax_181 = len(st_181)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_181 = [ st_181 for st_181 in STC_181 if len(st_181) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_181 = []\n",
    "for n in range(len(STC5_181)):\n",
    "    tc_181 = [ u for u in STC5_181[n][0] ]\n",
    "    for k in range(1, len(STC5_181[n])):\n",
    "        tc_181 = [ u+v for u in tc_181 for v in STC5_181[n][k] ]\n",
    "    TC5_181 = TC5_181 + tc_181\n",
    "setTC5_181 = list(set(TC5_181))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_181 = [ TC5_181.count(setTC5_181[l]) for l in range(len(setTC5_181)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_181 = [ [] for l in range(len(setTC5_181)) ]\n",
    "for s in range(181):\n",
    "    STC5null_181 = [ list(st_181) for st_181 in STC5_181]\n",
    "    for st_181 in STC5null_181:\n",
    "        np.random.shuffle(st_181)\n",
    "    TC5null_181= []\n",
    "    for n in range(len(STC5null_181)):\n",
    "        tc_181 = [ u for u in STC5null_181[n][0] ]\n",
    "        for k in range(1, len(STC5null_181[n])):\n",
    "            tc_181 = [ u+v for u in tc_181 for v in STC5null_181[n][k] ]\n",
    "        TC5null_181= TC5null_181+ tc_181\n",
    "    for l in range(len(setTC5_181)):\n",
    "        if TC5null_181.count(setTC5_181[l]) > 0:\n",
    "            fTC5null_181[l].append(TC5null_181.count(setTC5_181[l]))\n",
    "        else:\n",
    "            fTC5null_181[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a23d734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "εQVVV\n",
      "QQWVQ\n",
      "WVVCW\n",
      "CQVε\n",
      "CWεQ\n",
      "εQVVC\n",
      "WVεWW\n",
      "WVεCW\n",
      "QCCVC\n",
      "CVεQW\n",
      "WQεWC\n",
      "CVWCW\n",
      "CVCCV\n",
      "QεQVQ\n",
      "QεWVε\n",
      "CQVQ\n",
      "CVεCW\n",
      "VW\n",
      "WVVQW\n",
      "WVC\n",
      "QεWVQ\n",
      "QCεVC\n",
      "WVCCW\n",
      "QCWVQ\n",
      "CVCCW\n",
      "εQεVC\n",
      "QCQVC\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_181)):\n",
    "    if sum(freq >= fTC5_181[l] for freq in fTC5null_181[l]) < 5:\n",
    "        print(setTC5_181[l], fTC5_181[l], sum(freq >= fTC5_181[l] for freq in fTC5null_181[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648d22c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "CVεCW\n",
      "QCεVC\n",
      "CVCCW\n",
      "QCQVC\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_181)):\n",
    "    if sum(freq >= fTC5_181[l] for freq in fTC5null_181[l]) < 1:\n",
    "        print(setTC5_181[l], fTC5_181[l], sum(freq >= fTC5_181[l] for freq in fTC5null_181[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d158b410",
   "metadata": {},
   "source": [
    "# 182 (C) AGI - (E) ALI - (Z) SECB - (T) MBT - (V) TEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c644832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_182 = max(min(Date_AGI), min(Date_ALI), min(Date_SECB), min(Date_MBT), min(Date_TEL))\n",
    "end_182 = min(max(Date_AGI), max(Date_ALI), max(Date_SECB), max(Date_MBT), max(Date_TEL))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_182_1 = Date_AGI.index(start_182)\n",
    "AGI_182_2 = Date_AGI.index(end_182)\n",
    "\n",
    "ALI_182_1 = Date_ALI.index(start_182)\n",
    "ALI_182_2 = Date_ALI.index(end_182)\n",
    "\n",
    "SECB_182_1 = Date_SECB.index(start_182)\n",
    "SECB_182_2 = Date_SECB.index(end_182)\n",
    "\n",
    "MBT_182_1 = Date_MBT.index(start_182)\n",
    "MBT_182_2 = Date_MBT.index(end_182)\n",
    "\n",
    "TEL_182_1 = Date_TEL.index(start_182)\n",
    "TEL_182_2 = Date_TEL.index(end_182)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C182 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_182_1:AGI_182_2])\n",
    "E182 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_182_1:ALI_182_2])\n",
    "Z182 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_182_1:SECB_182_2])\n",
    "T182 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_182_1:MBT_182_2])\n",
    "V182 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_182_1:TEL_182_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C182 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "E182 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z182 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T182 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V182 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "387822d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_182 = []\n",
    "st_182 = []\n",
    "n = 1\n",
    "while n < len(C182):\n",
    "    sc_182 = ''\n",
    "    if C182[n] > C182[n-1]:\n",
    "        sc_182 = sc_182 + 'C'\n",
    "    if E182[n] > E182[n-1]:\n",
    "        sc_182 = sc_182 + 'E'\n",
    "    if Z182[n] > Z182[n-1]:\n",
    "        sc_182 = sc_182 + 'Z'\n",
    "    if T182[n] > T182[n-1]:\n",
    "        sc_182 = sc_182 + 'T'\n",
    "    if V182[n] > V182[n-1]:\n",
    "        sc_182 = sc_182 + 'V'\n",
    "    if len(sc_182) > 0:\n",
    "        st_182.append(sc_182)\n",
    "    else:\n",
    "        STC_182.append(st_182)\n",
    "        st_182 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_182 = STC_182.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_182 = [ st_182 for st_182 in STC_182 if len(st_182) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_182 = len(C182)\n",
    "lmax_182 = 0\n",
    "for st_182 in STC_182:\n",
    "    if len(st_182) < lmin_182:\n",
    "        lmin_182 = len(st_182)\n",
    "    if len(st_182) > lmax_182:\n",
    "        lmax_182 = len(st_182)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_182 = [ st_182 for st_182 in STC_182 if len(st_182) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_182 = []\n",
    "for n in range(len(STC5_182)):\n",
    "    tc_182 = [ u for u in STC5_182[n][0] ]\n",
    "    for k in range(1, len(STC5_182[n])):\n",
    "        tc_182 = [ u+v for u in tc_182 for v in STC5_182[n][k] ]\n",
    "    TC5_182 = TC5_182 + tc_182\n",
    "setTC5_182 = list(set(TC5_182))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_182 = [ TC5_182.count(setTC5_182[l]) for l in range(len(setTC5_182)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_182 = [ [] for l in range(len(setTC5_182)) ]\n",
    "for s in range(182):\n",
    "    STC5null_182 = [ list(st_182) for st_182 in STC5_182]\n",
    "    for st_182 in STC5null_182:\n",
    "        np.random.shuffle(st_182)\n",
    "    TC5null_182= []\n",
    "    for n in range(len(STC5null_182)):\n",
    "        tc_182 = [ u for u in STC5null_182[n][0] ]\n",
    "        for k in range(1, len(STC5null_182[n])):\n",
    "            tc_182 = [ u+v for u in tc_182 for v in STC5null_182[n][k] ]\n",
    "        TC5null_182= TC5null_182+ tc_182\n",
    "    for l in range(len(setTC5_182)):\n",
    "        if TC5null_182.count(setTC5_182[l]) > 0:\n",
    "            fTC5null_182[l].append(TC5null_182.count(setTC5_182[l]))\n",
    "        else:\n",
    "            fTC5null_182[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a23e61a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "VVZEZ\n",
      "VEVCT\n",
      "VTZTZ\n",
      "CEVTT\n",
      "VVZZZ\n",
      "TVCTZ\n",
      "ZCEET\n",
      "ZVZ\n",
      "VVVET\n",
      "ZCTCT\n",
      "TVVZT\n",
      "TVVET\n",
      "VEET\n",
      "VVVVT\n",
      "VZZZE\n",
      "VEZE\n",
      "ETT\n",
      "VVVZT\n",
      "CEVCT\n",
      "TEEET\n",
      "TVEZT\n",
      "VVCZE\n",
      "ZEEET\n",
      "EVZ\n",
      "CZTZ\n",
      "EVZZE\n",
      "TEVET\n",
      "VVVCT\n",
      "VVCTZ\n",
      "ETE\n",
      "TEET\n",
      "TEEEV\n",
      "VVCZZ\n",
      "CZTC\n",
      "TVVTT\n",
      "ZCTCC\n",
      "ZTVV\n",
      "VEVTT\n",
      "ZEETT\n",
      "ZTZ\n",
      "ETZ\n",
      "VVZZT\n",
      "VEVVT\n",
      "EZZZE\n",
      "VVVTT\n",
      "ETV\n",
      "TEVTT\n",
      "ZCZTZ\n",
      "CEET\n",
      "VEVCC\n",
      "VVZTZ\n",
      "VVZET\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_182)):\n",
    "    if sum(freq >= fTC5_182[l] for freq in fTC5null_182[l]) < 5:\n",
    "        print(setTC5_182[l], fTC5_182[l], sum(freq >= fTC5_182[l] for freq in fTC5null_182[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48ed98c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "VEVCT\n",
      "VVVZT\n",
      "ETE\n",
      "TVVTT\n",
      "EZZZE\n",
      "ETV\n",
      "VVZTZ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_182)):\n",
    "    if sum(freq >= fTC5_182[l] for freq in fTC5null_182[l]) < 1:\n",
    "        print(setTC5_182[l], fTC5_182[l], sum(freq >= fTC5_182[l] for freq in fTC5null_182[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91c2d48",
   "metadata": {},
   "source": [
    "# 183 (C) AGI - (E) ALI - (Z) SECB - (T) MBT - (ε) URC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40e8233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_183 = max(min(Date_AGI), min(Date_ALI), min(Date_SECB), min(Date_MBT), min(Date_URC))\n",
    "end_183 = min(max(Date_AGI), max(Date_ALI), max(Date_SECB), max(Date_MBT), max(Date_URC))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_183_1 = Date_AGI.index(start_183)\n",
    "AGI_183_2 = Date_AGI.index(end_183)\n",
    "\n",
    "ALI_183_1 = Date_ALI.index(start_183)\n",
    "ALI_183_2 = Date_ALI.index(end_183)\n",
    "\n",
    "SECB_183_1 = Date_SECB.index(start_183)\n",
    "SECB_183_2 = Date_SECB.index(end_183)\n",
    "\n",
    "MBT_183_1 = Date_MBT.index(start_183)\n",
    "MBT_183_2 = Date_MBT.index(end_183)\n",
    "\n",
    "URC_183_1 = Date_URC.index(start_183)\n",
    "URC_183_2 = Date_URC.index(end_183)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C183 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_183_1:AGI_183_2])\n",
    "E183 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_183_1:ALI_183_2])\n",
    "Z183 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_183_1:SECB_183_2])\n",
    "T183 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_183_1:MBT_183_2])\n",
    "ε183 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_183_1:URC_183_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C183 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "E183 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z183 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T183 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε183 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fac0c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_183 = []\n",
    "st_183 = []\n",
    "n = 1\n",
    "while n < len(C183):\n",
    "    sc_183 = ''\n",
    "    if C183[n] > C183[n-1]:\n",
    "        sc_183 = sc_183 + 'C'\n",
    "    if E183[n] > E183[n-1]:\n",
    "        sc_183 = sc_183 + 'E'\n",
    "    if Z183[n] > Z183[n-1]:\n",
    "        sc_183 = sc_183 + 'Z'\n",
    "    if T183[n] > T183[n-1]:\n",
    "        sc_183 = sc_183 + 'T'\n",
    "    if ε183[n] > ε183[n-1]:\n",
    "        sc_183 = sc_183 + 'ε'\n",
    "    if len(sc_183) > 0:\n",
    "        st_183.append(sc_183)\n",
    "    else:\n",
    "        STC_183.append(st_183)\n",
    "        st_183 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_183 = STC_183.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_183 = [ st_183 for st_183 in STC_183 if len(st_183) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_183 = len(C183)\n",
    "lmax_183 = 0\n",
    "for st_183 in STC_183:\n",
    "    if len(st_183) < lmin_183:\n",
    "        lmin_183 = len(st_183)\n",
    "    if len(st_183) > lmax_183:\n",
    "        lmax_183 = len(st_183)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_183 = [ st_183 for st_183 in STC_183 if len(st_183) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_183 = []\n",
    "for n in range(len(STC5_183)):\n",
    "    tc_183 = [ u for u in STC5_183[n][0] ]\n",
    "    for k in range(1, len(STC5_183[n])):\n",
    "        tc_183 = [ u+v for u in tc_183 for v in STC5_183[n][k] ]\n",
    "    TC5_183 = TC5_183 + tc_183\n",
    "setTC5_183 = list(set(TC5_183))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_183 = [ TC5_183.count(setTC5_183[l]) for l in range(len(setTC5_183)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_183 = [ [] for l in range(len(setTC5_183)) ]\n",
    "for s in range(183):\n",
    "    STC5null_183 = [ list(st_183) for st_183 in STC5_183]\n",
    "    for st_183 in STC5null_183:\n",
    "        np.random.shuffle(st_183)\n",
    "    TC5null_183= []\n",
    "    for n in range(len(STC5null_183)):\n",
    "        tc_183 = [ u for u in STC5null_183[n][0] ]\n",
    "        for k in range(1, len(STC5null_183[n])):\n",
    "            tc_183 = [ u+v for u in tc_183 for v in STC5null_183[n][k] ]\n",
    "        TC5null_183= TC5null_183+ tc_183\n",
    "    for l in range(len(setTC5_183)):\n",
    "        if TC5null_183.count(setTC5_183[l]) > 0:\n",
    "            fTC5null_183[l].append(TC5null_183.count(setTC5_183[l]))\n",
    "        else:\n",
    "            fTC5null_183[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0a50a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "εZTC\n",
      "CCεZZ\n",
      "CTC\n",
      "ETε\n",
      "ZCEET\n",
      "CZεεZ\n",
      "TTεEε\n",
      "TZεεE\n",
      "ETT\n",
      "εETC\n",
      "TεTTε\n",
      "ZCETT\n",
      "ETE\n",
      "TεCE\n",
      "TZZTε\n",
      "TεεεE\n",
      "ZEETT\n",
      "ZTZ\n",
      "ETCEε\n",
      "EZZZE\n",
      "ZCETZ\n",
      "ETC\n",
      "εEZε\n",
      "CCETZ\n",
      "TTZEε\n",
      "TεZTε\n",
      "ZEETZ\n",
      "εCCε\n",
      "ZCZTε\n",
      "TEεεE\n",
      "TTZTε\n",
      "TεεTε\n",
      "εεTC\n",
      "ZTEZT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_183)):\n",
    "    if sum(freq >= fTC5_183[l] for freq in fTC5null_183[l]) < 5:\n",
    "        print(setTC5_183[l], fTC5_183[l], sum(freq >= fTC5_183[l] for freq in fTC5null_183[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d419dbed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "ETE\n",
      "TεCE\n",
      "ZEETT\n",
      "EZZZE\n",
      "TTZEε\n",
      "εεTC\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_183)):\n",
    "    if sum(freq >= fTC5_183[l] for freq in fTC5null_183[l]) < 1:\n",
    "        print(setTC5_183[l], fTC5_183[l], sum(freq >= fTC5_183[l] for freq in fTC5null_183[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1350107",
   "metadata": {},
   "source": [
    "# 184 (C) AGI - (E) ALI - (Z) SECB - (T) MBT - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cee879c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_184 = max(min(Date_AGI), min(Date_ALI), min(Date_SECB), min(Date_MBT), min(Date_PGOLD))\n",
    "end_184 = min(max(Date_AGI), max(Date_ALI), max(Date_SECB), max(Date_MBT), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_184_1 = Date_AGI.index(start_184)\n",
    "AGI_184_2 = Date_AGI.index(end_184)\n",
    "\n",
    "ALI_184_1 = Date_ALI.index(start_184)\n",
    "ALI_184_2 = Date_ALI.index(end_184)\n",
    "\n",
    "SECB_184_1 = Date_SECB.index(start_184)\n",
    "SECB_184_2 = Date_SECB.index(end_184)\n",
    "\n",
    "MBT_184_1 = Date_MBT.index(start_184)\n",
    "MBT_184_2 = Date_MBT.index(end_184)\n",
    "\n",
    "PGOLD_184_1 = Date_PGOLD.index(start_184)\n",
    "PGOLD_184_2 = Date_PGOLD.index(end_184)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C184 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_184_1:AGI_184_2])\n",
    "E184 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_184_1:ALI_184_2])\n",
    "Z184 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_184_1:SECB_184_2])\n",
    "T184 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_184_1:MBT_184_2])\n",
    "W184 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_184_1:PGOLD_184_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C184 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "E184 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z184 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T184 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "W184 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b36c860c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_184 = []\n",
    "st_184 = []\n",
    "n = 1\n",
    "while n < len(C184):\n",
    "    sc_184 = ''\n",
    "    if C184[n] > C184[n-1]:\n",
    "        sc_184 = sc_184 + 'C'\n",
    "    if E184[n] > E184[n-1]:\n",
    "        sc_184 = sc_184 + 'E'\n",
    "    if Z184[n] > Z184[n-1]:\n",
    "        sc_184 = sc_184 + 'Z'\n",
    "    if T184[n] > T184[n-1]:\n",
    "        sc_184 = sc_184 + 'T'\n",
    "    if W184[n] > W184[n-1]:\n",
    "        sc_184 = sc_184 + 'W'\n",
    "    if len(sc_184) > 0:\n",
    "        st_184.append(sc_184)\n",
    "    else:\n",
    "        STC_184.append(st_184)\n",
    "        st_184 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_184 = STC_184.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_184 = [ st_184 for st_184 in STC_184 if len(st_184) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_184 = len(C184)\n",
    "lmax_184 = 0\n",
    "for st_184 in STC_184:\n",
    "    if len(st_184) < lmin_184:\n",
    "        lmin_184 = len(st_184)\n",
    "    if len(st_184) > lmax_184:\n",
    "        lmax_184 = len(st_184)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_184 = [ st_184 for st_184 in STC_184 if len(st_184) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_184 = []\n",
    "for n in range(len(STC5_184)):\n",
    "    tc_184 = [ u for u in STC5_184[n][0] ]\n",
    "    for k in range(1, len(STC5_184[n])):\n",
    "        tc_184 = [ u+v for u in tc_184 for v in STC5_184[n][k] ]\n",
    "    TC5_184 = TC5_184 + tc_184\n",
    "setTC5_184 = list(set(TC5_184))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_184 = [ TC5_184.count(setTC5_184[l]) for l in range(len(setTC5_184)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_184 = [ [] for l in range(len(setTC5_184)) ]\n",
    "for s in range(184):\n",
    "    STC5null_184 = [ list(st_184) for st_184 in STC5_184]\n",
    "    for st_184 in STC5null_184:\n",
    "        np.random.shuffle(st_184)\n",
    "    TC5null_184= []\n",
    "    for n in range(len(STC5null_184)):\n",
    "        tc_184 = [ u for u in STC5null_184[n][0] ]\n",
    "        for k in range(1, len(STC5null_184[n])):\n",
    "            tc_184 = [ u+v for u in tc_184 for v in STC5null_184[n][k] ]\n",
    "        TC5null_184= TC5null_184+ tc_184\n",
    "    for l in range(len(setTC5_184)):\n",
    "        if TC5null_184.count(setTC5_184[l]) > 0:\n",
    "            fTC5null_184[l].append(TC5null_184.count(setTC5_184[l]))\n",
    "        else:\n",
    "            fTC5null_184[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06b2a025",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "WZEWW\n",
      "WTZE\n",
      "ZZCWE\n",
      "TZCWE\n",
      "WTE\n",
      "WCEWW\n",
      "WEZC\n",
      "EZEWE\n",
      "WTZT\n",
      "WZZWE\n",
      "ZZEWE\n",
      "WCTWW\n",
      "WZEWE\n",
      "ETWTC\n",
      "WEEWE\n",
      "WCZWW\n",
      "WZTWW\n",
      "WTZWE\n",
      "WEEC\n",
      "WEZT\n",
      "CTZ\n",
      "ZZTCC\n",
      "TCWW\n",
      "TCZZ\n",
      "WEZE\n",
      "WEZZ\n",
      "WZEWC\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_184)):\n",
    "    if sum(freq >= fTC5_184[l] for freq in fTC5null_184[l]) < 5:\n",
    "        print(setTC5_184[l], fTC5_184[l], sum(freq >= fTC5_184[l] for freq in fTC5null_184[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3707c6bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "WZEWW\n",
      "WTZT\n",
      "WZTWW\n",
      "WEZT\n",
      "ZZTCC\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_184)):\n",
    "    if sum(freq >= fTC5_184[l] for freq in fTC5null_184[l]) < 1:\n",
    "        print(setTC5_184[l], fTC5_184[l], sum(freq >= fTC5_184[l] for freq in fTC5null_184[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef4887f",
   "metadata": {},
   "source": [
    "# 185 (C) AGI - (E) ALI - (Z) SECB - (V) TEL - (ε) URC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de284cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_185 = max(min(Date_AGI), min(Date_ALI), min(Date_SECB), min(Date_TEL), min(Date_URC))\n",
    "end_185 = min(max(Date_AGI), max(Date_ALI), max(Date_SECB), max(Date_TEL), max(Date_URC))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_185_1 = Date_AGI.index(start_185)\n",
    "AGI_185_2 = Date_AGI.index(end_185)\n",
    "\n",
    "ALI_185_1 = Date_ALI.index(start_185)\n",
    "ALI_185_2 = Date_ALI.index(end_185)\n",
    "\n",
    "SECB_185_1 = Date_SECB.index(start_185)\n",
    "SECB_185_2 = Date_SECB.index(end_185)\n",
    "\n",
    "TEL_185_1 = Date_TEL.index(start_185)\n",
    "TEL_185_2 = Date_TEL.index(end_185)\n",
    "\n",
    "URC_185_1 = Date_URC.index(start_185)\n",
    "URC_185_2 = Date_URC.index(end_185)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C185 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_185_1:AGI_185_2])\n",
    "E185 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_185_1:ALI_185_2])\n",
    "Z185 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_185_1:SECB_185_2])\n",
    "V185 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_185_1:TEL_185_2])\n",
    "ε185 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_185_1:URC_185_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C185 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "E185 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z185 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "V185 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε185 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f50d64b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_185 = []\n",
    "st_185 = []\n",
    "n = 1\n",
    "while n < len(C185):\n",
    "    sc_185 = ''\n",
    "    if C185[n] > C185[n-1]:\n",
    "        sc_185 = sc_185 + 'C'\n",
    "    if E185[n] > E185[n-1]:\n",
    "        sc_185 = sc_185 + 'E'\n",
    "    if Z185[n] > Z185[n-1]:\n",
    "        sc_185 = sc_185 + 'Z'\n",
    "    if V185[n] > V185[n-1]:\n",
    "        sc_185 = sc_185 + 'V'\n",
    "    if ε185[n] > ε185[n-1]:\n",
    "        sc_185 = sc_185 + 'ε'\n",
    "    if len(sc_185) > 0:\n",
    "        st_185.append(sc_185)\n",
    "    else:\n",
    "        STC_185.append(st_185)\n",
    "        st_185 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_185 = STC_185.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_185 = [ st_185 for st_185 in STC_185 if len(st_185) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_185 = len(C185)\n",
    "lmax_185 = 0\n",
    "for st_185 in STC_185:\n",
    "    if len(st_185) < lmin_185:\n",
    "        lmin_185 = len(st_185)\n",
    "    if len(st_185) > lmax_185:\n",
    "        lmax_185 = len(st_185)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_185 = [ st_185 for st_185 in STC_185 if len(st_185) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_185 = []\n",
    "for n in range(len(STC5_185)):\n",
    "    tc_185 = [ u for u in STC5_185[n][0] ]\n",
    "    for k in range(1, len(STC5_185[n])):\n",
    "        tc_185 = [ u+v for u in tc_185 for v in STC5_185[n][k] ]\n",
    "    TC5_185 = TC5_185 + tc_185\n",
    "setTC5_185 = list(set(TC5_185))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_185 = [ TC5_185.count(setTC5_185[l]) for l in range(len(setTC5_185)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_185 = [ [] for l in range(len(setTC5_185)) ]\n",
    "for s in range(185):\n",
    "    STC5null_185 = [ list(st_185) for st_185 in STC5_185]\n",
    "    for st_185 in STC5null_185:\n",
    "        np.random.shuffle(st_185)\n",
    "    TC5null_185= []\n",
    "    for n in range(len(STC5null_185)):\n",
    "        tc_185 = [ u for u in STC5null_185[n][0] ]\n",
    "        for k in range(1, len(STC5null_185[n])):\n",
    "            tc_185 = [ u+v for u in tc_185 for v in STC5null_185[n][k] ]\n",
    "        TC5null_185= TC5null_185+ tc_185\n",
    "    for l in range(len(setTC5_185)):\n",
    "        if TC5null_185.count(setTC5_185[l]) > 0:\n",
    "            fTC5null_185[l].append(TC5null_185.count(setTC5_185[l]))\n",
    "        else:\n",
    "            fTC5null_185[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2cca5ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "εVEZV\n",
      "εEEC\n",
      "CEεEV\n",
      "EEVε\n",
      "εECEV\n",
      "εZZCε\n",
      "VVCV\n",
      "εεCεV\n",
      "εZZZV\n",
      "ZEEVZ\n",
      "εZCεV\n",
      "EEEEV\n",
      "εεZZV\n",
      "εεCZV\n",
      "εεCε\n",
      "CZCZV\n",
      "εVCCV\n",
      "CZεEV\n",
      "εZZEV\n",
      "εεCCV\n",
      "εVVZE\n",
      "CVVCV\n",
      "CVZZV\n",
      "CZZCε\n",
      "CεZZV\n",
      "CVεCV\n",
      "VEEEV\n",
      "CZVCV\n",
      "εEEE\n",
      "εεVε\n",
      "CZZZE\n",
      "εCCεV\n",
      "VVCZE\n",
      "CZCZE\n",
      "EVZZE\n",
      "εEEε\n",
      "εZCZV\n",
      "CEEEV\n",
      "CZVVV\n",
      "εVεZE\n",
      "CεCZV\n",
      "εVVεE\n",
      "εVCZV\n",
      "CVCCV\n",
      "εZCZE\n",
      "CZCCV\n",
      "εεCZE\n",
      "εVCZE\n",
      "CEVEV\n",
      "VEVEV\n",
      "εEZE\n",
      "εZZVε\n",
      "CVεEV\n",
      "εECZV\n",
      "EEVEV\n",
      "CZCεV\n",
      "EEZZE\n",
      "CVVZV\n",
      "εVEZE\n",
      "CZZZε\n",
      "εEεZV\n",
      "εZCCV\n",
      "εEεEV\n",
      "εEVε\n",
      "CEεCV\n",
      "CZZZV\n",
      "CVεZV\n",
      "εVCEV\n",
      "εVVEV\n",
      "εεVZV\n",
      "εEZε\n",
      "ECEEV\n",
      "εVεZV\n",
      "EEZEV\n",
      "CECEV\n",
      "εCVε\n",
      "εVVZV\n",
      "EEεEV\n",
      "εCCZV\n",
      "CEZEV\n",
      "εEVE\n",
      "CεVZV\n",
      "εVεEV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_185)):\n",
    "    if sum(freq >= fTC5_185[l] for freq in fTC5null_185[l]) < 5:\n",
    "        print(setTC5_185[l], fTC5_185[l], sum(freq >= fTC5_185[l] for freq in fTC5null_185[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf217933",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "CEεEV\n",
      "εεCZV\n",
      "εεCε\n",
      "εVCCV\n",
      "εVVZE\n",
      "CZZZE\n",
      "εZCZV\n",
      "εVCZV\n",
      "εZCZE\n",
      "εεCZE\n",
      "εVCZE\n",
      "EEZZE\n",
      "εVEZE\n",
      "εZCCV\n",
      "εVVZV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_185)):\n",
    "    if sum(freq >= fTC5_185[l] for freq in fTC5null_185[l]) < 1:\n",
    "        print(setTC5_185[l], fTC5_185[l], sum(freq >= fTC5_185[l] for freq in fTC5null_185[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b692a797",
   "metadata": {},
   "source": [
    "# 186 (C) AGI - (E) ALI - (Z) SECB - (V) TEL - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "989ed7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_186 = max(min(Date_AGI), min(Date_ALI), min(Date_SECB), min(Date_TEL), min(Date_PGOLD))\n",
    "end_186 = min(max(Date_AGI), max(Date_ALI), max(Date_SECB), max(Date_TEL), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_186_1 = Date_AGI.index(start_186)\n",
    "AGI_186_2 = Date_AGI.index(end_186)\n",
    "\n",
    "ALI_186_1 = Date_ALI.index(start_186)\n",
    "ALI_186_2 = Date_ALI.index(end_186)\n",
    "\n",
    "SECB_186_1 = Date_SECB.index(start_186)\n",
    "SECB_186_2 = Date_SECB.index(end_186)\n",
    "\n",
    "TEL_186_1 = Date_TEL.index(start_186)\n",
    "TEL_186_2 = Date_TEL.index(end_186)\n",
    "\n",
    "PGOLD_186_1 = Date_PGOLD.index(start_186)\n",
    "PGOLD_186_2 = Date_PGOLD.index(end_186)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C186 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_186_1:AGI_186_2])\n",
    "E186 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_186_1:ALI_186_2])\n",
    "Z186 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_186_1:SECB_186_2])\n",
    "V186 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_186_1:TEL_186_2])\n",
    "W186 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_186_1:PGOLD_186_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C186 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "E186 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z186 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "V186 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "W186 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29f9b4ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_186 = []\n",
    "st_186 = []\n",
    "n = 1\n",
    "while n < len(C186):\n",
    "    sc_186 = ''\n",
    "    if C186[n] > C186[n-1]:\n",
    "        sc_186 = sc_186 + 'C'\n",
    "    if E186[n] > E186[n-1]:\n",
    "        sc_186 = sc_186 + 'E'\n",
    "    if Z186[n] > Z186[n-1]:\n",
    "        sc_186 = sc_186 + 'Z'\n",
    "    if V186[n] > V186[n-1]:\n",
    "        sc_186 = sc_186 + 'V'\n",
    "    if W186[n] > W186[n-1]:\n",
    "        sc_186 = sc_186 + 'W'\n",
    "    if len(sc_186) > 0:\n",
    "        st_186.append(sc_186)\n",
    "    else:\n",
    "        STC_186.append(st_186)\n",
    "        st_186 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_186 = STC_186.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_186 = [ st_186 for st_186 in STC_186 if len(st_186) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_186 = len(C186)\n",
    "lmax_186 = 0\n",
    "for st_186 in STC_186:\n",
    "    if len(st_186) < lmin_186:\n",
    "        lmin_186 = len(st_186)\n",
    "    if len(st_186) > lmax_186:\n",
    "        lmax_186 = len(st_186)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_186 = [ st_186 for st_186 in STC_186 if len(st_186) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_186 = []\n",
    "for n in range(len(STC5_186)):\n",
    "    tc_186 = [ u for u in STC5_186[n][0] ]\n",
    "    for k in range(1, len(STC5_186[n])):\n",
    "        tc_186 = [ u+v for u in tc_186 for v in STC5_186[n][k] ]\n",
    "    TC5_186 = TC5_186 + tc_186\n",
    "setTC5_186 = list(set(TC5_186))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_186 = [ TC5_186.count(setTC5_186[l]) for l in range(len(setTC5_186)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_186 = [ [] for l in range(len(setTC5_186)) ]\n",
    "for s in range(186):\n",
    "    STC5null_186 = [ list(st_186) for st_186 in STC5_186]\n",
    "    for st_186 in STC5null_186:\n",
    "        np.random.shuffle(st_186)\n",
    "    TC5null_186= []\n",
    "    for n in range(len(STC5null_186)):\n",
    "        tc_186 = [ u for u in STC5null_186[n][0] ]\n",
    "        for k in range(1, len(STC5null_186[n])):\n",
    "            tc_186 = [ u+v for u in tc_186 for v in STC5null_186[n][k] ]\n",
    "        TC5null_186= TC5null_186+ tc_186\n",
    "    for l in range(len(setTC5_186)):\n",
    "        if TC5null_186.count(setTC5_186[l]) > 0:\n",
    "            fTC5null_186[l].append(TC5null_186.count(setTC5_186[l]))\n",
    "        else:\n",
    "            fTC5null_186[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94a73c3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "CEZCV\n",
      "VEWZV\n",
      "ZVVZV\n",
      "WCEWW\n",
      "WCV\n",
      "CEVZW\n",
      "EEVWZ\n",
      "CVVZW\n",
      "WEWZV\n",
      "WZVWE\n",
      "WVEWW\n",
      "CCZZV\n",
      "CEVCW\n",
      "VEVC\n",
      "ECZZV\n",
      "WCVWW\n",
      "WVVWE\n",
      "CEVEV\n",
      "VVWW\n",
      "VCWW\n",
      "CVVZV\n",
      "WCEWZ\n",
      "WCVWZ\n",
      "VEWEV\n",
      "CEVCV\n",
      "CEVCC\n",
      "ZEWZV\n",
      "ECEZC\n",
      "ECVZV\n",
      "WCEZC\n",
      "WCVWE\n",
      "ECEWC\n",
      "CEZEV\n",
      "ZCVZV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_186)):\n",
    "    if sum(freq >= fTC5_186[l] for freq in fTC5null_186[l]) < 5:\n",
    "        print(setTC5_186[l], fTC5_186[l], sum(freq >= fTC5_186[l] for freq in fTC5null_186[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86df6880",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "CVVZW\n",
      "WEWZV\n",
      "WZVWE\n",
      "CCZZV\n",
      "CEVCW\n",
      "CEVCV\n",
      "WCVWE\n",
      "ZCVZV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_186)):\n",
    "    if sum(freq >= fTC5_186[l] for freq in fTC5null_186[l]) < 1:\n",
    "        print(setTC5_186[l], fTC5_186[l], sum(freq >= fTC5_186[l] for freq in fTC5null_186[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa85140",
   "metadata": {},
   "source": [
    "# 187 (C) AGI - (E) ALI - (Z) SECB - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "564c8f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_187 = max(min(Date_AGI), min(Date_ALI), min(Date_SECB), min(Date_URC), min(Date_PGOLD))\n",
    "end_187 = min(max(Date_AGI), max(Date_ALI), max(Date_SECB), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_187_1 = Date_AGI.index(start_187)\n",
    "AGI_187_2 = Date_AGI.index(end_187)\n",
    "\n",
    "ALI_187_1 = Date_ALI.index(start_187)\n",
    "ALI_187_2 = Date_ALI.index(end_187)\n",
    "\n",
    "SECB_187_1 = Date_SECB.index(start_187)\n",
    "SECB_187_2 = Date_SECB.index(end_187)\n",
    "\n",
    "URC_187_1 = Date_URC.index(start_187)\n",
    "URC_187_2 = Date_URC.index(end_187)\n",
    "\n",
    "PGOLD_187_1 = Date_PGOLD.index(start_187)\n",
    "PGOLD_187_2 = Date_PGOLD.index(end_187)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C187 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_187_1:AGI_187_2])\n",
    "E187 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_187_1:ALI_187_2])\n",
    "Z187 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_187_1:SECB_187_2])\n",
    "ε187 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_187_1:URC_187_2])\n",
    "W187 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_187_1:PGOLD_187_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C187 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "E187 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z187 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε187 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W187 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be796ad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_187 = []\n",
    "st_187 = []\n",
    "n = 1\n",
    "while n < len(C187):\n",
    "    sc_187 = ''\n",
    "    if C187[n] > C187[n-1]:\n",
    "        sc_187 = sc_187 + 'C'\n",
    "    if E187[n] > E187[n-1]:\n",
    "        sc_187 = sc_187 + 'E'\n",
    "    if Z187[n] > Z187[n-1]:\n",
    "        sc_187 = sc_187 + 'Z'\n",
    "    if ε187[n] > ε187[n-1]:\n",
    "        sc_187 = sc_187 + 'ε'\n",
    "    if W187[n] > W187[n-1]:\n",
    "        sc_187 = sc_187 + 'W'\n",
    "    if len(sc_187) > 0:\n",
    "        st_187.append(sc_187)\n",
    "    else:\n",
    "        STC_187.append(st_187)\n",
    "        st_187 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_187 = STC_187.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_187 = [ st_187 for st_187 in STC_187 if len(st_187) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_187 = len(C187)\n",
    "lmax_187 = 0\n",
    "for st_187 in STC_187:\n",
    "    if len(st_187) < lmin_187:\n",
    "        lmin_187 = len(st_187)\n",
    "    if len(st_187) > lmax_187:\n",
    "        lmax_187 = len(st_187)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_187 = [ st_187 for st_187 in STC_187 if len(st_187) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_187 = []\n",
    "for n in range(len(STC5_187)):\n",
    "    tc_187 = [ u for u in STC5_187[n][0] ]\n",
    "    for k in range(1, len(STC5_187[n])):\n",
    "        tc_187 = [ u+v for u in tc_187 for v in STC5_187[n][k] ]\n",
    "    TC5_187 = TC5_187 + tc_187\n",
    "setTC5_187 = list(set(TC5_187))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_187 = [ TC5_187.count(setTC5_187[l]) for l in range(len(setTC5_187)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_187 = [ [] for l in range(len(setTC5_187)) ]\n",
    "for s in range(187):\n",
    "    STC5null_187 = [ list(st_187) for st_187 in STC5_187]\n",
    "    for st_187 in STC5null_187:\n",
    "        np.random.shuffle(st_187)\n",
    "    TC5null_187= []\n",
    "    for n in range(len(STC5null_187)):\n",
    "        tc_187 = [ u for u in STC5null_187[n][0] ]\n",
    "        for k in range(1, len(STC5null_187[n])):\n",
    "            tc_187 = [ u+v for u in tc_187 for v in STC5null_187[n][k] ]\n",
    "        TC5null_187= TC5null_187+ tc_187\n",
    "    for l in range(len(setTC5_187)):\n",
    "        if TC5null_187.count(setTC5_187[l]) > 0:\n",
    "            fTC5null_187[l].append(TC5null_187.count(setTC5_187[l]))\n",
    "        else:\n",
    "            fTC5null_187[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26ae6faa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "WεεWE\n",
      "εZCεZ\n",
      "WCEWW\n",
      "WεEWW\n",
      "WEZC\n",
      "WEεZW\n",
      "εECC\n",
      "WεZWE\n",
      "CZεZE\n",
      "ECε\n",
      "εεCε\n",
      "WεεWW\n",
      "EZεZC\n",
      "EZεεE\n",
      "EZεWε\n",
      "CZεεE\n",
      "ECεZW\n",
      "EZεZE\n",
      "EWεWε\n",
      "EZεεW\n",
      "EZεWE\n",
      "WCεWW\n",
      "WZεWW\n",
      "CEZCW\n",
      "CEεZW\n",
      "ECEWC\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_187)):\n",
    "    if sum(freq >= fTC5_187[l] for freq in fTC5null_187[l]) < 5:\n",
    "        print(setTC5_187[l], fTC5_187[l], sum(freq >= fTC5_187[l] for freq in fTC5null_187[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b95c5bdb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "ECε\n",
      "εεCε\n",
      "CZεεE\n",
      "CEεZW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_187)):\n",
    "    if sum(freq >= fTC5_187[l] for freq in fTC5null_187[l]) < 1:\n",
    "        print(setTC5_187[l], fTC5_187[l], sum(freq >= fTC5_187[l] for freq in fTC5null_187[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed2ade9",
   "metadata": {},
   "source": [
    "# 188 (C) AGI - (E) ALI - (T) MBT- (V) TEL - (ε) URC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58700213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_188 = max(min(Date_AGI), min(Date_ALI), min(Date_MBT), min(Date_TEL), min(Date_URC))\n",
    "end_188 = min(max(Date_AGI), max(Date_ALI), max(Date_MBT), max(Date_TEL), max(Date_URC))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_188_1 = Date_AGI.index(start_188)\n",
    "AGI_188_2 = Date_AGI.index(end_188)\n",
    "\n",
    "ALI_188_1 = Date_ALI.index(start_188)\n",
    "ALI_188_2 = Date_ALI.index(end_188)\n",
    "\n",
    "MBT_188_1 = Date_MBT.index(start_188)\n",
    "MBT_188_2 = Date_MBT.index(end_188)\n",
    "\n",
    "TEL_188_1 = Date_TEL.index(start_188)\n",
    "TEL_188_2 = Date_TEL.index(end_188)\n",
    "\n",
    "URC_188_1 = Date_URC.index(start_188)\n",
    "URC_188_2 = Date_URC.index(end_188)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C188 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_188_1:AGI_188_2])\n",
    "E188 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_188_1:ALI_188_2])\n",
    "T188 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_188_1:MBT_188_2])\n",
    "V188 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_188_1:TEL_188_2])\n",
    "ε188 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_188_1:URC_188_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C188 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "E188 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "T188 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V188 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε188 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c141441b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_188 = []\n",
    "st_188 = []\n",
    "n = 1\n",
    "while n < len(C188):\n",
    "    sc_188 = ''\n",
    "    if C188[n] > C188[n-1]:\n",
    "        sc_188 = sc_188 + 'C'\n",
    "    if E188[n] > E188[n-1]:\n",
    "        sc_188 = sc_188 + 'E'\n",
    "    if T188[n] > T188[n-1]:\n",
    "        sc_188 = sc_188 + 'T'\n",
    "    if V188[n] > V188[n-1]:\n",
    "        sc_188 = sc_188 + 'V'\n",
    "    if ε188[n] > ε188[n-1]:\n",
    "        sc_188 = sc_188 + 'ε'\n",
    "    if len(sc_188) > 0:\n",
    "        st_188.append(sc_188)\n",
    "    else:\n",
    "        STC_188.append(st_188)\n",
    "        st_188 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_188 = STC_188.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_188 = [ st_188 for st_188 in STC_188 if len(st_188) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_188 = len(C188)\n",
    "lmax_188 = 0\n",
    "for st_188 in STC_188:\n",
    "    if len(st_188) < lmin_188:\n",
    "        lmin_188 = len(st_188)\n",
    "    if len(st_188) > lmax_188:\n",
    "        lmax_188 = len(st_188)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_188 = [ st_188 for st_188 in STC_188 if len(st_188) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_188 = []\n",
    "for n in range(len(STC5_188)):\n",
    "    tc_188 = [ u for u in STC5_188[n][0] ]\n",
    "    for k in range(1, len(STC5_188[n])):\n",
    "        tc_188 = [ u+v for u in tc_188 for v in STC5_188[n][k] ]\n",
    "    TC5_188 = TC5_188 + tc_188\n",
    "setTC5_188 = list(set(TC5_188))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_188 = [ TC5_188.count(setTC5_188[l]) for l in range(len(setTC5_188)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_188 = [ [] for l in range(len(setTC5_188)) ]\n",
    "for s in range(188):\n",
    "    STC5null_188 = [ list(st_188) for st_188 in STC5_188]\n",
    "    for st_188 in STC5null_188:\n",
    "        np.random.shuffle(st_188)\n",
    "    TC5null_188= []\n",
    "    for n in range(len(STC5null_188)):\n",
    "        tc_188 = [ u for u in STC5null_188[n][0] ]\n",
    "        for k in range(1, len(STC5null_188[n])):\n",
    "            tc_188 = [ u+v for u in tc_188 for v in STC5null_188[n][k] ]\n",
    "        TC5null_188= TC5null_188+ tc_188\n",
    "    for l in range(len(setTC5_188)):\n",
    "        if TC5null_188.count(setTC5_188[l]) > 0:\n",
    "            fTC5null_188[l].append(TC5null_188.count(setTC5_188[l]))\n",
    "        else:\n",
    "            fTC5null_188[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14589aca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "εETVε\n",
      "VCVET\n",
      "VC\n",
      "εETVT\n",
      "TCEVT\n",
      "ECεEV\n",
      "εVCTε\n",
      "EEEEV\n",
      "εECVT\n",
      "VVVET\n",
      "εVCCC\n",
      "VEET\n",
      "εεTTε\n",
      "VVVVT\n",
      "EEEVT\n",
      "VEEEV\n",
      "εEEE\n",
      "CεTTε\n",
      "εεTVT\n",
      "εCTCE\n",
      "CCVT\n",
      "VCεEV\n",
      "εETTT\n",
      "εεCVε\n",
      "εεTVε\n",
      "TCEET\n",
      "TEEEV\n",
      "TVCCC\n",
      "CVET\n",
      "TCTTT\n",
      "VEVT\n",
      "CεTVε\n",
      "CεE\n",
      "εεCVT\n",
      "εεCTε\n",
      "CTεT\n",
      "VCVVT\n",
      "TEEVT\n",
      "VεEVT\n",
      "VVVTT\n",
      "εVVTT\n",
      "CEET\n",
      "εVCTT\n",
      "εVCTC\n",
      "TCTVT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_188)):\n",
    "    if sum(freq >= fTC5_188[l] for freq in fTC5null_188[l]) < 5:\n",
    "        print(setTC5_188[l], fTC5_188[l], sum(freq >= fTC5_188[l] for freq in fTC5null_188[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "561aaee3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "VCVET\n",
      "TCEVT\n",
      "EEEEV\n",
      "TVCCC\n",
      "VVVTT\n",
      "CEET\n",
      "εVCTT\n",
      "TCTVT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_188)):\n",
    "    if sum(freq >= fTC5_188[l] for freq in fTC5null_188[l]) < 1:\n",
    "        print(setTC5_188[l], fTC5_188[l], sum(freq >= fTC5_188[l] for freq in fTC5null_188[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a783143",
   "metadata": {},
   "source": [
    "# 189 (C) AGI - (E) ALI - (T) MBT- (V) TEL - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "111cf076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_189 = max(min(Date_AGI), min(Date_ALI), min(Date_MBT), min(Date_TEL), min(Date_PGOLD))\n",
    "end_189 = min(max(Date_AGI), max(Date_ALI), max(Date_MBT), max(Date_TEL), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_189_1 = Date_AGI.index(start_189)\n",
    "AGI_189_2 = Date_AGI.index(end_189)\n",
    "\n",
    "ALI_189_1 = Date_ALI.index(start_189)\n",
    "ALI_189_2 = Date_ALI.index(end_189)\n",
    "\n",
    "MBT_189_1 = Date_MBT.index(start_189)\n",
    "MBT_189_2 = Date_MBT.index(end_189)\n",
    "\n",
    "TEL_189_1 = Date_TEL.index(start_189)\n",
    "TEL_189_2 = Date_TEL.index(end_189)\n",
    "\n",
    "PGOLD_189_1 = Date_PGOLD.index(start_189)\n",
    "PGOLD_189_2 = Date_PGOLD.index(end_189)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C189 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_189_1:AGI_189_2])\n",
    "E189 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_189_1:ALI_189_2])\n",
    "T189 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_189_1:MBT_189_2])\n",
    "V189 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_189_1:TEL_189_2])\n",
    "W189 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_189_1:PGOLD_189_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C189 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "E189 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "T189 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V189 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "W189 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52774aec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_189 = []\n",
    "st_189 = []\n",
    "n = 1\n",
    "while n < len(C189):\n",
    "    sc_189 = ''\n",
    "    if C189[n] > C189[n-1]:\n",
    "        sc_189 = sc_189 + 'C'\n",
    "    if E189[n] > E189[n-1]:\n",
    "        sc_189 = sc_189 + 'E'\n",
    "    if T189[n] > T189[n-1]:\n",
    "        sc_189 = sc_189 + 'T'\n",
    "    if V189[n] > V189[n-1]:\n",
    "        sc_189 = sc_189 + 'V'\n",
    "    if W189[n] > W189[n-1]:\n",
    "        sc_189 = sc_189 + 'W'\n",
    "    if len(sc_189) > 0:\n",
    "        st_189.append(sc_189)\n",
    "    else:\n",
    "        STC_189.append(st_189)\n",
    "        st_189 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_189 = STC_189.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_189 = [ st_189 for st_189 in STC_189 if len(st_189) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_189 = len(C189)\n",
    "lmax_189 = 0\n",
    "for st_189 in STC_189:\n",
    "    if len(st_189) < lmin_189:\n",
    "        lmin_189 = len(st_189)\n",
    "    if len(st_189) > lmax_189:\n",
    "        lmax_189 = len(st_189)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_189 = [ st_189 for st_189 in STC_189 if len(st_189) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_189 = []\n",
    "for n in range(len(STC5_189)):\n",
    "    tc_189 = [ u for u in STC5_189[n][0] ]\n",
    "    for k in range(1, len(STC5_189[n])):\n",
    "        tc_189 = [ u+v for u in tc_189 for v in STC5_189[n][k] ]\n",
    "    TC5_189 = TC5_189 + tc_189\n",
    "setTC5_189 = list(set(TC5_189))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_189 = [ TC5_189.count(setTC5_189[l]) for l in range(len(setTC5_189)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_189 = [ [] for l in range(len(setTC5_189)) ]\n",
    "for s in range(189):\n",
    "    STC5null_189 = [ list(st_189) for st_189 in STC5_189]\n",
    "    for st_189 in STC5null_189:\n",
    "        np.random.shuffle(st_189)\n",
    "    TC5null_189= []\n",
    "    for n in range(len(STC5null_189)):\n",
    "        tc_189 = [ u for u in STC5null_189[n][0] ]\n",
    "        for k in range(1, len(STC5null_189[n])):\n",
    "            tc_189 = [ u+v for u in tc_189 for v in STC5null_189[n][k] ]\n",
    "        TC5null_189= TC5null_189+ tc_189\n",
    "    for l in range(len(setTC5_189)):\n",
    "        if TC5null_189.count(setTC5_189[l]) > 0:\n",
    "            fTC5null_189[l].append(TC5null_189.count(setTC5_189[l]))\n",
    "        else:\n",
    "            fTC5null_189[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f803894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "CVCTT\n",
      "WVVCW\n",
      "VEETW\n",
      "WECTW\n",
      "WCEWW\n",
      "CVVTW\n",
      "WTV\n",
      "CVCTW\n",
      "WEVTT\n",
      "WEVTW\n",
      "EVCTW\n",
      "EEETW\n",
      "VVETW\n",
      "VVVTW\n",
      "CEVTW\n",
      "TVVTW\n",
      "WEVCW\n",
      "CEETW\n",
      "TVWTW\n",
      "TCVTW\n",
      "WCTWW\n",
      "EEVTW\n",
      "WVV\n",
      "WCCTW\n",
      "WCVWW\n",
      "WVVTW\n",
      "VCVTW\n",
      "WVCTW\n",
      "CCETW\n",
      "TVWE\n",
      "TEVTW\n",
      "CEEEW\n",
      "VVCTW\n",
      "ECEWW\n",
      "ECVTW\n",
      "WVTCW\n",
      "VEEEW\n",
      "CVETW\n",
      "TCEWW\n",
      "VEVTW\n",
      "TCETW\n",
      "TVETW\n",
      "WVCCW\n",
      "CECTW\n",
      "TVCTW\n",
      "VCETW\n",
      "CVCCW\n",
      "WCVTW\n",
      "CVEEW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_189)):\n",
    "    if sum(freq >= fTC5_189[l] for freq in fTC5null_189[l]) < 5:\n",
    "        print(setTC5_189[l], fTC5_189[l], sum(freq >= fTC5_189[l] for freq in fTC5null_189[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2a179d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "VEETW\n",
      "CVCTW\n",
      "WEVTW\n",
      "VVETW\n",
      "CEVTW\n",
      "TVVTW\n",
      "TEVTW\n",
      "VVCTW\n",
      "CVETW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_189)):\n",
    "    if sum(freq >= fTC5_189[l] for freq in fTC5null_189[l]) < 1:\n",
    "        print(setTC5_189[l], fTC5_189[l], sum(freq >= fTC5_189[l] for freq in fTC5null_189[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad2fdbe",
   "metadata": {},
   "source": [
    "# 190 (C) AGI - (E) ALI - (T) MBT- (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a59008de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_190 = max(min(Date_AGI), min(Date_ALI), min(Date_MBT), min(Date_URC), min(Date_PGOLD))\n",
    "end_190 = min(max(Date_AGI), max(Date_ALI), max(Date_MBT), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_190_1 = Date_AGI.index(start_190)\n",
    "AGI_190_2 = Date_AGI.index(end_190)\n",
    "\n",
    "ALI_190_1 = Date_ALI.index(start_190)\n",
    "ALI_190_2 = Date_ALI.index(end_190)\n",
    "\n",
    "MBT_190_1 = Date_MBT.index(start_190)\n",
    "MBT_190_2 = Date_MBT.index(end_190)\n",
    "\n",
    "URC_190_1 = Date_URC.index(start_190)\n",
    "URC_190_2 = Date_URC.index(end_190)\n",
    "\n",
    "PGOLD_190_1 = Date_PGOLD.index(start_190)\n",
    "PGOLD_190_2 = Date_PGOLD.index(end_190)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C190 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_190_1:AGI_190_2])\n",
    "E190 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_190_1:ALI_190_2])\n",
    "T190 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_190_1:MBT_190_2])\n",
    "ε190 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_190_1:URC_190_2])\n",
    "W190 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_190_1:PGOLD_190_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C190 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "E190 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "T190 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε190 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W190 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad40446d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_190 = []\n",
    "st_190 = []\n",
    "n = 1\n",
    "while n < len(C190):\n",
    "    sc_190 = ''\n",
    "    if C190[n] > C190[n-1]:\n",
    "        sc_190 = sc_190 + 'C'\n",
    "    if E190[n] > E190[n-1]:\n",
    "        sc_190 = sc_190 + 'E'\n",
    "    if T190[n] > T190[n-1]:\n",
    "        sc_190 = sc_190 + 'T'\n",
    "    if ε190[n] > ε190[n-1]:\n",
    "        sc_190 = sc_190 + 'ε'\n",
    "    if W190[n] > W190[n-1]:\n",
    "        sc_190 = sc_190 + 'W'\n",
    "    if len(sc_190) > 0:\n",
    "        st_190.append(sc_190)\n",
    "    else:\n",
    "        STC_190.append(st_190)\n",
    "        st_190 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_190 = STC_190.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_190 = [ st_190 for st_190 in STC_190 if len(st_190) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_190 = len(C190)\n",
    "lmax_190 = 0\n",
    "for st_190 in STC_190:\n",
    "    if len(st_190) < lmin_190:\n",
    "        lmin_190 = len(st_190)\n",
    "    if len(st_190) > lmax_190:\n",
    "        lmax_190 = len(st_190)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_190 = [ st_190 for st_190 in STC_190 if len(st_190) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_190 = []\n",
    "for n in range(len(STC5_190)):\n",
    "    tc_190 = [ u for u in STC5_190[n][0] ]\n",
    "    for k in range(1, len(STC5_190[n])):\n",
    "        tc_190 = [ u+v for u in tc_190 for v in STC5_190[n][k] ]\n",
    "    TC5_190 = TC5_190 + tc_190\n",
    "setTC5_190 = list(set(TC5_190))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_190 = [ TC5_190.count(setTC5_190[l]) for l in range(len(setTC5_190)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_190 = [ [] for l in range(len(setTC5_190)) ]\n",
    "for s in range(190):\n",
    "    STC5null_190 = [ list(st_190) for st_190 in STC5_190]\n",
    "    for st_190 in STC5null_190:\n",
    "        np.random.shuffle(st_190)\n",
    "    TC5null_190= []\n",
    "    for n in range(len(STC5null_190)):\n",
    "        tc_190 = [ u for u in STC5null_190[n][0] ]\n",
    "        for k in range(1, len(STC5null_190[n])):\n",
    "            tc_190 = [ u+v for u in tc_190 for v in STC5null_190[n][k] ]\n",
    "        TC5null_190= TC5null_190+ tc_190\n",
    "    for l in range(len(setTC5_190)):\n",
    "        if TC5null_190.count(setTC5_190[l]) > 0:\n",
    "            fTC5null_190[l].append(TC5null_190.count(setTC5_190[l]))\n",
    "        else:\n",
    "            fTC5null_190[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bd3afbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "EεεWE\n",
      "ECεεW\n",
      "WεεWE\n",
      "WεCWE\n",
      "εEEC\n",
      "TCεεE\n",
      "WTEWE\n",
      "WCEWW\n",
      "εEWC\n",
      "TCCεE\n",
      "CCεεW\n",
      "WTεWE\n",
      "WεεWW\n",
      "CTεTW\n",
      "WCTWW\n",
      "WEEWE\n",
      "εETC\n",
      "CTCTW\n",
      "CCCεW\n",
      "CεCCε\n",
      "ECTεC\n",
      "ECCεW\n",
      "WεεεW\n",
      "ECεεT\n",
      "εEεW\n",
      "ECεWW\n",
      "εWTC\n",
      "WEEC\n",
      "WEETW\n",
      "TεεWE\n",
      "ECEWW\n",
      "WεEWE\n",
      "CCCεE\n",
      "ECEεT\n",
      "CTETW\n",
      "WWEC\n",
      "ECεεE\n",
      "ECEεC\n",
      "εTεW\n",
      "WCεWW\n",
      "ECTεE\n",
      "εCTC\n",
      "ECεεC\n",
      "ECCεE\n",
      "CECTW\n",
      "εCεW\n",
      "CECTT\n",
      "ECEεW\n",
      "εEWW\n",
      "WεWET\n",
      "TCεεW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_190)):\n",
    "    if sum(freq >= fTC5_190[l] for freq in fTC5null_190[l]) < 5:\n",
    "        print(setTC5_190[l], fTC5_190[l], sum(freq >= fTC5_190[l] for freq in fTC5null_190[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94184215",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "WεεWE\n",
      "WCEWW\n",
      "ECεWW\n",
      "ECεεE\n",
      "ECCεE\n",
      "CECTT\n",
      "εEWW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_190)):\n",
    "    if sum(freq >= fTC5_190[l] for freq in fTC5null_190[l]) < 1:\n",
    "        print(setTC5_190[l], fTC5_190[l], sum(freq >= fTC5_190[l] for freq in fTC5null_190[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f6f6de",
   "metadata": {},
   "source": [
    "# 191 (C) AGI - (E) ALI - (V) TEL - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8301c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_191 = max(min(Date_AGI), min(Date_ALI), min(Date_TEL), min(Date_URC), min(Date_PGOLD))\n",
    "end_191 = min(max(Date_AGI), max(Date_ALI), max(Date_TEL), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_191_1 = Date_AGI.index(start_191)\n",
    "AGI_191_2 = Date_AGI.index(end_191)\n",
    "\n",
    "ALI_191_1 = Date_ALI.index(start_191)\n",
    "ALI_191_2 = Date_ALI.index(end_191)\n",
    "\n",
    "TEL_191_1 = Date_TEL.index(start_191)\n",
    "TEL_191_2 = Date_TEL.index(end_191)\n",
    "\n",
    "URC_191_1 = Date_URC.index(start_191)\n",
    "URC_191_2 = Date_URC.index(end_191)\n",
    "\n",
    "PGOLD_191_1 = Date_PGOLD.index(start_191)\n",
    "PGOLD_191_2 = Date_PGOLD.index(end_191)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C191 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_191_1:AGI_191_2])\n",
    "E191 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_191_1:ALI_191_2])\n",
    "V191 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_191_1:TEL_191_2])\n",
    "ε191 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_191_1:URC_191_2])\n",
    "W191 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_191_1:PGOLD_191_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C191 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "E191 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "V191 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε191 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W191 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c004947",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_191 = []\n",
    "st_191 = []\n",
    "n = 1\n",
    "while n < len(C191):\n",
    "    sc_191 = ''\n",
    "    if C191[n] > C191[n-1]:\n",
    "        sc_191 = sc_191 + 'C'\n",
    "    if E191[n] > E191[n-1]:\n",
    "        sc_191 = sc_191 + 'E'\n",
    "    if V191[n] > V191[n-1]:\n",
    "        sc_191 = sc_191 + 'V'\n",
    "    if ε191[n] > ε191[n-1]:\n",
    "        sc_191 = sc_191 + 'ε'\n",
    "    if W191[n] > W191[n-1]:\n",
    "        sc_191 = sc_191 + 'W'\n",
    "    if len(sc_191) > 0:\n",
    "        st_191.append(sc_191)\n",
    "    else:\n",
    "        STC_191.append(st_191)\n",
    "        st_191 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_191 = STC_191.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_191 = [ st_191 for st_191 in STC_191 if len(st_191) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_191 = len(C191)\n",
    "lmax_191 = 0\n",
    "for st_191 in STC_191:\n",
    "    if len(st_191) < lmin_191:\n",
    "        lmin_191 = len(st_191)\n",
    "    if len(st_191) > lmax_191:\n",
    "        lmax_191 = len(st_191)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_191 = [ st_191 for st_191 in STC_191 if len(st_191) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_191 = []\n",
    "for n in range(len(STC5_191)):\n",
    "    tc_191 = [ u for u in STC5_191[n][0] ]\n",
    "    for k in range(1, len(STC5_191[n])):\n",
    "        tc_191 = [ u+v for u in tc_191 for v in STC5_191[n][k] ]\n",
    "    TC5_191 = TC5_191 + tc_191\n",
    "setTC5_191 = list(set(TC5_191))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_191 = [ TC5_191.count(setTC5_191[l]) for l in range(len(setTC5_191)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_191 = [ [] for l in range(len(setTC5_191)) ]\n",
    "for s in range(191):\n",
    "    STC5null_191 = [ list(st_191) for st_191 in STC5_191]\n",
    "    for st_191 in STC5null_191:\n",
    "        np.random.shuffle(st_191)\n",
    "    TC5null_191= []\n",
    "    for n in range(len(STC5null_191)):\n",
    "        tc_191 = [ u for u in STC5null_191[n][0] ]\n",
    "        for k in range(1, len(STC5null_191[n])):\n",
    "            tc_191 = [ u+v for u in tc_191 for v in STC5null_191[n][k] ]\n",
    "        TC5null_191= TC5null_191+ tc_191\n",
    "    for l in range(len(setTC5_191)):\n",
    "        if TC5null_191.count(setTC5_191[l]) > 0:\n",
    "            fTC5null_191[l].append(TC5null_191.count(setTC5_191[l]))\n",
    "        else:\n",
    "            fTC5null_191[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e8f9ecd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "εVVC\n",
      "εWVW\n",
      "WVεεW\n",
      "εεWE\n",
      "WCEWW\n",
      "εVVE\n",
      "ECVWC\n",
      "WCεεW\n",
      "WεEWW\n",
      "ECEEC\n",
      "WVεWW\n",
      "εWVC\n",
      "ECε\n",
      "WεεWW\n",
      "WVVεW\n",
      "WVVC\n",
      "εVWE\n",
      "CVVCV\n",
      "εEEE\n",
      "εεVε\n",
      "ECεWC\n",
      "EεεWW\n",
      "εVWW\n",
      "CεVC\n",
      "εCCεV\n",
      "CEεCW\n",
      "EVεWW\n",
      "WCEWC\n",
      "WCVWW\n",
      "εEVC\n",
      "WεεεW\n",
      "ECεWW\n",
      "CEεEW\n",
      "CVεEW\n",
      "VεVC\n",
      "εEWE\n",
      "ECEWW\n",
      "εVVW\n",
      "VW\n",
      "VVWE\n",
      "εεVE\n",
      "CCVC\n",
      "EWεWW\n",
      "WCεWW\n",
      "CEVC\n",
      "ECEWC\n",
      "WCEεW\n",
      "εEWW\n",
      "εEVE\n",
      "εCVE\n",
      "VVVE\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_191)):\n",
    "    if sum(freq >= fTC5_191[l] for freq in fTC5null_191[l]) < 5:\n",
    "        print(setTC5_191[l], fTC5_191[l], sum(freq >= fTC5_191[l] for freq in fTC5null_191[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87a83a0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "WCEWW\n",
      "εVVE\n",
      "WCεεW\n",
      "εVWE\n",
      "εVVW\n",
      "WCεWW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_191)):\n",
    "    if sum(freq >= fTC5_191[l] for freq in fTC5null_191[l]) < 1:\n",
    "        print(setTC5_191[l], fTC5_191[l], sum(freq >= fTC5_191[l] for freq in fTC5null_191[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a29f8ef",
   "metadata": {},
   "source": [
    "# 192 (C) AGI - (Z) SECB - (T) MBT - (V) TEL - (ε) URC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d844061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_192 = max(min(Date_AGI), min(Date_SECB), min(Date_MBT), min(Date_TEL), min(Date_URC))\n",
    "end_192 = min(max(Date_AGI), max(Date_SECB), max(Date_MBT), max(Date_TEL), max(Date_URC))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_192_1 = Date_AGI.index(start_192)\n",
    "AGI_192_2 = Date_AGI.index(end_192)\n",
    "\n",
    "SECB_192_1 = Date_SECB.index(start_192)\n",
    "SECB_192_2 = Date_SECB.index(end_192)\n",
    "\n",
    "MBT_192_1 = Date_MBT.index(start_192)\n",
    "MBT_192_2 = Date_MBT.index(end_192)\n",
    "\n",
    "TEL_192_1 = Date_TEL.index(start_192)\n",
    "TEL_192_2 = Date_TEL.index(end_192)\n",
    "\n",
    "URC_192_1 = Date_URC.index(start_192)\n",
    "URC_192_2 = Date_URC.index(end_192)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C192 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_192_1:AGI_192_2])\n",
    "Z192 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_192_1:SECB_192_2])\n",
    "T192 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_192_1:MBT_192_2])\n",
    "V192 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_192_1:TEL_192_2])\n",
    "ε192 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_192_1:URC_192_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C192 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z192 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T192 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V192 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε192 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef6d5ab6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_192 = []\n",
    "st_192 = []\n",
    "n = 1\n",
    "while n < len(C192):\n",
    "    sc_192 = ''\n",
    "    if C192[n] > C192[n-1]:\n",
    "        sc_192 = sc_192 + 'C'\n",
    "    if Z192[n] > Z192[n-1]:\n",
    "        sc_192 = sc_192 + 'Z'\n",
    "    if T192[n] > T192[n-1]:\n",
    "        sc_192 = sc_192 + 'T'\n",
    "    if V192[n] > V192[n-1]:\n",
    "        sc_192 = sc_192 + 'V'\n",
    "    if ε192[n] > ε192[n-1]:\n",
    "        sc_192 = sc_192 + 'ε'\n",
    "    if len(sc_192) > 0:\n",
    "        st_192.append(sc_192)\n",
    "    else:\n",
    "        STC_192.append(st_192)\n",
    "        st_192 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_192 = STC_192.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_192 = [ st_192 for st_192 in STC_192 if len(st_192) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_192 = len(C192)\n",
    "lmax_192 = 0\n",
    "for st_192 in STC_192:\n",
    "    if len(st_192) < lmin_192:\n",
    "        lmin_192 = len(st_192)\n",
    "    if len(st_192) > lmax_192:\n",
    "        lmax_192 = len(st_192)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_192 = [ st_192 for st_192 in STC_192 if len(st_192) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_192 = []\n",
    "for n in range(len(STC5_192)):\n",
    "    tc_192 = [ u for u in STC5_192[n][0] ]\n",
    "    for k in range(1, len(STC5_192[n])):\n",
    "        tc_192 = [ u+v for u in tc_192 for v in STC5_192[n][k] ]\n",
    "    TC5_192 = TC5_192 + tc_192\n",
    "setTC5_192 = list(set(TC5_192))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_192 = [ TC5_192.count(setTC5_192[l]) for l in range(len(setTC5_192)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_192 = [ [] for l in range(len(setTC5_192)) ]\n",
    "for s in range(192):\n",
    "    STC5null_192 = [ list(st_192) for st_192 in STC5_192]\n",
    "    for st_192 in STC5null_192:\n",
    "        np.random.shuffle(st_192)\n",
    "    TC5null_192= []\n",
    "    for n in range(len(STC5null_192)):\n",
    "        tc_192 = [ u for u in STC5null_192[n][0] ]\n",
    "        for k in range(1, len(STC5null_192[n])):\n",
    "            tc_192 = [ u+v for u in tc_192 for v in STC5null_192[n][k] ]\n",
    "        TC5null_192= TC5null_192+ tc_192\n",
    "    for l in range(len(setTC5_192)):\n",
    "        if TC5null_192.count(setTC5_192[l]) > 0:\n",
    "            fTC5null_192[l].append(TC5null_192.count(setTC5_192[l]))\n",
    "        else:\n",
    "            fTC5null_192[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0509958e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "εZTVV\n",
      "ZεVVT\n",
      "εZTC\n",
      "CεC\n",
      "εεZT\n",
      "TVCTZ\n",
      "CTC\n",
      "εεCε\n",
      "TVVZT\n",
      "εVCCV\n",
      "εVCCC\n",
      "ZCVZT\n",
      "TZεZε\n",
      "ZεTTε\n",
      "εVCTV\n",
      "εCTTT\n",
      "ZεVTT\n",
      "ZVVZT\n",
      "ZCVVT\n",
      "TZεTε\n",
      "εVCZV\n",
      "ZCVZZ\n",
      "VVCTZ\n",
      "ZCTCZ\n",
      "TZTZε\n",
      "ZεVε\n",
      "TZZTε\n",
      "εCTTC\n",
      "ZTVV\n",
      "ZCTTT\n",
      "ZTZ\n",
      "ZCTTε\n",
      "εCTTV\n",
      "VZVT\n",
      "ZCVTT\n",
      "TCTVT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_192)):\n",
    "    if sum(freq >= fTC5_192[l] for freq in fTC5null_192[l]) < 5:\n",
    "        print(setTC5_192[l], fTC5_192[l], sum(freq >= fTC5_192[l] for freq in fTC5null_192[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "176fae47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "εZTC\n",
      "CTC\n",
      "TZZTε\n",
      "εCTTC\n",
      "ZCTTT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_192)):\n",
    "    if sum(freq >= fTC5_192[l] for freq in fTC5null_192[l]) < 1:\n",
    "        print(setTC5_192[l], fTC5_192[l], sum(freq >= fTC5_192[l] for freq in fTC5null_192[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9044be51",
   "metadata": {},
   "source": [
    "# 193 (C) AGI - (Z) SECB - (T) MBT - (V) TEL - (W) PGOLD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2051bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_193 = max(min(Date_AGI), min(Date_SECB), min(Date_MBT), min(Date_TEL), min(Date_PGOLD))\n",
    "end_193 = min(max(Date_AGI), max(Date_SECB), max(Date_MBT), max(Date_TEL), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_193_1 = Date_AGI.index(start_193)\n",
    "AGI_193_2 = Date_AGI.index(end_193)\n",
    "\n",
    "SECB_193_1 = Date_SECB.index(start_193)\n",
    "SECB_193_2 = Date_SECB.index(end_193)\n",
    "\n",
    "MBT_193_1 = Date_MBT.index(start_193)\n",
    "MBT_193_2 = Date_MBT.index(end_193)\n",
    "\n",
    "TEL_193_1 = Date_TEL.index(start_193)\n",
    "TEL_193_2 = Date_TEL.index(end_193)\n",
    "\n",
    "PGOLD_193_1 = Date_PGOLD.index(start_193)\n",
    "PGOLD_193_2 = Date_PGOLD.index(end_193)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C193 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_193_1:AGI_193_2])\n",
    "Z193 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_193_1:SECB_193_2])\n",
    "T193 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_193_1:MBT_193_2])\n",
    "V193 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_193_1:TEL_193_2])\n",
    "W193 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_193_1:PGOLD_193_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C193 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z193 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T193 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V193 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "W193 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7163ef2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_193 = []\n",
    "st_193 = []\n",
    "n = 1\n",
    "while n < len(C193):\n",
    "    sc_193 = ''\n",
    "    if C193[n] > C193[n-1]:\n",
    "        sc_193 = sc_193 + 'C'\n",
    "    if Z193[n] > Z193[n-1]:\n",
    "        sc_193 = sc_193 + 'Z'\n",
    "    if T193[n] > T193[n-1]:\n",
    "        sc_193 = sc_193 + 'T'\n",
    "    if V193[n] > V193[n-1]:\n",
    "        sc_193 = sc_193 + 'V'\n",
    "    if W193[n] > W193[n-1]:\n",
    "        sc_193 = sc_193 + 'W'\n",
    "    if len(sc_193) > 0:\n",
    "        st_193.append(sc_193)\n",
    "    else:\n",
    "        STC_193.append(st_193)\n",
    "        st_193 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_193 = STC_193.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_193 = [ st_193 for st_193 in STC_193 if len(st_193) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_193 = len(C193)\n",
    "lmax_193 = 0\n",
    "for st_193 in STC_193:\n",
    "    if len(st_193) < lmin_193:\n",
    "        lmin_193 = len(st_193)\n",
    "    if len(st_193) > lmax_193:\n",
    "        lmax_193 = len(st_193)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_193 = [ st_193 for st_193 in STC_193 if len(st_193) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_193 = []\n",
    "for n in range(len(STC5_193)):\n",
    "    tc_193 = [ u for u in STC5_193[n][0] ]\n",
    "    for k in range(1, len(STC5_193[n])):\n",
    "        tc_193 = [ u+v for u in tc_193 for v in STC5_193[n][k] ]\n",
    "    TC5_193 = TC5_193 + tc_193\n",
    "setTC5_193 = list(set(TC5_193))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_193 = [ TC5_193.count(setTC5_193[l]) for l in range(len(setTC5_193)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_193 = [ [] for l in range(len(setTC5_193)) ]\n",
    "for s in range(193):\n",
    "    STC5null_193 = [ list(st_193) for st_193 in STC5_193]\n",
    "    for st_193 in STC5null_193:\n",
    "        np.random.shuffle(st_193)\n",
    "    TC5null_193= []\n",
    "    for n in range(len(STC5null_193)):\n",
    "        tc_193 = [ u for u in STC5null_193[n][0] ]\n",
    "        for k in range(1, len(STC5null_193[n])):\n",
    "            tc_193 = [ u+v for u in tc_193 for v in STC5null_193[n][k] ]\n",
    "        TC5null_193= TC5null_193+ tc_193\n",
    "    for l in range(len(setTC5_193)):\n",
    "        if TC5null_193.count(setTC5_193[l]) > 0:\n",
    "            fTC5null_193[l].append(TC5null_193.count(setTC5_193[l]))\n",
    "        else:\n",
    "            fTC5null_193[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2a92eed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "CVCTW\n",
      "VTV\n",
      "VVWW\n",
      "VCWW\n",
      "WVCTW\n",
      "VVCTW\n",
      "VTWZC\n",
      "CVCWZ\n",
      "VZVC\n",
      "TVCWZ\n",
      "ZVCTW\n",
      "TVCTW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_193)):\n",
    "    if sum(freq >= fTC5_193[l] for freq in fTC5null_193[l]) < 5:\n",
    "        print(setTC5_193[l], fTC5_193[l], sum(freq >= fTC5_193[l] for freq in fTC5null_193[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "10aa4c1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_193)):\n",
    "    if sum(freq >= fTC5_193[l] for freq in fTC5null_193[l]) < 1:\n",
    "        print(setTC5_193[l], fTC5_193[l], sum(freq >= fTC5_193[l] for freq in fTC5null_193[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c627d81",
   "metadata": {},
   "source": [
    "# 194 (C) AGI - (Z) SECB - (T) MBT - (ε) URC - (W) PGOLD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56eb7db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_194 = max(min(Date_AGI), min(Date_SECB), min(Date_MBT), min(Date_URC), min(Date_PGOLD))\n",
    "end_194 = min(max(Date_AGI), max(Date_SECB), max(Date_MBT), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_194_1 = Date_AGI.index(start_194)\n",
    "AGI_194_2 = Date_AGI.index(end_194)\n",
    "\n",
    "SECB_194_1 = Date_SECB.index(start_194)\n",
    "SECB_194_2 = Date_SECB.index(end_194)\n",
    "\n",
    "MBT_194_1 = Date_MBT.index(start_194)\n",
    "MBT_194_2 = Date_MBT.index(end_194)\n",
    "\n",
    "URC_194_1 = Date_URC.index(start_194)\n",
    "URC_194_2 = Date_URC.index(end_194)\n",
    "\n",
    "PGOLD_194_1 = Date_PGOLD.index(start_194)\n",
    "PGOLD_194_2 = Date_PGOLD.index(end_194)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C194 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_194_1:AGI_194_2])\n",
    "Z194 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_194_1:SECB_194_2])\n",
    "T194 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_194_1:MBT_194_2])\n",
    "ε194 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_194_1:URC_194_2])\n",
    "W194 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_194_1:PGOLD_194_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C194 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z194 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T194 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε194 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W194 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "808f72a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_194 = []\n",
    "st_194 = []\n",
    "n = 1\n",
    "while n < len(C194):\n",
    "    sc_194 = ''\n",
    "    if C194[n] > C194[n-1]:\n",
    "        sc_194 = sc_194 + 'C'\n",
    "    if Z194[n] > Z194[n-1]:\n",
    "        sc_194 = sc_194 + 'Z'\n",
    "    if T194[n] > T194[n-1]:\n",
    "        sc_194 = sc_194 + 'T'\n",
    "    if ε194[n] > ε194[n-1]:\n",
    "        sc_194 = sc_194 + 'ε'\n",
    "    if W194[n] > W194[n-1]:\n",
    "        sc_194 = sc_194 + 'W'\n",
    "    if len(sc_194) > 0:\n",
    "        st_194.append(sc_194)\n",
    "    else:\n",
    "        STC_194.append(st_194)\n",
    "        st_194 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_194 = STC_194.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_194 = [ st_194 for st_194 in STC_194 if len(st_194) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_194 = len(C194)\n",
    "lmax_194 = 0\n",
    "for st_194 in STC_194:\n",
    "    if len(st_194) < lmin_194:\n",
    "        lmin_194 = len(st_194)\n",
    "    if len(st_194) > lmax_194:\n",
    "        lmax_194 = len(st_194)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_194 = [ st_194 for st_194 in STC_194 if len(st_194) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_194 = []\n",
    "for n in range(len(STC5_194)):\n",
    "    tc_194 = [ u for u in STC5_194[n][0] ]\n",
    "    for k in range(1, len(STC5_194[n])):\n",
    "        tc_194 = [ u+v for u in tc_194 for v in STC5_194[n][k] ]\n",
    "    TC5_194 = TC5_194 + tc_194\n",
    "setTC5_194 = list(set(TC5_194))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_194 = [ TC5_194.count(setTC5_194[l]) for l in range(len(setTC5_194)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_194 = [ [] for l in range(len(setTC5_194)) ]\n",
    "for s in range(194):\n",
    "    STC5null_194 = [ list(st_194) for st_194 in STC5_194]\n",
    "    for st_194 in STC5null_194:\n",
    "        np.random.shuffle(st_194)\n",
    "    TC5null_194= []\n",
    "    for n in range(len(STC5null_194)):\n",
    "        tc_194 = [ u for u in STC5null_194[n][0] ]\n",
    "        for k in range(1, len(STC5null_194[n])):\n",
    "            tc_194 = [ u+v for u in tc_194 for v in STC5null_194[n][k] ]\n",
    "        TC5null_194= TC5null_194+ tc_194\n",
    "    for l in range(len(setTC5_194)):\n",
    "        if TC5null_194.count(setTC5_194[l]) > 0:\n",
    "            fTC5null_194[l].append(TC5null_194.count(setTC5_194[l]))\n",
    "        else:\n",
    "            fTC5null_194[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fab94734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "εZTC\n",
      "WTZWW\n",
      "TCWεT\n",
      "TCCεZ\n",
      "CZCεZ\n",
      "WZZWW\n",
      "TZCεZ\n",
      "WεεWW\n",
      "εZε\n",
      "εZWW\n",
      "ZεWW\n",
      "TZεεZ\n",
      "TεWεT\n",
      "CCCεZ\n",
      "WCZWW\n",
      "WZTWW\n",
      "TεCεZ\n",
      "WCεWW\n",
      "WZεWW\n",
      "TεεεZ\n",
      "εCε\n",
      "εεWW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_194)):\n",
    "    if sum(freq >= fTC5_194[l] for freq in fTC5null_194[l]) < 5:\n",
    "        print(setTC5_194[l], fTC5_194[l], sum(freq >= fTC5_194[l] for freq in fTC5null_194[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c38d88d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "ZεWW\n",
      "CCCεZ\n",
      "εCε\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_194)):\n",
    "    if sum(freq >= fTC5_194[l] for freq in fTC5null_194[l]) < 1:\n",
    "        print(setTC5_194[l], fTC5_194[l], sum(freq >= fTC5_194[l] for freq in fTC5null_194[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be4d60",
   "metadata": {},
   "source": [
    "# 195 (C) AGI - (Z) SECB - (V) TEL - (ε) URC - (W) PGOLD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f0bee2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_195 = max(min(Date_AGI), min(Date_SECB), min(Date_TEL), min(Date_URC), min(Date_PGOLD))\n",
    "end_195 = min(max(Date_AGI), max(Date_SECB), max(Date_TEL), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_195_1 = Date_AGI.index(start_195)\n",
    "AGI_195_2 = Date_AGI.index(end_195)\n",
    "\n",
    "SECB_195_1 = Date_SECB.index(start_195)\n",
    "SECB_195_2 = Date_SECB.index(end_195)\n",
    "\n",
    "TEL_195_1 = Date_TEL.index(start_195)\n",
    "TEL_195_2 = Date_TEL.index(end_195)\n",
    "\n",
    "URC_195_1 = Date_URC.index(start_195)\n",
    "URC_195_2 = Date_URC.index(end_195)\n",
    "\n",
    "PGOLD_195_1 = Date_PGOLD.index(start_195)\n",
    "PGOLD_195_2 = Date_PGOLD.index(end_195)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C195 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_195_1:AGI_195_2])\n",
    "Z195 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_195_1:SECB_195_2])\n",
    "V195 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_195_1:TEL_195_2])\n",
    "ε195 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_195_1:URC_195_2])\n",
    "W195 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_195_1:PGOLD_195_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C195 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z195 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "V195 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε195 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W195 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a448bb3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_195 = []\n",
    "st_195 = []\n",
    "n = 1\n",
    "while n < len(C195):\n",
    "    sc_195 = ''\n",
    "    if C195[n] > C195[n-1]:\n",
    "        sc_195 = sc_195 + 'C'\n",
    "    if Z195[n] > Z195[n-1]:\n",
    "        sc_195 = sc_195 + 'Z'\n",
    "    if V195[n] > V195[n-1]:\n",
    "        sc_195 = sc_195 + 'V'\n",
    "    if ε195[n] > ε195[n-1]:\n",
    "        sc_195 = sc_195 + 'ε'\n",
    "    if W195[n] > W195[n-1]:\n",
    "        sc_195 = sc_195 + 'W'\n",
    "    if len(sc_195) > 0:\n",
    "        st_195.append(sc_195)\n",
    "    else:\n",
    "        STC_195.append(st_195)\n",
    "        st_195 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_195 = STC_195.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_195 = [ st_195 for st_195 in STC_195 if len(st_195) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_195 = len(C195)\n",
    "lmax_195 = 0\n",
    "for st_195 in STC_195:\n",
    "    if len(st_195) < lmin_195:\n",
    "        lmin_195 = len(st_195)\n",
    "    if len(st_195) > lmax_195:\n",
    "        lmax_195 = len(st_195)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_195 = [ st_195 for st_195 in STC_195 if len(st_195) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_195 = []\n",
    "for n in range(len(STC5_195)):\n",
    "    tc_195 = [ u for u in STC5_195[n][0] ]\n",
    "    for k in range(1, len(STC5_195[n])):\n",
    "        tc_195 = [ u+v for u in tc_195 for v in STC5_195[n][k] ]\n",
    "    TC5_195 = TC5_195 + tc_195\n",
    "setTC5_195 = list(set(TC5_195))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_195 = [ TC5_195.count(setTC5_195[l]) for l in range(len(setTC5_195)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_195 = [ [] for l in range(len(setTC5_195)) ]\n",
    "for s in range(195):\n",
    "    STC5null_195 = [ list(st_195) for st_195 in STC5_195]\n",
    "    for st_195 in STC5null_195:\n",
    "        np.random.shuffle(st_195)\n",
    "    TC5null_195= []\n",
    "    for n in range(len(STC5null_195)):\n",
    "        tc_195 = [ u for u in STC5null_195[n][0] ]\n",
    "        for k in range(1, len(STC5null_195[n])):\n",
    "            tc_195 = [ u+v for u in tc_195 for v in STC5null_195[n][k] ]\n",
    "        TC5null_195= TC5null_195+ tc_195\n",
    "    for l in range(len(setTC5_195)):\n",
    "        if TC5null_195.count(setTC5_195[l]) > 0:\n",
    "            fTC5null_195[l].append(TC5null_195.count(setTC5_195[l]))\n",
    "        else:\n",
    "            fTC5null_195[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb1856a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "CVεWW\n",
      "εCCWZ\n",
      "εεZεV\n",
      "WWεZC\n",
      "εCZZV\n",
      "CCεWW\n",
      "CεCεV\n",
      "εWVW\n",
      "εεCεV\n",
      "εVεZW\n",
      "CεZεV\n",
      "CCZWV\n",
      "ZεVεV\n",
      "CVVZW\n",
      "WεεZW\n",
      "εVWZW\n",
      "εεZZV\n",
      "εVVZW\n",
      "εεCZV\n",
      "εCZWZ\n",
      "εZVW\n",
      "WVεWW\n",
      "εWVC\n",
      "εεCε\n",
      "WεεWW\n",
      "CCεZW\n",
      "εVCCV\n",
      "εCZεV\n",
      "εZWW\n",
      "CVVCV\n",
      "CVZZV\n",
      "CεZZV\n",
      "CCZεV\n",
      "CCZZV\n",
      "WCεZW\n",
      "VWVC\n",
      "WVεZW\n",
      "CVVZV\n",
      "CZεZW\n",
      "CVεZC\n",
      "ZCV\n",
      "CVεZW\n",
      "CZεWW\n",
      "CVZZW\n",
      "ZVεZW\n",
      "VZVC\n",
      "CVεZV\n",
      "ZεVZV\n",
      "WCεWW\n",
      "WZεWW\n",
      "WZεZW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_195)):\n",
    "    if sum(freq >= fTC5_195[l] for freq in fTC5null_195[l]) < 5:\n",
    "        print(setTC5_195[l], fTC5_195[l], sum(freq >= fTC5_195[l] for freq in fTC5null_195[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "636be98f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "εεZεV\n",
      "εεCεV\n",
      "εVεZW\n",
      "εεCε\n",
      "WVεZW\n",
      "CVVZV\n",
      "CVεZW\n",
      "WZεWW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_195)):\n",
    "    if sum(freq >= fTC5_195[l] for freq in fTC5null_195[l]) < 1:\n",
    "        print(setTC5_195[l], fTC5_195[l], sum(freq >= fTC5_195[l] for freq in fTC5null_195[l]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
