{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad73c97",
   "metadata": {},
   "source": [
    "# One-Letter Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d393036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the csv files\n",
    "GTCAP = open('GTCAP.csv')\n",
    "AGI = open('AGI.csv')\n",
    "SM = open('SM.csv')\n",
    "MER = open('MER.csv')\n",
    "ALI = open('ALI.csv')\n",
    "SECB = open('SECB.csv')\n",
    "MBT = open('MBT.csv')\n",
    "TEL = open('TEL.csv')\n",
    "URC = open('URC.csv')\n",
    "PGOLD = open('PGOLD.csv')\n",
    "\n",
    "#initialize the lists\n",
    "Date_GTCAP = []\n",
    "ClosePrice_GTCAP = []\n",
    "Date_AGI = []\n",
    "ClosePrice_AGI = []\n",
    "Date_SM = []\n",
    "ClosePrice_SM = []\n",
    "Date_MER = []\n",
    "ClosePrice_MER = []\n",
    "Date_ALI = []\n",
    "ClosePrice_ALI = []\n",
    "Date_SECB = []\n",
    "ClosePrice_SECB = []\n",
    "Date_MBT = []\n",
    "ClosePrice_MBT = []\n",
    "Date_TEL = []\n",
    "ClosePrice_TEL = []\n",
    "Date_URC = []\n",
    "ClosePrice_URC = []\n",
    "Date_PGOLD = []\n",
    "ClosePrice_PGOLD = []\n",
    "\n",
    "#skip the header line\n",
    "GTCAP.readline()\n",
    "AGI.readline()\n",
    "SM.readline()\n",
    "MER.readline()\n",
    "ALI.readline()\n",
    "SECB.readline()\n",
    "MBT.readline()\n",
    "TEL.readline()\n",
    "URC.readline()\n",
    "PGOLD.readline()\n",
    "\n",
    "#go through the files line by line\n",
    "for line in GTCAP:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_GTCAP.append(sline[0])\n",
    "    ClosePrice_GTCAP.append(float(sline[1]))\n",
    "    \n",
    "for line in AGI:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_AGI.append(sline[0])\n",
    "    ClosePrice_AGI.append(float(sline[1]))\n",
    "    \n",
    "for line in SM:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_SM.append(sline[0])\n",
    "    ClosePrice_SM.append(float(sline[1]))\n",
    "    \n",
    "for line in MER:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_MER.append(sline[0])\n",
    "    ClosePrice_MER.append(float(sline[1]))\n",
    "    \n",
    "for line in ALI:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_ALI.append(sline[0])\n",
    "    ClosePrice_ALI.append(float(sline[1]))\n",
    "    \n",
    "for line in SECB:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_SECB.append(sline[0])\n",
    "    ClosePrice_SECB.append(float(sline[1]))\n",
    "    \n",
    "for line in MBT:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_MBT.append(sline[0])\n",
    "    ClosePrice_MBT.append(float(sline[1]))\n",
    "    \n",
    "for line in TEL:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_TEL.append(sline[0])\n",
    "    ClosePrice_TEL.append(float(sline[1]))\n",
    "    \n",
    "for line in URC:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_URC.append(sline[0])\n",
    "    ClosePrice_URC.append(float(sline[1]))\n",
    "        \n",
    "for line in PGOLD:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_PGOLD.append(sline[0])\n",
    "    ClosePrice_PGOLD.append(float(sline[1]))\n",
    "\n",
    "\n",
    "#close files\n",
    "GTCAP.close()\n",
    "AGI.close()\n",
    "SM.close()\n",
    "MER.close()\n",
    "ALI.close()\n",
    "SECB.close()\n",
    "MBT.close()\n",
    "TEL.close()\n",
    "URC.close()\n",
    "PGOLD.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e92dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea64333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates into datetime structure\n",
    "for n in range(len(Date_GTCAP)):\n",
    "    Date_GTCAP[n] = datetime.datetime.strptime(Date_GTCAP[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_AGI)):\n",
    "    Date_AGI[n] = datetime.datetime.strptime(Date_AGI[n], '%m/%d/%y').date()\n",
    "    \n",
    "for n in range(len(Date_SM)):\n",
    "    Date_SM[n] = datetime.datetime.strptime(Date_SM[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_MER)):\n",
    "    Date_MER[n] = datetime.datetime.strptime(Date_MER[n], '%m/%d/%y').date()\n",
    "    \n",
    "for n in range(len(Date_ALI)):\n",
    "    Date_ALI[n] = datetime.datetime.strptime(Date_ALI[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_SECB)):\n",
    "    Date_SECB[n] = datetime.datetime.strptime(Date_SECB[n], '%m/%d/%y').date()\n",
    "    \n",
    "for n in range(len(Date_MBT)):\n",
    "    Date_MBT[n] = datetime.datetime.strptime(Date_MBT[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_TEL)):\n",
    "    Date_TEL[n] = datetime.datetime.strptime(Date_TEL[n], '%m/%d/%y').date()\n",
    "    \n",
    "for n in range(len(Date_URC)):\n",
    "    Date_URC[n] = datetime.datetime.strptime(Date_URC[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_PGOLD)):\n",
    "    Date_PGOLD[n] = datetime.datetime.strptime(Date_PGOLD[n], '%m/%d/%y').date()\n",
    "    \n",
    "# save Date and ClosePrice\n",
    "np.save('GTCAPDate.npy', Date_GTCAP)\n",
    "np.save('GTCAPClosePrice.npy', ClosePrice_GTCAP)\n",
    "np.save('AGIDate.npy', Date_AGI)\n",
    "np.save('AGIClosePrice.npy', ClosePrice_AGI)\n",
    "np.save('SMDate.npy', Date_SM)\n",
    "np.save('SMClosePrice.npy', ClosePrice_SM)\n",
    "np.save('MERDate.npy', Date_MER)\n",
    "np.save('MERClosePrice.npy', ClosePrice_MER)\n",
    "np.save('ALIDate.npy', Date_ALI)\n",
    "np.save('ALIClosePrice.npy', ClosePrice_ALI)\n",
    "np.save('SECBDate.npy', Date_SECB)\n",
    "np.save('SECBClosePrice.npy', ClosePrice_SECB)\n",
    "np.save('MBTDate.npy', Date_MBT)\n",
    "np.save('MBTClosePrice.npy', ClosePrice_MBT)\n",
    "np.save('TELDate.npy', Date_TEL)\n",
    "np.save('TELClosePrice.npy', ClosePrice_TEL)\n",
    "np.save('URCDate.npy', Date_URC)\n",
    "np.save('URCClosePrice.npy', ClosePrice_URC)\n",
    "np.save('PGOLDDate.npy', Date_PGOLD)\n",
    "np.save('PGOLDClosePrice.npy', ClosePrice_PGOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d00fcad",
   "metadata": {},
   "source": [
    "# Five-letter Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0bd8f",
   "metadata": {},
   "source": [
    "# 166 (C) AGI - (Q) MER - (E) ALI - (T) MBT - (V) TEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8bdf08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_166 = max(min(Date_AGI), min(Date_MER), min(Date_ALI), min(Date_MBT), min(Date_TEL))\n",
    "end_166 = min(max(Date_AGI), max(Date_MER), max(Date_ALI), max(Date_MBT), max(Date_TEL))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_166_1 = Date_AGI.index(start_166)\n",
    "AGI_166_2 = Date_AGI.index(end_166)\n",
    "\n",
    "MER_166_1 = Date_MER.index(start_166)\n",
    "MER_166_2 = Date_MER.index(end_166)\n",
    "\n",
    "ALI_166_1 = Date_ALI.index(start_166)\n",
    "ALI_166_2 = Date_ALI.index(end_166)\n",
    "\n",
    "MBT_166_1 = Date_MBT.index(start_166)\n",
    "MBT_166_2 = Date_MBT.index(end_166)\n",
    "\n",
    "TEL_166_1 = Date_TEL.index(start_166)\n",
    "TEL_166_2 = Date_TEL.index(end_166)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C166 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_166_1:AGI_166_2])\n",
    "Q166 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_166_1:MER_166_2])\n",
    "E166 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_166_1:ALI_166_2])\n",
    "T166 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_166_1:MBT_166_2])\n",
    "V166 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_166_1:TEL_166_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C166 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q166 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "E166 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "T166 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V166 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0a1f0b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_166 = []\n",
    "st_166 = []\n",
    "n = 1\n",
    "while n < len(C166):\n",
    "    sc_166 = ''\n",
    "    if C166[n] > C166[n-1]:\n",
    "        sc_166 = sc_166 + 'C'\n",
    "    if Q166[n] > Q166[n-1]:\n",
    "        sc_166 = sc_166 + 'Q'\n",
    "    if E166[n] > E166[n-1]:\n",
    "        sc_166 = sc_166 + 'E'\n",
    "    if T166[n] > T166[n-1]:\n",
    "        sc_166 = sc_166 + 'T'\n",
    "    if V166[n] > V166[n-1]:\n",
    "        sc_166 = sc_166 + 'V'\n",
    "    if len(sc_166) > 0:\n",
    "        st_166.append(sc_166)\n",
    "    else:\n",
    "        STC_166.append(st_166)\n",
    "        st_166 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_166 = STC_166.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_166 = [ st_166 for st_166 in STC_166 if len(st_166) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_166 = len(C166)\n",
    "lmax_166 = 0\n",
    "for st_166 in STC_166:\n",
    "    if len(st_166) < lmin_166:\n",
    "        lmin_166 = len(st_166)\n",
    "    if len(st_166) > lmax_166:\n",
    "        lmax_166 = len(st_166)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_166 = [ st_166 for st_166 in STC_166 if len(st_166) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_166 = []\n",
    "for n in range(len(STC5_166)):\n",
    "    tc_166 = [ u for u in STC5_166[n][0] ]\n",
    "    for k in range(1, len(STC5_166[n])):\n",
    "        tc_166 = [ u+v for u in tc_166 for v in STC5_166[n][k] ]\n",
    "    TC5_166 = TC5_166 + tc_166\n",
    "setTC5_166 = list(set(TC5_166))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_166 = [ TC5_166.count(setTC5_166[l]) for l in range(len(setTC5_166)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_166 = [ [] for l in range(len(setTC5_166)) ]\n",
    "for s in range(166):\n",
    "    STC5null_166 = [ list(st_166) for st_166 in STC5_166]\n",
    "    for st_166 in STC5null_166:\n",
    "        np.random.shuffle(st_166)\n",
    "    TC5null_166= []\n",
    "    for n in range(len(STC5null_166)):\n",
    "        tc_166 = [ u for u in STC5null_166[n][0] ]\n",
    "        for k in range(1, len(STC5null_166[n])):\n",
    "            tc_166 = [ u+v for u in tc_166 for v in STC5null_166[n][k] ]\n",
    "        TC5null_166= TC5null_166+ tc_166\n",
    "    for l in range(len(setTC5_166)):\n",
    "        if TC5null_166.count(setTC5_166[l]) > 0:\n",
    "            fTC5null_166[l].append(TC5null_166.count(setTC5_166[l]))\n",
    "        else:\n",
    "            fTC5null_166[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fd0c629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "QQVVC\n",
      "CEVET\n",
      "CVEV\n",
      "TVET\n",
      "TEEEV\n",
      "VVET\n",
      "QQVVE\n",
      "QQEEE\n",
      "QQVEQ\n",
      "VVVET\n",
      "QCVCE\n",
      "QQEEQ\n",
      "EVCT\n",
      "QCVTC\n",
      "TETET\n",
      "TECT\n",
      "TEVCT\n",
      "CEET\n",
      "QQCEC\n",
      "QQVCC\n",
      "TCEVT\n",
      "QETCT\n",
      "QVVET\n",
      "QCVVT\n",
      "QVET\n",
      "VVVCT\n",
      "ETTTC\n",
      "VVVQT\n",
      "VEVET\n",
      "EVVCC\n",
      "QTVVC\n",
      "QCVVC\n",
      "QQVEC\n",
      "QTVET\n",
      "TEEET\n",
      "VTE\n",
      "QQT\n",
      "QCCEE\n",
      "QTVVT\n",
      "QQE\n",
      "CQE\n",
      "QCCEC\n",
      "QEVET\n",
      "QVCET\n",
      "QQVQT\n",
      "QETET\n",
      "QEEQT\n",
      "VVVVT\n",
      "QTET\n",
      "QVVQT\n",
      "VQEET\n",
      "QQCET\n",
      "QCEEC\n",
      "CVVCT\n",
      "QQVET\n",
      "QEVTT\n",
      "QQVTT\n",
      "QVCEQ\n",
      "TECET\n",
      "TQVET\n",
      "QTCEC\n",
      "TQET\n",
      "VVVTT\n",
      "TVVTT\n",
      "QCEET\n",
      "ETE\n",
      "EVVVT\n",
      "VEVCT\n",
      "TQEET\n",
      "EEVEC\n",
      "QCVEC\n",
      "QTCVC\n",
      "QVVTT\n",
      "QQEET\n",
      "QEEET\n",
      "CEVCE\n",
      "QEECT\n",
      "QQVVT\n",
      "CEVCT\n",
      "CTCV\n",
      "VQVCT\n",
      "TCTVT\n",
      "QEVQT\n",
      "QVVVT\n",
      "TCEET\n",
      "CECET\n",
      "TVCT\n",
      "QEVVT\n",
      "QEVCT\n",
      "QECET\n",
      "VQVET\n",
      "QCVET\n",
      "QQET\n",
      "QCVCT\n",
      "QCTTC\n",
      "TEVET\n",
      "QQVCT\n",
      "QVCTQ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_166)):\n",
    "    if sum(freq >= fTC5_166[l] for freq in fTC5null_166[l]) < 5:\n",
    "        print(setTC5_166[l], fTC5_166[l], sum(freq >= fTC5_166[l] for freq in fTC5null_166[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17780d30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "CEVET\n",
      "QQVEQ\n",
      "VVVET\n",
      "QQEEQ\n",
      "QVVET\n",
      "VVVQT\n",
      "VEVET\n",
      "TEEET\n",
      "QQT\n",
      "QEVET\n",
      "QQVQT\n",
      "QVVQT\n",
      "QQVET\n",
      "QQVTT\n",
      "VVVTT\n",
      "QCVEC\n",
      "QTCVC\n",
      "QVVTT\n",
      "QQEET\n",
      "QQVVT\n",
      "CEVCT\n",
      "QEVQT\n",
      "QVVVT\n",
      "TVCT\n",
      "QEVCT\n",
      "VQVET\n",
      "TEVET\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_166)):\n",
    "    if sum(freq >= fTC5_166[l] for freq in fTC5null_166[l]) < 1:\n",
    "        print(setTC5_166[l], fTC5_166[l], sum(freq >= fTC5_166[l] for freq in fTC5null_166[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202eaf83",
   "metadata": {},
   "source": [
    "# 167 (C) AGI - (Q) MER - (E) ALI - (T) MBT - (ε) URC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94403dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_167 = max(min(Date_AGI), min(Date_MER), min(Date_ALI), min(Date_MBT), min(Date_URC))\n",
    "end_167 = min(max(Date_AGI), max(Date_MER), max(Date_ALI), max(Date_MBT), max(Date_URC))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_167_1 = Date_AGI.index(start_167)\n",
    "AGI_167_2 = Date_AGI.index(end_167)\n",
    "\n",
    "MER_167_1 = Date_MER.index(start_167)\n",
    "MER_167_2 = Date_MER.index(end_167)\n",
    "\n",
    "ALI_167_1 = Date_ALI.index(start_167)\n",
    "ALI_167_2 = Date_ALI.index(end_167)\n",
    "\n",
    "MBT_167_1 = Date_MBT.index(start_167)\n",
    "MBT_167_2 = Date_MBT.index(end_167)\n",
    "\n",
    "URC_167_1 = Date_URC.index(start_167)\n",
    "URC_167_2 = Date_URC.index(end_167)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C167 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_167_1:AGI_167_2])\n",
    "Q167 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_167_1:MER_167_2])\n",
    "E167 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_167_1:ALI_167_2])\n",
    "T167 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_167_1:MBT_167_2])\n",
    "ε167 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_167_1:URC_167_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C167 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q167 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "E167 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "T167 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε167 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7ff8c52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_167 = []\n",
    "st_167 = []\n",
    "n = 1\n",
    "while n < len(C167):\n",
    "    sc_167 = ''\n",
    "    if C167[n] > C167[n-1]:\n",
    "        sc_167 = sc_167 + 'C'\n",
    "    if Q167[n] > Q167[n-1]:\n",
    "        sc_167 = sc_167 + 'Q'\n",
    "    if E167[n] > E167[n-1]:\n",
    "        sc_167 = sc_167 + 'E'\n",
    "    if T167[n] > T167[n-1]:\n",
    "        sc_167 = sc_167 + 'T'\n",
    "    if ε167[n] > ε167[n-1]:\n",
    "        sc_167 = sc_167 + 'ε'\n",
    "    if len(sc_167) > 0:\n",
    "        st_167.append(sc_167)\n",
    "    else:\n",
    "        STC_167.append(st_167)\n",
    "        st_167 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_167 = STC_167.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_167 = [ st_167 for st_167 in STC_167 if len(st_167) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_167 = len(C167)\n",
    "lmax_167 = 0\n",
    "for st_167 in STC_167:\n",
    "    if len(st_167) < lmin_167:\n",
    "        lmin_167 = len(st_167)\n",
    "    if len(st_167) > lmax_167:\n",
    "        lmax_167 = len(st_167)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_167 = [ st_167 for st_167 in STC_167 if len(st_167) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_167 = []\n",
    "for n in range(len(STC5_167)):\n",
    "    tc_167 = [ u for u in STC5_167[n][0] ]\n",
    "    for k in range(1, len(STC5_167[n])):\n",
    "        tc_167 = [ u+v for u in tc_167 for v in STC5_167[n][k] ]\n",
    "    TC5_167 = TC5_167 + tc_167\n",
    "setTC5_167 = list(set(TC5_167))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_167 = [ TC5_167.count(setTC5_167[l]) for l in range(len(setTC5_167)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_167 = [ [] for l in range(len(setTC5_167)) ]\n",
    "for s in range(167):\n",
    "    STC5null_167 = [ list(st_167) for st_167 in STC5_167]\n",
    "    for st_167 in STC5null_167:\n",
    "        np.random.shuffle(st_167)\n",
    "    TC5null_167= []\n",
    "    for n in range(len(STC5null_167)):\n",
    "        tc_167 = [ u for u in STC5null_167[n][0] ]\n",
    "        for k in range(1, len(STC5null_167[n])):\n",
    "            tc_167 = [ u+v for u in tc_167 for v in STC5null_167[n][k] ]\n",
    "        TC5null_167= TC5null_167+ tc_167\n",
    "    for l in range(len(setTC5_167)):\n",
    "        if TC5null_167.count(setTC5_167[l]) > 0:\n",
    "            fTC5null_167[l].append(TC5null_167.count(setTC5_167[l]))\n",
    "        else:\n",
    "            fTC5null_167[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da4a2e2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "QεCET\n",
      "ECTεQ\n",
      "QCTQT\n",
      "TETET\n",
      "εQεQ\n",
      "TεCEE\n",
      "TεεQε\n",
      "TTEQε\n",
      "CCCεQ\n",
      "QεεEQ\n",
      "QεTεE\n",
      "CQTQQ\n",
      "QεCEE\n",
      "TCCεQ\n",
      "QεCεE\n",
      "TECEQ\n",
      "CεEEQ\n",
      "TEEET\n",
      "QECEQ\n",
      "TQCET\n",
      "QTT\n",
      "QQT\n",
      "EεCEQ\n",
      "CεCEQ\n",
      "TεεEQ\n",
      "CTC\n",
      "CTTT\n",
      "CCQεQ\n",
      "TECEE\n",
      "εQQQ\n",
      "TECET\n",
      "TQCEQ\n",
      "QCTεE\n",
      "ECCεQ\n",
      "εQCQ\n",
      "CECEQ\n",
      "TCTεT\n",
      "TQEET\n",
      "QεCEQ\n",
      "QQEET\n",
      "QεCEC\n",
      "CεCEC\n",
      "TεCEC\n",
      "TεCET\n",
      "TεCEQ\n",
      "QCQεQ\n",
      "QCTεT\n",
      "TεEEQ\n",
      "CECET\n",
      "CCεεT\n",
      "εQTQ\n",
      "ECTεε\n",
      "CεCEE\n",
      "CECEE\n",
      "ECTεT\n",
      "CεCET\n",
      "Qεε\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_167)):\n",
    "    if sum(freq >= fTC5_167[l] for freq in fTC5null_167[l]) < 5:\n",
    "        print(setTC5_167[l], fTC5_167[l], sum(freq >= fTC5_167[l] for freq in fTC5null_167[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32c0f77b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "EεCEQ\n",
      "CεCEQ\n",
      "TεεEQ\n",
      "TECET\n",
      "QεCEQ\n",
      "QεCEC\n",
      "TεCEQ\n",
      "QCTεT\n",
      "TεEEQ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_167)):\n",
    "    if sum(freq >= fTC5_167[l] for freq in fTC5null_167[l]) < 1:\n",
    "        print(setTC5_167[l], fTC5_167[l], sum(freq >= fTC5_167[l] for freq in fTC5null_167[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aed0fa3",
   "metadata": {},
   "source": [
    "# 168 (C) AGI - (Q) MER - (E) ALI - (T) MBT - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f53f308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_168 = max(min(Date_AGI), min(Date_MER), min(Date_ALI), min(Date_MBT), min(Date_PGOLD))\n",
    "end_168 = min(max(Date_AGI), max(Date_MER), max(Date_ALI), max(Date_MBT), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_168_1 = Date_AGI.index(start_168)\n",
    "AGI_168_2 = Date_AGI.index(end_168)\n",
    "\n",
    "MER_168_1 = Date_MER.index(start_168)\n",
    "MER_168_2 = Date_MER.index(end_168)\n",
    "\n",
    "ALI_168_1 = Date_ALI.index(start_168)\n",
    "ALI_168_2 = Date_ALI.index(end_168)\n",
    "\n",
    "MBT_168_1 = Date_MBT.index(start_168)\n",
    "MBT_168_2 = Date_MBT.index(end_168)\n",
    "\n",
    "PGOLD_168_1 = Date_PGOLD.index(start_168)\n",
    "PGOLD_168_2 = Date_PGOLD.index(end_168)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C168 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_168_1:AGI_168_2])\n",
    "Q168 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_168_1:MER_168_2])\n",
    "E168 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_168_1:ALI_168_2])\n",
    "T168 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_168_1:MBT_168_2])\n",
    "W168 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_168_1:PGOLD_168_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C168 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q168 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "E168 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "T168 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "W168 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2758e7f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_168 = []\n",
    "st_168 = []\n",
    "n = 1\n",
    "while n < len(C168):\n",
    "    sc_168 = ''\n",
    "    if C168[n] > C168[n-1]:\n",
    "        sc_168 = sc_168 + 'C'\n",
    "    if Q168[n] > Q168[n-1]:\n",
    "        sc_168 = sc_168 + 'Q'\n",
    "    if E168[n] > E168[n-1]:\n",
    "        sc_168 = sc_168 + 'E'\n",
    "    if T168[n] > T168[n-1]:\n",
    "        sc_168 = sc_168 + 'T'\n",
    "    if W168[n] > W168[n-1]:\n",
    "        sc_168 = sc_168 + 'W'\n",
    "    if len(sc_168) > 0:\n",
    "        st_168.append(sc_168)\n",
    "    else:\n",
    "        STC_168.append(st_168)\n",
    "        st_168 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_168 = STC_168.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_168 = [ st_168 for st_168 in STC_168 if len(st_168) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_168 = len(C168)\n",
    "lmax_168 = 0\n",
    "for st_168 in STC_168:\n",
    "    if len(st_168) < lmin_168:\n",
    "        lmin_168 = len(st_168)\n",
    "    if len(st_168) > lmax_168:\n",
    "        lmax_168 = len(st_168)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_168 = [ st_168 for st_168 in STC_168 if len(st_168) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_168 = []\n",
    "for n in range(len(STC5_168)):\n",
    "    tc_168 = [ u for u in STC5_168[n][0] ]\n",
    "    for k in range(1, len(STC5_168[n])):\n",
    "        tc_168 = [ u+v for u in tc_168 for v in STC5_168[n][k] ]\n",
    "    TC5_168 = TC5_168 + tc_168\n",
    "setTC5_168 = list(set(TC5_168))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_168 = [ TC5_168.count(setTC5_168[l]) for l in range(len(setTC5_168)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_168 = [ [] for l in range(len(setTC5_168)) ]\n",
    "for s in range(168):\n",
    "    STC5null_168 = [ list(st_168) for st_168 in STC5_168]\n",
    "    for st_168 in STC5null_168:\n",
    "        np.random.shuffle(st_168)\n",
    "    TC5null_168= []\n",
    "    for n in range(len(STC5null_168)):\n",
    "        tc_168 = [ u for u in STC5null_168[n][0] ]\n",
    "        for k in range(1, len(STC5null_168[n])):\n",
    "            tc_168 = [ u+v for u in tc_168 for v in STC5null_168[n][k] ]\n",
    "        TC5null_168= TC5null_168+ tc_168\n",
    "    for l in range(len(setTC5_168)):\n",
    "        if TC5null_168.count(setTC5_168[l]) > 0:\n",
    "            fTC5null_168[l].append(TC5null_168.count(setTC5_168[l]))\n",
    "        else:\n",
    "            fTC5null_168[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e25d207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "QWCWE\n",
      "TEEQE\n",
      "QWCQE\n",
      "EEWTW\n",
      "CCCQW\n",
      "QETTW\n",
      "ECT\n",
      "WEETW\n",
      "WQTCW\n",
      "CETCW\n",
      "QQQTW\n",
      "QWEWE\n",
      "WEEWE\n",
      "CQCEW\n",
      "CCCTW\n",
      "QWEWW\n",
      "WEWTW\n",
      "QETWE\n",
      "QWCWW\n",
      "CCQQW\n",
      "TETTW\n",
      "CQETW\n",
      "WECTW\n",
      "QQQT\n",
      "QEEQE\n",
      "WCTCW\n",
      "QWEQE\n",
      "WECCW\n",
      "CQCTW\n",
      "TEWTW\n",
      "WETTW\n",
      "QWEE\n",
      "ECWTW\n",
      "TCCQW\n",
      "CQCCW\n",
      "QEEWE\n",
      "TECTW\n",
      "ECCQW\n",
      "WETQW\n",
      "WQT\n",
      "QECWE\n",
      "WCTTW\n",
      "CTCTW\n",
      "TETCW\n",
      "WETCW\n",
      "QECQE\n",
      "CCCCW\n",
      "CEECW\n",
      "QWTWW\n",
      "QCCQE\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_168)):\n",
    "    if sum(freq >= fTC5_168[l] for freq in fTC5null_168[l]) < 5:\n",
    "        print(setTC5_168[l], fTC5_168[l], sum(freq >= fTC5_168[l] for freq in fTC5null_168[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3d0fe83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "CCCQW\n",
      "TETTW\n",
      "WECTW\n",
      "CQCTW\n",
      "WETTW\n",
      "QWEE\n",
      "TECTW\n",
      "ECCQW\n",
      "TETCW\n",
      "QECQE\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_168)):\n",
    "    if sum(freq >= fTC5_168[l] for freq in fTC5null_168[l]) < 1:\n",
    "        print(setTC5_168[l], fTC5_168[l], sum(freq >= fTC5_168[l] for freq in fTC5null_168[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710e0a77",
   "metadata": {},
   "source": [
    "# 169 (C) AGI - (Q) MER - (E) ALI - (V) TEL - (ε) URC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7043a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_169 = max(min(Date_AGI), min(Date_MER), min(Date_ALI), min(Date_TEL), min(Date_URC))\n",
    "end_169 = min(max(Date_AGI), max(Date_MER), max(Date_ALI), max(Date_TEL), max(Date_URC))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_169_1 = Date_AGI.index(start_169)\n",
    "AGI_169_2 = Date_AGI.index(end_169)\n",
    "\n",
    "MER_169_1 = Date_MER.index(start_169)\n",
    "MER_169_2 = Date_MER.index(end_169)\n",
    "\n",
    "ALI_169_1 = Date_ALI.index(start_169)\n",
    "ALI_169_2 = Date_ALI.index(end_169)\n",
    "\n",
    "TEL_169_1 = Date_TEL.index(start_169)\n",
    "TEL_169_2 = Date_TEL.index(end_169)\n",
    "\n",
    "URC_169_1 = Date_URC.index(start_169)\n",
    "URC_169_2 = Date_URC.index(end_169)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C169 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_169_1:AGI_169_2])\n",
    "Q169 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_169_1:MER_169_2])\n",
    "E169 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_169_1:ALI_169_2])\n",
    "V169 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_169_1:TEL_169_2])\n",
    "ε169 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_169_1:URC_169_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C169 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q169 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "E169 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "V169 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε169 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f9d041b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_169 = []\n",
    "st_169 = []\n",
    "n = 1\n",
    "while n < len(C169):\n",
    "    sc_169 = ''\n",
    "    if C169[n] > C169[n-1]:\n",
    "        sc_169 = sc_169 + 'C'\n",
    "    if Q169[n] > Q169[n-1]:\n",
    "        sc_169 = sc_169 + 'Q'\n",
    "    if E169[n] > E169[n-1]:\n",
    "        sc_169 = sc_169 + 'E'\n",
    "    if V169[n] > V169[n-1]:\n",
    "        sc_169 = sc_169 + 'V'\n",
    "    if ε169[n] > ε169[n-1]:\n",
    "        sc_169 = sc_169 + 'ε'\n",
    "    if len(sc_169) > 0:\n",
    "        st_169.append(sc_169)\n",
    "    else:\n",
    "        STC_169.append(st_169)\n",
    "        st_169 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_169 = STC_169.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_169 = [ st_169 for st_169 in STC_169 if len(st_169) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_169 = len(C169)\n",
    "lmax_169 = 0\n",
    "for st_169 in STC_169:\n",
    "    if len(st_169) < lmin_169:\n",
    "        lmin_169 = len(st_169)\n",
    "    if len(st_169) > lmax_169:\n",
    "        lmax_169 = len(st_169)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_169 = [ st_169 for st_169 in STC_169 if len(st_169) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_169 = []\n",
    "for n in range(len(STC5_169)):\n",
    "    tc_169 = [ u for u in STC5_169[n][0] ]\n",
    "    for k in range(1, len(STC5_169[n])):\n",
    "        tc_169 = [ u+v for u in tc_169 for v in STC5_169[n][k] ]\n",
    "    TC5_169 = TC5_169 + tc_169\n",
    "setTC5_169 = list(set(TC5_169))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_169 = [ TC5_169.count(setTC5_169[l]) for l in range(len(setTC5_169)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_169 = [ [] for l in range(len(setTC5_169)) ]\n",
    "for s in range(169):\n",
    "    STC5null_169 = [ list(st_169) for st_169 in STC5_169]\n",
    "    for st_169 in STC5null_169:\n",
    "        np.random.shuffle(st_169)\n",
    "    TC5null_169= []\n",
    "    for n in range(len(STC5null_169)):\n",
    "        tc_169 = [ u for u in STC5null_169[n][0] ]\n",
    "        for k in range(1, len(STC5null_169[n])):\n",
    "            tc_169 = [ u+v for u in tc_169 for v in STC5null_169[n][k] ]\n",
    "        TC5null_169= TC5null_169+ tc_169\n",
    "    for l in range(len(setTC5_169)):\n",
    "        if TC5null_169.count(setTC5_169[l]) > 0:\n",
    "            fTC5null_169[l].append(TC5null_169.count(setTC5_169[l]))\n",
    "        else:\n",
    "            fTC5null_169[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90e6dabe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "CQQε\n",
      "QCCεE\n",
      "VVCV\n",
      "QCεVε\n",
      "QQEEQ\n",
      "CCQC\n",
      "QCεEE\n",
      "QEEEQ\n",
      "εVVEε\n",
      "CVVCε\n",
      "εVCCV\n",
      "VCQE\n",
      "QεCEE\n",
      "εVVEV\n",
      "CEεC\n",
      "εVCCε\n",
      "CQEQQ\n",
      "εVVQE\n",
      "εVVVε\n",
      "QCVVC\n",
      "CCQV\n",
      "QCEVε\n",
      "CQQQ\n",
      "QCCEE\n",
      "CVC\n",
      "VEεV\n",
      "QεVEC\n",
      "εEεQ\n",
      "CEεV\n",
      "VVQC\n",
      "εEεε\n",
      "QCεεE\n",
      "εVVCε\n",
      "εEVE\n",
      "εEεV\n",
      "CVQE\n",
      "CEQEV\n",
      "QCCVE\n",
      "CEQC\n",
      "CCεEV\n",
      "QCQVE\n",
      "εEεE\n",
      "VQεV\n",
      "QCCVC\n",
      "CEEC\n",
      "CQQE\n",
      "CEQV\n",
      "VCQC\n",
      "QVCCV\n",
      "εVVEE\n",
      "εEQE\n",
      "CCQE\n",
      "VVVCε\n",
      "CQQV\n",
      "QεEεE\n",
      "QQEEε\n",
      "VVεV\n",
      "CEQE\n",
      "εVεEE\n",
      "VEQC\n",
      "QCEεE\n",
      "CQQC\n",
      "VQEQV\n",
      "QCEEε\n",
      "EEεEV\n",
      "εVVεE\n",
      "CCεVV\n",
      "QCεVE\n",
      "QCEVC\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_169)):\n",
    "    if sum(freq >= fTC5_169[l] for freq in fTC5null_169[l]) < 5:\n",
    "        print(setTC5_169[l], fTC5_169[l], sum(freq >= fTC5_169[l] for freq in fTC5null_169[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30f965dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "QQEEQ\n",
      "CCQV\n",
      "VEεV\n",
      "QCεεE\n",
      "εEεV\n",
      "VCQC\n",
      "εVVEE\n",
      "CCQE\n",
      "CEQE\n",
      "QCEεE\n",
      "QCEEε\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_169)):\n",
    "    if sum(freq >= fTC5_169[l] for freq in fTC5null_169[l]) < 1:\n",
    "        print(setTC5_169[l], fTC5_169[l], sum(freq >= fTC5_169[l] for freq in fTC5null_169[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b428d0",
   "metadata": {},
   "source": [
    "# 170 (C) AGI - (Q) MER - (E) ALI - (V) TEL - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0197215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_170 = max(min(Date_AGI), min(Date_MER), min(Date_ALI), min(Date_TEL), min(Date_PGOLD))\n",
    "end_170 = min(max(Date_AGI), max(Date_MER), max(Date_ALI), max(Date_TEL), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_170_1 = Date_AGI.index(start_170)\n",
    "AGI_170_2 = Date_AGI.index(end_170)\n",
    "\n",
    "MER_170_1 = Date_MER.index(start_170)\n",
    "MER_170_2 = Date_MER.index(end_170)\n",
    "\n",
    "ALI_170_1 = Date_ALI.index(start_170)\n",
    "ALI_170_2 = Date_ALI.index(end_170)\n",
    "\n",
    "TEL_170_1 = Date_TEL.index(start_170)\n",
    "TEL_170_2 = Date_TEL.index(end_170)\n",
    "\n",
    "PGOLD_170_1 = Date_PGOLD.index(start_170)\n",
    "PGOLD_170_2 = Date_PGOLD.index(end_170)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C170 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_170_1:AGI_170_2])\n",
    "Q170 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_170_1:MER_170_2])\n",
    "E170 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_170_1:ALI_170_2])\n",
    "V170 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_170_1:TEL_170_2])\n",
    "W170 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_170_1:PGOLD_170_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C170 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q170 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "E170 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "V170 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "W170 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7d72890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_170 = []\n",
    "st_170 = []\n",
    "n = 1\n",
    "while n < len(C170):\n",
    "    sc_170 = ''\n",
    "    if C170[n] > C170[n-1]:\n",
    "        sc_170 = sc_170 + 'C'\n",
    "    if Q170[n] > Q170[n-1]:\n",
    "        sc_170 = sc_170 + 'Q'\n",
    "    if E170[n] > E170[n-1]:\n",
    "        sc_170 = sc_170 + 'E'\n",
    "    if V170[n] > V170[n-1]:\n",
    "        sc_170 = sc_170 + 'V'\n",
    "    if W170[n] > W170[n-1]:\n",
    "        sc_170 = sc_170 + 'W'\n",
    "    if len(sc_170) > 0:\n",
    "        st_170.append(sc_170)\n",
    "    else:\n",
    "        STC_170.append(st_170)\n",
    "        st_170 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_170 = STC_170.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_170 = [ st_170 for st_170 in STC_170 if len(st_170) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_170 = len(C170)\n",
    "lmax_170 = 0\n",
    "for st_170 in STC_170:\n",
    "    if len(st_170) < lmin_170:\n",
    "        lmin_170 = len(st_170)\n",
    "    if len(st_170) > lmax_170:\n",
    "        lmax_170 = len(st_170)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_170 = [ st_170 for st_170 in STC_170 if len(st_170) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_170 = []\n",
    "for n in range(len(STC5_170)):\n",
    "    tc_170 = [ u for u in STC5_170[n][0] ]\n",
    "    for k in range(1, len(STC5_170[n])):\n",
    "        tc_170 = [ u+v for u in tc_170 for v in STC5_170[n][k] ]\n",
    "    TC5_170 = TC5_170 + tc_170\n",
    "setTC5_170 = list(set(TC5_170))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_170 = [ TC5_170.count(setTC5_170[l]) for l in range(len(setTC5_170)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_170 = [ [] for l in range(len(setTC5_170)) ]\n",
    "for s in range(170):\n",
    "    STC5null_170 = [ list(st_170) for st_170 in STC5_170]\n",
    "    for st_170 in STC5null_170:\n",
    "        np.random.shuffle(st_170)\n",
    "    TC5null_170= []\n",
    "    for n in range(len(STC5null_170)):\n",
    "        tc_170 = [ u for u in STC5null_170[n][0] ]\n",
    "        for k in range(1, len(STC5null_170[n])):\n",
    "            tc_170 = [ u+v for u in tc_170 for v in STC5null_170[n][k] ]\n",
    "        TC5null_170= TC5null_170+ tc_170\n",
    "    for l in range(len(setTC5_170)):\n",
    "        if TC5null_170.count(setTC5_170[l]) > 0:\n",
    "            fTC5null_170[l].append(TC5null_170.count(setTC5_170[l]))\n",
    "        else:\n",
    "            fTC5null_170[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a23d734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "WVVCW\n",
      "ECW\n",
      "QCWVC\n",
      "WCCCW\n",
      "CEVEW\n",
      "WVCCW\n",
      "QQQE\n",
      "QWEWW\n",
      "QCEVW\n",
      "VVQVW\n",
      "QQWE\n",
      "QVCWW\n",
      "WQEVW\n",
      "QCEWE\n",
      "WVVQW\n",
      "WCECW\n",
      "CVECW\n",
      "WECCW\n",
      "QEEEW\n",
      "QVCCW\n",
      "QEQVC\n",
      "QQVE\n",
      "WVWCW\n",
      "WVVEW\n",
      "VVEC\n",
      "QCWVQ\n",
      "WQCCW\n",
      "QCQVC\n",
      "QCECE\n",
      "WVECW\n",
      "WCEVW\n",
      "QEWVW\n",
      "QVWVQ\n",
      "QCCVC\n",
      "CCQ\n",
      "QEWVC\n",
      "QCECW\n",
      "VVCCW\n",
      "QEWVQ\n",
      "WCEVE\n",
      "QQWVQ\n",
      "QEECW\n",
      "WQECW\n",
      "QCWVW\n",
      "CEECW\n",
      "VVQCW\n",
      "QCEVC\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_170)):\n",
    "    if sum(freq >= fTC5_170[l] for freq in fTC5null_170[l]) < 5:\n",
    "        print(setTC5_170[l], fTC5_170[l], sum(freq >= fTC5_170[l] for freq in fTC5null_170[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "648d22c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "WVCCW\n",
      "QVCWW\n",
      "QCQVC\n",
      "CCQ\n",
      "QEWVQ\n",
      "WQECW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_170)):\n",
    "    if sum(freq >= fTC5_170[l] for freq in fTC5null_170[l]) < 1:\n",
    "        print(setTC5_170[l], fTC5_170[l], sum(freq >= fTC5_170[l] for freq in fTC5null_170[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ab8cf",
   "metadata": {},
   "source": [
    "# 171 (C) AGI - (Q) MER - (E) ALI - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49d1dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_171 = max(min(Date_AGI), min(Date_MER), min(Date_ALI), min(Date_URC), min(Date_PGOLD))\n",
    "end_171 = min(max(Date_AGI), max(Date_MER), max(Date_ALI), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_171_1 = Date_AGI.index(start_171)\n",
    "AGI_171_2 = Date_AGI.index(end_171)\n",
    "\n",
    "MER_171_1 = Date_MER.index(start_171)\n",
    "MER_171_2 = Date_MER.index(end_171)\n",
    "\n",
    "ALI_171_1 = Date_ALI.index(start_171)\n",
    "ALI_171_2 = Date_ALI.index(end_171)\n",
    "\n",
    "URC_171_1 = Date_URC.index(start_171)\n",
    "URC_171_2 = Date_URC.index(end_171)\n",
    "\n",
    "PGOLD_171_1 = Date_PGOLD.index(start_171)\n",
    "PGOLD_171_2 = Date_PGOLD.index(end_171)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C171 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_171_1:AGI_171_2])\n",
    "Q171 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_171_1:MER_171_2])\n",
    "E171 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_171_1:ALI_171_2])\n",
    "ε171 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_171_1:URC_171_2])\n",
    "W171 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_171_1:PGOLD_171_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C171 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q171 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "E171 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε171 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W171 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86d39852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_171 = []\n",
    "st_171 = []\n",
    "n = 1\n",
    "while n < len(C171):\n",
    "    sc_171 = ''\n",
    "    if C171[n] > C171[n-1]:\n",
    "        sc_171 = sc_171 + 'C'\n",
    "    if Q171[n] > Q171[n-1]:\n",
    "        sc_171 = sc_171 + 'Q'\n",
    "    if E171[n] > E171[n-1]:\n",
    "        sc_171 = sc_171 + 'E'\n",
    "    if ε171[n] > ε171[n-1]:\n",
    "        sc_171 = sc_171 + 'ε'\n",
    "    if W171[n] > W171[n-1]:\n",
    "        sc_171 = sc_171 + 'W'\n",
    "    if len(sc_171) > 0:\n",
    "        st_171.append(sc_171)\n",
    "    else:\n",
    "        STC_171.append(st_171)\n",
    "        st_171 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_171 = STC_171.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_171 = [ st_171 for st_171 in STC_171 if len(st_171) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_171 = len(C171)\n",
    "lmax_171 = 0\n",
    "for st_171 in STC_171:\n",
    "    if len(st_171) < lmin_171:\n",
    "        lmin_171 = len(st_171)\n",
    "    if len(st_171) > lmax_171:\n",
    "        lmax_171 = len(st_171)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_171 = [ st_171 for st_171 in STC_171 if len(st_171) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_171 = []\n",
    "for n in range(len(STC5_171)):\n",
    "    tc_171 = [ u for u in STC5_171[n][0] ]\n",
    "    for k in range(1, len(STC5_171[n])):\n",
    "        tc_171 = [ u+v for u in tc_171 for v in STC5_171[n][k] ]\n",
    "    TC5_171 = TC5_171 + tc_171\n",
    "setTC5_171 = list(set(TC5_171))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_171 = [ TC5_171.count(setTC5_171[l]) for l in range(len(setTC5_171)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_171 = [ [] for l in range(len(setTC5_171)) ]\n",
    "for s in range(171):\n",
    "    STC5null_171 = [ list(st_171) for st_171 in STC5_171]\n",
    "    for st_171 in STC5null_171:\n",
    "        np.random.shuffle(st_171)\n",
    "    TC5null_171= []\n",
    "    for n in range(len(STC5null_171)):\n",
    "        tc_171 = [ u for u in STC5null_171[n][0] ]\n",
    "        for k in range(1, len(STC5null_171[n])):\n",
    "            tc_171 = [ u+v for u in tc_171 for v in STC5null_171[n][k] ]\n",
    "        TC5null_171= TC5null_171+ tc_171\n",
    "    for l in range(len(setTC5_171)):\n",
    "        if TC5null_171.count(setTC5_171[l]) > 0:\n",
    "            fTC5null_171[l].append(TC5null_171.count(setTC5_171[l]))\n",
    "        else:\n",
    "            fTC5null_171[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac5dea24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "QεεεE\n",
      "QCCεE\n",
      "QεεQE\n",
      "WECW\n",
      "QWCQE\n",
      "QεCQE\n",
      "εQεQ\n",
      "CCCQW\n",
      "CCεεW\n",
      "QWεWE\n",
      "εQCE\n",
      "ECεεW\n",
      "QεQεQ\n",
      "QWEWE\n",
      "QCCQC\n",
      "CCCεW\n",
      "CQECW\n",
      "QWεQE\n",
      "CECCW\n",
      "WWεWC\n",
      "QWεEE\n",
      "QεεεW\n",
      "ECCQC\n",
      "QQWE\n",
      "ECεεC\n",
      "QCεεW\n",
      "EECQC\n",
      "ECε\n",
      "QWεWQ\n",
      "QCεεE\n",
      "ECεQC\n",
      "QEεεE\n",
      "QWεWW\n",
      "QεQQQ\n",
      "QεEWE\n",
      "QεCQQ\n",
      "EQW\n",
      "εEWE\n",
      "εW\n",
      "εCCE\n",
      "εECE\n",
      "εECW\n",
      "QEWE\n",
      "QεεWE\n",
      "QWεεW\n",
      "WEW\n",
      "CQCCW\n",
      "CQεCW\n",
      "EEεQC\n",
      "CCεQW\n",
      "CQεEW\n",
      "EW\n",
      "CεECW\n",
      "QWεεE\n",
      "εQWE\n",
      "QWεWC\n",
      "QEεWC\n",
      "CEεεW\n",
      "CEECW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_171)):\n",
    "    if sum(freq >= fTC5_171[l] for freq in fTC5null_171[l]) < 5:\n",
    "        print(setTC5_171[l], fTC5_171[l], sum(freq >= fTC5_171[l] for freq in fTC5null_171[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d47a5789",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "QεεεE\n",
      "CCCεW\n",
      "QCεεE\n",
      "εEWE\n",
      "QEWE\n",
      "QεεWE\n",
      "CQεEW\n",
      "CEECW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_171)):\n",
    "    if sum(freq >= fTC5_171[l] for freq in fTC5null_171[l]) < 1:\n",
    "        print(setTC5_171[l], fTC5_171[l], sum(freq >= fTC5_171[l] for freq in fTC5null_171[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4d88bf",
   "metadata": {},
   "source": [
    "# 172 (C) AGI - (Q) MER - (Z) SECB - (T) MBT - (V) TEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9431ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_172 = max(min(Date_AGI), min(Date_MER), min(Date_SECB), min(Date_MBT), min(Date_TEL))\n",
    "end_172 = min(max(Date_AGI), max(Date_MER), max(Date_SECB), max(Date_MBT), max(Date_TEL))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_172_1 = Date_AGI.index(start_172)\n",
    "AGI_172_2 = Date_AGI.index(end_172)\n",
    "\n",
    "MER_172_1 = Date_MER.index(start_172)\n",
    "MER_172_2 = Date_MER.index(end_172)\n",
    "\n",
    "SECB_172_1 = Date_SECB.index(start_172)\n",
    "SECB_172_2 = Date_SECB.index(end_172)\n",
    "\n",
    "MBT_172_1 = Date_MBT.index(start_172)\n",
    "MBT_172_2 = Date_MBT.index(end_172)\n",
    "\n",
    "TEL_172_1 = Date_TEL.index(start_172)\n",
    "TEL_172_2 = Date_TEL.index(end_172)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C172 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_172_1:AGI_172_2])\n",
    "Q172 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_172_1:MER_172_2])\n",
    "Z172 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_172_1:SECB_172_2])\n",
    "T172 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_172_1:MBT_172_2])\n",
    "V172 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_172_1:TEL_172_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C172 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q172 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z172 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T172 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V172 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a3ed527",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_172 = []\n",
    "st_172 = []\n",
    "n = 1\n",
    "while n < len(C172):\n",
    "    sc_172 = ''\n",
    "    if C172[n] > C172[n-1]:\n",
    "        sc_172 = sc_172 + 'C'\n",
    "    if Q172[n] > Q172[n-1]:\n",
    "        sc_172 = sc_172 + 'Q'\n",
    "    if Z172[n] > Z172[n-1]:\n",
    "        sc_172 = sc_172 + 'Z'\n",
    "    if T172[n] > T172[n-1]:\n",
    "        sc_172 = sc_172 + 'T'\n",
    "    if V172[n] > V172[n-1]:\n",
    "        sc_172 = sc_172 + 'V'\n",
    "    if len(sc_172) > 0:\n",
    "        st_172.append(sc_172)\n",
    "    else:\n",
    "        STC_172.append(st_172)\n",
    "        st_172 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_172 = STC_172.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_172 = [ st_172 for st_172 in STC_172 if len(st_172) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_172 = len(C172)\n",
    "lmax_172 = 0\n",
    "for st_172 in STC_172:\n",
    "    if len(st_172) < lmin_172:\n",
    "        lmin_172 = len(st_172)\n",
    "    if len(st_172) > lmax_172:\n",
    "        lmax_172 = len(st_172)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_172 = [ st_172 for st_172 in STC_172 if len(st_172) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_172 = []\n",
    "for n in range(len(STC5_172)):\n",
    "    tc_172 = [ u for u in STC5_172[n][0] ]\n",
    "    for k in range(1, len(STC5_172[n])):\n",
    "        tc_172 = [ u+v for u in tc_172 for v in STC5_172[n][k] ]\n",
    "    TC5_172 = TC5_172 + tc_172\n",
    "setTC5_172 = list(set(TC5_172))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_172 = [ TC5_172.count(setTC5_172[l]) for l in range(len(setTC5_172)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_172 = [ [] for l in range(len(setTC5_172)) ]\n",
    "for s in range(172):\n",
    "    STC5null_172 = [ list(st_172) for st_172 in STC5_172]\n",
    "    for st_172 in STC5null_172:\n",
    "        np.random.shuffle(st_172)\n",
    "    TC5null_172= []\n",
    "    for n in range(len(STC5null_172)):\n",
    "        tc_172 = [ u for u in STC5null_172[n][0] ]\n",
    "        for k in range(1, len(STC5null_172[n])):\n",
    "            tc_172 = [ u+v for u in tc_172 for v in STC5null_172[n][k] ]\n",
    "        TC5null_172= TC5null_172+ tc_172\n",
    "    for l in range(len(setTC5_172)):\n",
    "        if TC5null_172.count(setTC5_172[l]) > 0:\n",
    "            fTC5null_172[l].append(TC5null_172.count(setTC5_172[l]))\n",
    "        else:\n",
    "            fTC5null_172[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1355d597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "QQVZQ\n",
      "QCTCQ\n",
      "VVZTZ\n",
      "ZCZZZ\n",
      "CVTZ\n",
      "ZCZTT\n",
      "QQVZ\n",
      "QQTC\n",
      "QVZTQ\n",
      "VQVCC\n",
      "QVCZZ\n",
      "QVCTZ\n",
      "CVQTT\n",
      "QTVT\n",
      "QQVCC\n",
      "QCZZZ\n",
      "QZZZT\n",
      "TVCCZ\n",
      "VTVCC\n",
      "VVVZT\n",
      "VVVCT\n",
      "CVCTZ\n",
      "QZZTQ\n",
      "ZCTZC\n",
      "VVVQT\n",
      "QVZCZ\n",
      "VVCTZ\n",
      "QCZVT\n",
      "TVQVT\n",
      "VQVZQ\n",
      "QCZTZ\n",
      "QVVV\n",
      "TQVZT\n",
      "VVVZQ\n",
      "QVZZT\n",
      "CVTC\n",
      "TVVQT\n",
      "QVZTZ\n",
      "QZZZZ\n",
      "TVCTV\n",
      "ZTVV\n",
      "VVVVT\n",
      "QVVQT\n",
      "QVCZV\n",
      "QCZTC\n",
      "QCZVZ\n",
      "TVQTT\n",
      "VQVZV\n",
      "QVVZT\n",
      "VVVTT\n",
      "TVVTT\n",
      "ZCTCC\n",
      "QZCZZ\n",
      "ZVZZT\n",
      "CVCCZ\n",
      "QVCCZ\n",
      "QCZCZ\n",
      "ZCZVT\n",
      "QVZZZ\n",
      "VVVCC\n",
      "ZCZCC\n",
      "CTZT\n",
      "QQVVT\n",
      "QVVT\n",
      "QCVZZ\n",
      "QVCZQ\n",
      "QCZZT\n",
      "ZVZZZ\n",
      "TVCTT\n",
      "TVVVT\n",
      "QVVVT\n",
      "QVVCC\n",
      "QVCTV\n",
      "VVZTT\n",
      "QQVT\n",
      "QQVZT\n",
      "TZTZQ\n",
      "QTZVZ\n",
      "TVCTZ\n",
      "QVCZT\n",
      "QQTZ\n",
      "QQZZ\n",
      "ZCZCZ\n",
      "TVVZT\n",
      "QVCTQ\n",
      "VVCZZ\n",
      "QCCZZ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_172)):\n",
    "    if sum(freq >= fTC5_172[l] for freq in fTC5null_172[l]) < 5:\n",
    "        print(setTC5_172[l], fTC5_172[l], sum(freq >= fTC5_172[l] for freq in fTC5null_172[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7c9960b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "QQVZ\n",
      "QQTC\n",
      "VQVCC\n",
      "QVCZZ\n",
      "QVCTZ\n",
      "VVCTZ\n",
      "QVZZT\n",
      "ZTVV\n",
      "VVVVT\n",
      "TVQTT\n",
      "QVVZT\n",
      "VVVTT\n",
      "TVVTT\n",
      "QVCCZ\n",
      "QCZCZ\n",
      "ZCZVT\n",
      "QVZZZ\n",
      "VVVCC\n",
      "ZCZCC\n",
      "QVVT\n",
      "TVCTT\n",
      "QVCZT\n",
      "TVVZT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_172)):\n",
    "    if sum(freq >= fTC5_172[l] for freq in fTC5null_172[l]) < 1:\n",
    "        print(setTC5_172[l], fTC5_172[l], sum(freq >= fTC5_172[l] for freq in fTC5null_172[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336fe263",
   "metadata": {},
   "source": [
    "# 173 (C) AGI - (Q) MER - (Z) SECB - (T) MBT - (ε) URC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5468e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_173 = max(min(Date_AGI), min(Date_MER), min(Date_SECB), min(Date_MBT), min(Date_URC))\n",
    "end_173 = min(max(Date_AGI), max(Date_MER), max(Date_SECB), max(Date_MBT), max(Date_URC))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_173_1 = Date_AGI.index(start_173)\n",
    "AGI_173_2 = Date_AGI.index(end_173)\n",
    "\n",
    "MER_173_1 = Date_MER.index(start_173)\n",
    "MER_173_2 = Date_MER.index(end_173)\n",
    "\n",
    "SECB_173_1 = Date_SECB.index(start_173)\n",
    "SECB_173_2 = Date_SECB.index(end_173)\n",
    "\n",
    "MBT_173_1 = Date_MBT.index(start_173)\n",
    "MBT_173_2 = Date_MBT.index(end_173)\n",
    "\n",
    "URC_173_1 = Date_URC.index(start_173)\n",
    "URC_173_2 = Date_URC.index(end_173)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C173 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_173_1:AGI_173_2])\n",
    "Q173 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_173_1:MER_173_2])\n",
    "Z173 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_173_1:SECB_173_2])\n",
    "T173 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_173_1:MBT_173_2])\n",
    "ε173 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_173_1:URC_173_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C173 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q173 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z173 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T173 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε173 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c35137f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_173 = []\n",
    "st_173 = []\n",
    "n = 1\n",
    "while n < len(C173):\n",
    "    sc_173 = ''\n",
    "    if C173[n] > C173[n-1]:\n",
    "        sc_173 = sc_173 + 'C'\n",
    "    if Q173[n] > Q173[n-1]:\n",
    "        sc_173 = sc_173 + 'Q'\n",
    "    if Z173[n] > Z173[n-1]:\n",
    "        sc_173 = sc_173 + 'Z'\n",
    "    if T173[n] > T173[n-1]:\n",
    "        sc_173 = sc_173 + 'T'\n",
    "    if ε173[n] > ε173[n-1]:\n",
    "        sc_173 = sc_173 + 'ε'\n",
    "    if len(sc_173) > 0:\n",
    "        st_173.append(sc_173)\n",
    "    else:\n",
    "        STC_173.append(st_173)\n",
    "        st_173 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_173 = STC_173.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_173 = [ st_173 for st_173 in STC_173 if len(st_173) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_173 = len(C173)\n",
    "lmax_173 = 0\n",
    "for st_173 in STC_173:\n",
    "    if len(st_173) < lmin_173:\n",
    "        lmin_173 = len(st_173)\n",
    "    if len(st_173) > lmax_173:\n",
    "        lmax_173 = len(st_173)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_173 = [ st_173 for st_173 in STC_173 if len(st_173) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_173 = []\n",
    "for n in range(len(STC5_173)):\n",
    "    tc_173 = [ u for u in STC5_173[n][0] ]\n",
    "    for k in range(1, len(STC5_173[n])):\n",
    "        tc_173 = [ u+v for u in tc_173 for v in STC5_173[n][k] ]\n",
    "    TC5_173 = TC5_173 + tc_173\n",
    "setTC5_173 = list(set(TC5_173))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_173 = [ TC5_173.count(setTC5_173[l]) for l in range(len(setTC5_173)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_173 = [ [] for l in range(len(setTC5_173)) ]\n",
    "for s in range(173):\n",
    "    STC5null_173 = [ list(st_173) for st_173 in STC5_173]\n",
    "    for st_173 in STC5null_173:\n",
    "        np.random.shuffle(st_173)\n",
    "    TC5null_173= []\n",
    "    for n in range(len(STC5null_173)):\n",
    "        tc_173 = [ u for u in STC5null_173[n][0] ]\n",
    "        for k in range(1, len(STC5null_173[n])):\n",
    "            tc_173 = [ u+v for u in tc_173 for v in STC5null_173[n][k] ]\n",
    "        TC5null_173= TC5null_173+ tc_173\n",
    "    for l in range(len(setTC5_173)):\n",
    "        if TC5null_173.count(setTC5_173[l]) > 0:\n",
    "            fTC5null_173[l].append(TC5null_173.count(setTC5_173[l]))\n",
    "        else:\n",
    "            fTC5null_173[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "503e0f55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "CZQεQ\n",
      "ZCZZZ\n",
      "QCεZZ\n",
      "QCεZQ\n",
      "εTC\n",
      "ZTε\n",
      "εTZCQ\n",
      "εQεQ\n",
      "TCεZQ\n",
      "εZTZ\n",
      "QCZZZ\n",
      "QZεQZ\n",
      "QCTεZ\n",
      "TTZTε\n",
      "CCεZZ\n",
      "TεεQQ\n",
      "TQCεQ\n",
      "TQTZQ\n",
      "QCTZT\n",
      "TCCεQ\n",
      "TεεZQ\n",
      "TTZZQ\n",
      "CCεZQ\n",
      "CCTZT\n",
      "εZZCε\n",
      "TZεQQ\n",
      "TTεZQ\n",
      "QZεεZ\n",
      "QCTZZ\n",
      "TZεεε\n",
      "CTC\n",
      "CεQεQ\n",
      "TQεZQ\n",
      "εZTQ\n",
      "ZQCQ\n",
      "TCTZε\n",
      "CCQεQ\n",
      "ZTZT\n",
      "TTZQε\n",
      "QCCZT\n",
      "εQCQ\n",
      "ZZεεε\n",
      "CCTTT\n",
      "ZCZTε\n",
      "QεZZZ\n",
      "TTεQQ\n",
      "εTCQ\n",
      "QCZZT\n",
      "εZεZ\n",
      "QCTεT\n",
      "CZεεε\n",
      "TQCQ\n",
      "TQZTε\n",
      "ZQεQ\n",
      "εZTC\n",
      "TεCεQ\n",
      "CTZCε\n",
      "CCεεQ\n",
      "εZεQ\n",
      "TCεZZ\n",
      "TTZZε\n",
      "TTε\n",
      "εZCQ\n",
      "εQTQ\n",
      "TTεTQ\n",
      "QCTTT\n",
      "QCCZZ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_173)):\n",
    "    if sum(freq >= fTC5_173[l] for freq in fTC5null_173[l]) < 5:\n",
    "        print(setTC5_173[l], fTC5_173[l], sum(freq >= fTC5_173[l] for freq in fTC5null_173[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5dcc74eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "ZTε\n",
      "TCεZQ\n",
      "QCZZZ\n",
      "TTZTε\n",
      "QCTZT\n",
      "CCεZQ\n",
      "QCTZZ\n",
      "ZQCQ\n",
      "CCQεQ\n",
      "εQCQ\n",
      "QCZZT\n",
      "TQCQ\n",
      "ZQεQ\n",
      "εZTC\n",
      "CTZCε\n",
      "εZεQ\n",
      "εZCQ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_173)):\n",
    "    if sum(freq >= fTC5_173[l] for freq in fTC5null_173[l]) < 1:\n",
    "        print(setTC5_173[l], fTC5_173[l], sum(freq >= fTC5_173[l] for freq in fTC5null_173[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc749106",
   "metadata": {},
   "source": [
    "# 174 (C) AGI - (Q) MER - (Z) SECB - (T) MBT - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ea94f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_174 = max(min(Date_AGI), min(Date_MER), min(Date_SECB), min(Date_MBT), min(Date_PGOLD))\n",
    "end_174 = min(max(Date_AGI), max(Date_MER), max(Date_SECB), max(Date_MBT), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_174_1 = Date_AGI.index(start_174)\n",
    "AGI_174_2 = Date_AGI.index(end_174)\n",
    "\n",
    "MER_174_1 = Date_MER.index(start_174)\n",
    "MER_174_2 = Date_MER.index(end_174)\n",
    "\n",
    "SECB_174_1 = Date_SECB.index(start_174)\n",
    "SECB_174_2 = Date_SECB.index(end_174)\n",
    "\n",
    "MBT_174_1 = Date_MBT.index(start_174)\n",
    "MBT_174_2 = Date_MBT.index(end_174)\n",
    "\n",
    "PGOLD_174_1 = Date_PGOLD.index(start_174)\n",
    "PGOLD_174_2 = Date_PGOLD.index(end_174)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C174 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_174_1:AGI_174_2])\n",
    "Q174 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_174_1:MER_174_2])\n",
    "Z174 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_174_1:SECB_174_2])\n",
    "T174 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_174_1:MBT_174_2])\n",
    "W174 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_174_1:PGOLD_174_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C174 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q174 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z174 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T174 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "W174 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "657e2013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_174 = []\n",
    "st_174 = []\n",
    "n = 1\n",
    "while n < len(C174):\n",
    "    sc_174 = ''\n",
    "    if C174[n] > C174[n-1]:\n",
    "        sc_174 = sc_174 + 'C'\n",
    "    if Q174[n] > Q174[n-1]:\n",
    "        sc_174 = sc_174 + 'Q'\n",
    "    if Z174[n] > Z174[n-1]:\n",
    "        sc_174 = sc_174 + 'Z'\n",
    "    if T174[n] > T174[n-1]:\n",
    "        sc_174 = sc_174 + 'T'\n",
    "    if W174[n] > W174[n-1]:\n",
    "        sc_174 = sc_174 + 'W'\n",
    "    if len(sc_174) > 0:\n",
    "        st_174.append(sc_174)\n",
    "    else:\n",
    "        STC_174.append(st_174)\n",
    "        st_174 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_174 = STC_174.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_174 = [ st_174 for st_174 in STC_174 if len(st_174) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_174 = len(C174)\n",
    "lmax_174 = 0\n",
    "for st_174 in STC_174:\n",
    "    if len(st_174) < lmin_174:\n",
    "        lmin_174 = len(st_174)\n",
    "    if len(st_174) > lmax_174:\n",
    "        lmax_174 = len(st_174)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_174 = [ st_174 for st_174 in STC_174 if len(st_174) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_174 = []\n",
    "for n in range(len(STC5_174)):\n",
    "    tc_174 = [ u for u in STC5_174[n][0] ]\n",
    "    for k in range(1, len(STC5_174[n])):\n",
    "        tc_174 = [ u+v for u in tc_174 for v in STC5_174[n][k] ]\n",
    "    TC5_174 = TC5_174 + tc_174\n",
    "setTC5_174 = list(set(TC5_174))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_174 = [ TC5_174.count(setTC5_174[l]) for l in range(len(setTC5_174)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_174 = [ [] for l in range(len(setTC5_174)) ]\n",
    "for s in range(174):\n",
    "    STC5null_174 = [ list(st_174) for st_174 in STC5_174]\n",
    "    for st_174 in STC5null_174:\n",
    "        np.random.shuffle(st_174)\n",
    "    TC5null_174= []\n",
    "    for n in range(len(STC5null_174)):\n",
    "        tc_174 = [ u for u in STC5null_174[n][0] ]\n",
    "        for k in range(1, len(STC5null_174[n])):\n",
    "            tc_174 = [ u+v for u in tc_174 for v in STC5null_174[n][k] ]\n",
    "        TC5null_174= TC5null_174+ tc_174\n",
    "    for l in range(len(setTC5_174)):\n",
    "        if TC5null_174.count(setTC5_174[l]) > 0:\n",
    "            fTC5null_174[l].append(TC5null_174.count(setTC5_174[l]))\n",
    "        else:\n",
    "            fTC5null_174[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5451e87e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "TWZWC\n",
      "CWCWC\n",
      "TQTZT\n",
      "CWZQ\n",
      "CTQWC\n",
      "TTQWC\n",
      "CWQWC\n",
      "TTCWC\n",
      "QZQT\n",
      "TTZWC\n",
      "CWZWC\n",
      "ZTZWC\n",
      "TWQWC\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_174)):\n",
    "    if sum(freq >= fTC5_174[l] for freq in fTC5null_174[l]) < 5:\n",
    "        print(setTC5_174[l], fTC5_174[l], sum(freq >= fTC5_174[l] for freq in fTC5null_174[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc565554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "TTQWC\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_174)):\n",
    "    if sum(freq >= fTC5_174[l] for freq in fTC5null_174[l]) < 1:\n",
    "        print(setTC5_174[l], fTC5_174[l], sum(freq >= fTC5_174[l] for freq in fTC5null_174[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe08afb3",
   "metadata": {},
   "source": [
    "# 175 (C) AGI - (Q) MER - (Z) SECB - (V) TEL - (ε) URC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a83c3295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_175 = max(min(Date_AGI), min(Date_MER), min(Date_SECB), min(Date_TEL), min(Date_URC))\n",
    "end_175 = min(max(Date_AGI), max(Date_MER), max(Date_SECB), max(Date_TEL), max(Date_URC))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_175_1 = Date_AGI.index(start_175)\n",
    "AGI_175_2 = Date_AGI.index(end_175)\n",
    "\n",
    "MER_175_1 = Date_MER.index(start_175)\n",
    "MER_175_2 = Date_MER.index(end_175)\n",
    "\n",
    "SECB_175_1 = Date_SECB.index(start_175)\n",
    "SECB_175_2 = Date_SECB.index(end_175)\n",
    "\n",
    "TEL_175_1 = Date_TEL.index(start_175)\n",
    "TEL_175_2 = Date_TEL.index(end_175)\n",
    "\n",
    "URC_175_1 = Date_URC.index(start_175)\n",
    "URC_175_2 = Date_URC.index(end_175)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C175 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_175_1:AGI_175_2])\n",
    "Q175 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_175_1:MER_175_2])\n",
    "Z175 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_175_1:SECB_175_2])\n",
    "V175 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_175_1:TEL_175_2])\n",
    "ε175 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_175_1:URC_175_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C175 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q175 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z175 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "V175 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε175 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac1c0d26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_175 = []\n",
    "st_175 = []\n",
    "n = 1\n",
    "while n < len(C175):\n",
    "    sc_175 = ''\n",
    "    if C175[n] > C175[n-1]:\n",
    "        sc_175 = sc_175 + 'C'\n",
    "    if Q175[n] > Q175[n-1]:\n",
    "        sc_175 = sc_175 + 'Q'\n",
    "    if Z175[n] > Z175[n-1]:\n",
    "        sc_175 = sc_175 + 'Z'\n",
    "    if V175[n] > V175[n-1]:\n",
    "        sc_175 = sc_175 + 'V'\n",
    "    if ε175[n] > ε175[n-1]:\n",
    "        sc_175 = sc_175 + 'ε'\n",
    "    if len(sc_175) > 0:\n",
    "        st_175.append(sc_175)\n",
    "    else:\n",
    "        STC_175.append(st_175)\n",
    "        st_175 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_175 = STC_175.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_175 = [ st_175 for st_175 in STC_175 if len(st_175) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_175 = len(C175)\n",
    "lmax_175 = 0\n",
    "for st_175 in STC_175:\n",
    "    if len(st_175) < lmin_175:\n",
    "        lmin_175 = len(st_175)\n",
    "    if len(st_175) > lmax_175:\n",
    "        lmax_175 = len(st_175)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_175 = [ st_175 for st_175 in STC_175 if len(st_175) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_175 = []\n",
    "for n in range(len(STC5_175)):\n",
    "    tc_175 = [ u for u in STC5_175[n][0] ]\n",
    "    for k in range(1, len(STC5_175[n])):\n",
    "        tc_175 = [ u+v for u in tc_175 for v in STC5_175[n][k] ]\n",
    "    TC5_175 = TC5_175 + tc_175\n",
    "setTC5_175 = list(set(TC5_175))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_175 = [ TC5_175.count(setTC5_175[l]) for l in range(len(setTC5_175)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_175 = [ [] for l in range(len(setTC5_175)) ]\n",
    "for s in range(175):\n",
    "    STC5null_175 = [ list(st_175) for st_175 in STC5_175]\n",
    "    for st_175 in STC5null_175:\n",
    "        np.random.shuffle(st_175)\n",
    "    TC5null_175= []\n",
    "    for n in range(len(STC5null_175)):\n",
    "        tc_175 = [ u for u in STC5null_175[n][0] ]\n",
    "        for k in range(1, len(STC5null_175[n])):\n",
    "            tc_175 = [ u+v for u in tc_175 for v in STC5null_175[n][k] ]\n",
    "        TC5null_175= TC5null_175+ tc_175\n",
    "    for l in range(len(setTC5_175)):\n",
    "        if TC5null_175.count(setTC5_175[l]) > 0:\n",
    "            fTC5null_175[l].append(TC5null_175.count(setTC5_175[l]))\n",
    "        else:\n",
    "            fTC5null_175[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3100315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "εZCZV\n",
      "εVV\n",
      "QεCCQ\n",
      "εVZV\n",
      "εZQZε\n",
      "εZQZQ\n",
      "VVCV\n",
      "CCQC\n",
      "εεCZV\n",
      "εVZZV\n",
      "QCZZZ\n",
      "QCZQZ\n",
      "ZεCZV\n",
      "QZCZV\n",
      "CVVCε\n",
      "εVCCV\n",
      "QεCZV\n",
      "εZQεQ\n",
      "CεCZV\n",
      "εZεZQ\n",
      "VVCε\n",
      "εεQCQ\n",
      "ZεCZZ\n",
      "CCQV\n",
      "QZQCQ\n",
      "VZQCQ\n",
      "εεCεV\n",
      "εVεZV\n",
      "εVεZQ\n",
      "εQVZV\n",
      "εZVZV\n",
      "VVVCV\n",
      "QVCZV\n",
      "QZQZV\n",
      "QCZVZ\n",
      "CVεZε\n",
      "εZVCQ\n",
      "CVCCV\n",
      "εVZCV\n",
      "QCCVZ\n",
      "CεQCQ\n",
      "CZQCQ\n",
      "εZCCQ\n",
      "εZQZV\n",
      "εZQCε\n",
      "CQVZV\n",
      "ZZCZV\n",
      "εVCZV\n",
      "QCCZV\n",
      "εεZCε\n",
      "εεQZV\n",
      "CVVZε\n",
      "εVVZV\n",
      "VZVCQ\n",
      "εZQCQ\n",
      "εεVCε\n",
      "εZVZQ\n",
      "εVVZQ\n",
      "QεQZV\n",
      "ZQεQ\n",
      "εεVCQ\n",
      "QVCCV\n",
      "CVQCV\n",
      "CVQV\n",
      "εεQCε\n",
      "εCZZV\n",
      "VVVCε\n",
      "CVZCV\n",
      "εVQ\n",
      "QZCCQ\n",
      "CVCZV\n",
      "QCVVZ\n",
      "QCCZZ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_175)):\n",
    "    if sum(freq >= fTC5_175[l] for freq in fTC5null_175[l]) < 5:\n",
    "        print(setTC5_175[l], fTC5_175[l], sum(freq >= fTC5_175[l] for freq in fTC5null_175[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c789984",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "εεCZV\n",
      "εVCCV\n",
      "QεCZV\n",
      "εεQCQ\n",
      "εZVZV\n",
      "QVCZV\n",
      "QZQZV\n",
      "QCZVZ\n",
      "εVCZV\n",
      "εVVZV\n",
      "εZQCQ\n",
      "εVVZQ\n",
      "CVZCV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_175)):\n",
    "    if sum(freq >= fTC5_175[l] for freq in fTC5null_175[l]) < 1:\n",
    "        print(setTC5_175[l], fTC5_175[l], sum(freq >= fTC5_175[l] for freq in fTC5null_175[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21558eed",
   "metadata": {},
   "source": [
    "# 176 (C) AGI - (Q) MER - (Z) SECB - (V) TEL - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d04162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_176 = max(min(Date_AGI), min(Date_MER), min(Date_SECB), min(Date_TEL), min(Date_PGOLD))\n",
    "end_176 = min(max(Date_AGI), max(Date_MER), max(Date_SECB), max(Date_TEL), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_176_1 = Date_AGI.index(start_176)\n",
    "AGI_176_2 = Date_AGI.index(end_176)\n",
    "\n",
    "MER_176_1 = Date_MER.index(start_176)\n",
    "MER_176_2 = Date_MER.index(end_176)\n",
    "\n",
    "SECB_176_1 = Date_SECB.index(start_176)\n",
    "SECB_176_2 = Date_SECB.index(end_176)\n",
    "\n",
    "TEL_176_1 = Date_TEL.index(start_176)\n",
    "TEL_176_2 = Date_TEL.index(end_176)\n",
    "\n",
    "PGOLD_176_1 = Date_PGOLD.index(start_176)\n",
    "PGOLD_176_2 = Date_PGOLD.index(end_176)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C176 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_176_1:AGI_176_2])\n",
    "Q176 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_176_1:MER_176_2])\n",
    "Z176 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_176_1:SECB_176_2])\n",
    "V176 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_176_1:TEL_176_2])\n",
    "W176 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_176_1:PGOLD_176_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C176 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q176 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z176 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "V176 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "W176 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ff3673c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_176 = []\n",
    "st_176 = []\n",
    "n = 1\n",
    "while n < len(C176):\n",
    "    sc_176 = ''\n",
    "    if C176[n] > C176[n-1]:\n",
    "        sc_176 = sc_176 + 'C'\n",
    "    if Q176[n] > Q176[n-1]:\n",
    "        sc_176 = sc_176 + 'Q'\n",
    "    if Z176[n] > Z176[n-1]:\n",
    "        sc_176 = sc_176 + 'Z'\n",
    "    if V176[n] > V176[n-1]:\n",
    "        sc_176 = sc_176 + 'V'\n",
    "    if W176[n] > W176[n-1]:\n",
    "        sc_176 = sc_176 + 'W'\n",
    "    if len(sc_176) > 0:\n",
    "        st_176.append(sc_176)\n",
    "    else:\n",
    "        STC_176.append(st_176)\n",
    "        st_176 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_176 = STC_176.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_176 = [ st_176 for st_176 in STC_176 if len(st_176) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_176 = len(C176)\n",
    "lmax_176 = 0\n",
    "for st_176 in STC_176:\n",
    "    if len(st_176) < lmin_176:\n",
    "        lmin_176 = len(st_176)\n",
    "    if len(st_176) > lmax_176:\n",
    "        lmax_176 = len(st_176)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_176 = [ st_176 for st_176 in STC_176 if len(st_176) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_176 = []\n",
    "for n in range(len(STC5_176)):\n",
    "    tc_176 = [ u for u in STC5_176[n][0] ]\n",
    "    for k in range(1, len(STC5_176[n])):\n",
    "        tc_176 = [ u+v for u in tc_176 for v in STC5_176[n][k] ]\n",
    "    TC5_176 = TC5_176 + tc_176\n",
    "setTC5_176 = list(set(TC5_176))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_176 = [ TC5_176.count(setTC5_176[l]) for l in range(len(setTC5_176)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_176 = [ [] for l in range(len(setTC5_176)) ]\n",
    "for s in range(176):\n",
    "    STC5null_176 = [ list(st_176) for st_176 in STC5_176]\n",
    "    for st_176 in STC5null_176:\n",
    "        np.random.shuffle(st_176)\n",
    "    TC5null_176= []\n",
    "    for n in range(len(STC5null_176)):\n",
    "        tc_176 = [ u for u in STC5null_176[n][0] ]\n",
    "        for k in range(1, len(STC5null_176[n])):\n",
    "            tc_176 = [ u+v for u in tc_176 for v in STC5null_176[n][k] ]\n",
    "        TC5null_176= TC5null_176+ tc_176\n",
    "    for l in range(len(setTC5_176)):\n",
    "        if TC5null_176.count(setTC5_176[l]) > 0:\n",
    "            fTC5null_176[l].append(TC5null_176.count(setTC5_176[l]))\n",
    "        else:\n",
    "            fTC5null_176[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cef091ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "WQQVZ\n",
      "CVVQQ\n",
      "CVWZW\n",
      "VVQCV\n",
      "WQCWZ\n",
      "VVQZV\n",
      "CVZWZ\n",
      "ZCVWZ\n",
      "VVQZW\n",
      "WQCZV\n",
      "VVCWZ\n",
      "WVWWW\n",
      "WQCVZ\n",
      "ZCQWZ\n",
      "QVCCW\n",
      "WQCVC\n",
      "ZVVWZ\n",
      "VZCW\n",
      "WQCZW\n",
      "QCWVQ\n",
      "ZVCWZ\n",
      "CQVZV\n",
      "ZQQWZ\n",
      "VWCW\n",
      "CVVZV\n",
      "ZQZWZ\n",
      "ZQZQZ\n",
      "ZQCWZ\n",
      "CQZWZ\n",
      "WQVWZ\n",
      "CVCWZ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_176)):\n",
    "    if sum(freq >= fTC5_176[l] for freq in fTC5null_176[l]) < 5:\n",
    "        print(setTC5_176[l], fTC5_176[l], sum(freq >= fTC5_176[l] for freq in fTC5null_176[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83fa8194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "CVWZW\n",
      "ZQQWZ\n",
      "VWCW\n",
      "CVVZV\n",
      "CVCWZ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_176)):\n",
    "    if sum(freq >= fTC5_176[l] for freq in fTC5null_176[l]) < 1:\n",
    "        print(setTC5_176[l], fTC5_176[l], sum(freq >= fTC5_176[l] for freq in fTC5null_176[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444ce06f",
   "metadata": {},
   "source": [
    "# 177 (C) AGI - (Q) MER - (Z) SECB - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7de8e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_177 = max(min(Date_AGI), min(Date_MER), min(Date_SECB), min(Date_URC), min(Date_PGOLD))\n",
    "end_177 = min(max(Date_AGI), max(Date_MER), max(Date_SECB), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_177_1 = Date_AGI.index(start_177)\n",
    "AGI_177_2 = Date_AGI.index(end_177)\n",
    "\n",
    "MER_177_1 = Date_MER.index(start_177)\n",
    "MER_177_2 = Date_MER.index(end_177)\n",
    "\n",
    "SECB_177_1 = Date_SECB.index(start_177)\n",
    "SECB_177_2 = Date_SECB.index(end_177)\n",
    "\n",
    "URC_177_1 = Date_URC.index(start_177)\n",
    "URC_177_2 = Date_URC.index(end_177)\n",
    "\n",
    "PGOLD_177_1 = Date_PGOLD.index(start_177)\n",
    "PGOLD_177_2 = Date_PGOLD.index(end_177)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C177 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_177_1:AGI_177_2])\n",
    "Q177 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_177_1:MER_177_2])\n",
    "Z177 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_177_1:SECB_177_2])\n",
    "ε177 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_177_1:URC_177_2])\n",
    "W177 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_177_1:PGOLD_177_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C177 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q177 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z177 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε177 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W177 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a2e2b29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_177 = []\n",
    "st_177 = []\n",
    "n = 1\n",
    "while n < len(C177):\n",
    "    sc_177 = ''\n",
    "    if C177[n] > C177[n-1]:\n",
    "        sc_177 = sc_177 + 'C'\n",
    "    if Q177[n] > Q177[n-1]:\n",
    "        sc_177 = sc_177 + 'Q'\n",
    "    if Z177[n] > Z177[n-1]:\n",
    "        sc_177 = sc_177 + 'Z'\n",
    "    if ε177[n] > ε177[n-1]:\n",
    "        sc_177 = sc_177 + 'ε'\n",
    "    if W177[n] > W177[n-1]:\n",
    "        sc_177 = sc_177 + 'W'\n",
    "    if len(sc_177) > 0:\n",
    "        st_177.append(sc_177)\n",
    "    else:\n",
    "        STC_177.append(st_177)\n",
    "        st_177 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_177 = STC_177.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_177 = [ st_177 for st_177 in STC_177 if len(st_177) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_177 = len(C177)\n",
    "lmax_177 = 0\n",
    "for st_177 in STC_177:\n",
    "    if len(st_177) < lmin_177:\n",
    "        lmin_177 = len(st_177)\n",
    "    if len(st_177) > lmax_177:\n",
    "        lmax_177 = len(st_177)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_177 = [ st_177 for st_177 in STC_177 if len(st_177) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_177 = []\n",
    "for n in range(len(STC5_177)):\n",
    "    tc_177 = [ u for u in STC5_177[n][0] ]\n",
    "    for k in range(1, len(STC5_177[n])):\n",
    "        tc_177 = [ u+v for u in tc_177 for v in STC5_177[n][k] ]\n",
    "    TC5_177 = TC5_177 + tc_177\n",
    "setTC5_177 = list(set(TC5_177))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_177 = [ TC5_177.count(setTC5_177[l]) for l in range(len(setTC5_177)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_177 = [ [] for l in range(len(setTC5_177)) ]\n",
    "for s in range(177):\n",
    "    STC5null_177 = [ list(st_177) for st_177 in STC5_177]\n",
    "    for st_177 in STC5null_177:\n",
    "        np.random.shuffle(st_177)\n",
    "    TC5null_177= []\n",
    "    for n in range(len(STC5null_177)):\n",
    "        tc_177 = [ u for u in STC5null_177[n][0] ]\n",
    "        for k in range(1, len(STC5null_177[n])):\n",
    "            tc_177 = [ u+v for u in tc_177 for v in STC5null_177[n][k] ]\n",
    "        TC5null_177= TC5null_177+ tc_177\n",
    "    for l in range(len(setTC5_177)):\n",
    "        if TC5null_177.count(setTC5_177[l]) > 0:\n",
    "            fTC5null_177[l].append(TC5null_177.count(setTC5_177[l]))\n",
    "        else:\n",
    "            fTC5null_177[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e950d745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "QZQQQ\n",
      "εCZWZ\n",
      "WZεZC\n",
      "WZεWC\n",
      "εZZW\n",
      "WQεWW\n",
      "WQεZC\n",
      "ZZεWC\n",
      "ZCW\n",
      "WQεWC\n",
      "WWεWC\n",
      "WεεWC\n",
      "QεQQQ\n",
      "εZWε\n",
      "CZεQQ\n",
      "εQWZW\n",
      "WWεZC\n",
      "CQεZW\n",
      "WZεWW\n",
      "WCεWC\n",
      "εQCWZ\n",
      "WZεZW\n",
      "QCCQZ\n",
      "εQCWC\n",
      "WCεWW\n",
      "εZCW\n",
      "CQWZW\n",
      "εZCε\n",
      "CZεQC\n",
      "εQεZW\n",
      "QZCQQ\n",
      "εZWW\n",
      "ZQW\n",
      "WQεZW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_177)):\n",
    "    if sum(freq >= fTC5_177[l] for freq in fTC5null_177[l]) < 5:\n",
    "        print(setTC5_177[l], fTC5_177[l], sum(freq >= fTC5_177[l] for freq in fTC5null_177[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8106b983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "WZεWC\n",
      "WQεWW\n",
      "WQεWC\n",
      "WWεWC\n",
      "εZCW\n",
      "CQWZW\n",
      "εZCε\n",
      "εQεZW\n",
      "εZWW\n",
      "ZQW\n",
      "WQεZW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_177)):\n",
    "    if sum(freq >= fTC5_177[l] for freq in fTC5null_177[l]) < 1:\n",
    "        print(setTC5_177[l], fTC5_177[l], sum(freq >= fTC5_177[l] for freq in fTC5null_177[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fe34a8",
   "metadata": {},
   "source": [
    "# 178 (C) AGI - (Q) MER - (T) MBT - (V) TEL - (ε) URC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a949c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_178 = max(min(Date_AGI), min(Date_MER), min(Date_MBT), min(Date_TEL), min(Date_URC))\n",
    "end_178 = min(max(Date_AGI), max(Date_MER), max(Date_MBT), max(Date_TEL), max(Date_URC))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_178_1 = Date_AGI.index(start_178)\n",
    "AGI_178_2 = Date_AGI.index(end_178)\n",
    "\n",
    "MER_178_1 = Date_MER.index(start_178)\n",
    "MER_178_2 = Date_MER.index(end_178)\n",
    "\n",
    "MBT_178_1 = Date_MBT.index(start_178)\n",
    "MBT_178_2 = Date_MBT.index(end_178)\n",
    "\n",
    "TEL_178_1 = Date_TEL.index(start_178)\n",
    "TEL_178_2 = Date_TEL.index(end_178)\n",
    "\n",
    "URC_178_1 = Date_URC.index(start_178)\n",
    "URC_178_2 = Date_URC.index(end_178)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C178 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_178_1:AGI_178_2])\n",
    "Q178 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_178_1:MER_178_2])\n",
    "T178 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_178_1:MBT_178_2])\n",
    "V178 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_178_1:TEL_178_2])\n",
    "ε178 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_178_1:URC_178_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C178 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q178 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "T178 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V178 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε178 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85de97fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_178 = []\n",
    "st_178 = []\n",
    "n = 1\n",
    "while n < len(C178):\n",
    "    sc_178 = ''\n",
    "    if C178[n] > C178[n-1]:\n",
    "        sc_178 = sc_178 + 'C'\n",
    "    if Q178[n] > Q178[n-1]:\n",
    "        sc_178 = sc_178 + 'Q'\n",
    "    if T178[n] > T178[n-1]:\n",
    "        sc_178 = sc_178 + 'T'\n",
    "    if V178[n] > V178[n-1]:\n",
    "        sc_178 = sc_178 + 'V'\n",
    "    if ε178[n] > ε178[n-1]:\n",
    "        sc_178 = sc_178 + 'ε'\n",
    "    if len(sc_178) > 0:\n",
    "        st_178.append(sc_178)\n",
    "    else:\n",
    "        STC_178.append(st_178)\n",
    "        st_178 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_178 = STC_178.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_178 = [ st_178 for st_178 in STC_178 if len(st_178) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_178 = len(C178)\n",
    "lmax_178 = 0\n",
    "for st_178 in STC_178:\n",
    "    if len(st_178) < lmin_178:\n",
    "        lmin_178 = len(st_178)\n",
    "    if len(st_178) > lmax_178:\n",
    "        lmax_178 = len(st_178)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_178 = [ st_178 for st_178 in STC_178 if len(st_178) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_178 = []\n",
    "for n in range(len(STC5_178)):\n",
    "    tc_178 = [ u for u in STC5_178[n][0] ]\n",
    "    for k in range(1, len(STC5_178[n])):\n",
    "        tc_178 = [ u+v for u in tc_178 for v in STC5_178[n][k] ]\n",
    "    TC5_178 = TC5_178 + tc_178\n",
    "setTC5_178 = list(set(TC5_178))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_178 = [ TC5_178.count(setTC5_178[l]) for l in range(len(setTC5_178)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_178 = [ [] for l in range(len(setTC5_178)) ]\n",
    "for s in range(178):\n",
    "    STC5null_178 = [ list(st_178) for st_178 in STC5_178]\n",
    "    for st_178 in STC5null_178:\n",
    "        np.random.shuffle(st_178)\n",
    "    TC5null_178= []\n",
    "    for n in range(len(STC5null_178)):\n",
    "        tc_178 = [ u for u in STC5null_178[n][0] ]\n",
    "        for k in range(1, len(STC5null_178[n])):\n",
    "            tc_178 = [ u+v for u in tc_178 for v in STC5null_178[n][k] ]\n",
    "        TC5null_178= TC5null_178+ tc_178\n",
    "    for l in range(len(setTC5_178)):\n",
    "        if TC5null_178.count(setTC5_178[l]) > 0:\n",
    "            fTC5null_178[l].append(TC5null_178.count(setTC5_178[l]))\n",
    "        else:\n",
    "            fTC5null_178[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8644cf31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "εVVTT\n",
      "QεVεC\n",
      "CCQC\n",
      "QTVT\n",
      "CεC\n",
      "VVVTε\n",
      "CTCT\n",
      "VTεT\n",
      "QCVVT\n",
      "εQCVT\n",
      "εVVTC\n",
      "VVVCT\n",
      "QQCVQ\n",
      "QTεTQ\n",
      "εεQCQ\n",
      "CTVT\n",
      "CTQT\n",
      "CCQV\n",
      "CTεε\n",
      "εQCTT\n",
      "QQQT\n",
      "QQVVQ\n",
      "QTVVT\n",
      "QCCVT\n",
      "εCVCε\n",
      "QεVVT\n",
      "QQVQT\n",
      "QVQT\n",
      "VTVV\n",
      "VVVVT\n",
      "QVVQT\n",
      "QTCVQ\n",
      "QεVQC\n",
      "QεVQT\n",
      "VVVTT\n",
      "TVVTT\n",
      "CVQT\n",
      "VεVVQ\n",
      "CTεT\n",
      "QVVTT\n",
      "VTVT\n",
      "εVCTT\n",
      "QQVVT\n",
      "VTεV\n",
      "TCTVT\n",
      "QTVTQ\n",
      "QTVQC\n",
      "QVVVT\n",
      "εCQCQ\n",
      "QεCVT\n",
      "QQVQQ\n",
      "QTVQT\n",
      "εCVCQ\n",
      "CTεV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_178)):\n",
    "    if sum(freq >= fTC5_178[l] for freq in fTC5null_178[l]) < 5:\n",
    "        print(setTC5_178[l], fTC5_178[l], sum(freq >= fTC5_178[l] for freq in fTC5null_178[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a7641ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "QCVVT\n",
      "CCQV\n",
      "QCCVT\n",
      "QεVVT\n",
      "QVVQT\n",
      "QQVVT\n",
      "QVVVT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_178)):\n",
    "    if sum(freq >= fTC5_178[l] for freq in fTC5null_178[l]) < 1:\n",
    "        print(setTC5_178[l], fTC5_178[l], sum(freq >= fTC5_178[l] for freq in fTC5null_178[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3354a7",
   "metadata": {},
   "source": [
    "# 179 (C) AGI - (Q) MER - (T) MBT - (V) TEL - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf76653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_179 = max(min(Date_AGI), min(Date_MER), min(Date_MBT), min(Date_TEL), min(Date_PGOLD))\n",
    "end_179 = min(max(Date_AGI), max(Date_MER), max(Date_MBT), max(Date_TEL), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_179_1 = Date_AGI.index(start_179)\n",
    "AGI_179_2 = Date_AGI.index(end_179)\n",
    "\n",
    "MER_179_1 = Date_MER.index(start_179)\n",
    "MER_179_2 = Date_MER.index(end_179)\n",
    "\n",
    "MBT_179_1 = Date_MBT.index(start_179)\n",
    "MBT_179_2 = Date_MBT.index(end_179)\n",
    "\n",
    "TEL_179_1 = Date_TEL.index(start_179)\n",
    "TEL_179_2 = Date_TEL.index(end_179)\n",
    "\n",
    "PGOLD_179_1 = Date_PGOLD.index(start_179)\n",
    "PGOLD_179_2 = Date_PGOLD.index(end_179)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C179 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_179_1:AGI_179_2])\n",
    "Q179 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_179_1:MER_179_2])\n",
    "T179 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_179_1:MBT_179_2])\n",
    "V179 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_179_1:TEL_179_2])\n",
    "W179 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_179_1:PGOLD_179_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C179 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q179 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "T179 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V179 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "W179 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df7a8514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_179 = []\n",
    "st_179 = []\n",
    "n = 1\n",
    "while n < len(C179):\n",
    "    sc_179 = ''\n",
    "    if C179[n] > C179[n-1]:\n",
    "        sc_179 = sc_179 + 'C'\n",
    "    if Q179[n] > Q179[n-1]:\n",
    "        sc_179 = sc_179 + 'Q'\n",
    "    if T179[n] > T179[n-1]:\n",
    "        sc_179 = sc_179 + 'T'\n",
    "    if V179[n] > V179[n-1]:\n",
    "        sc_179 = sc_179 + 'V'\n",
    "    if W179[n] > W179[n-1]:\n",
    "        sc_179 = sc_179 + 'W'\n",
    "    if len(sc_179) > 0:\n",
    "        st_179.append(sc_179)\n",
    "    else:\n",
    "        STC_179.append(st_179)\n",
    "        st_179 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_179 = STC_179.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_179 = [ st_179 for st_179 in STC_179 if len(st_179) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_179 = len(C179)\n",
    "lmax_179 = 0\n",
    "for st_179 in STC_179:\n",
    "    if len(st_179) < lmin_179:\n",
    "        lmin_179 = len(st_179)\n",
    "    if len(st_179) > lmax_179:\n",
    "        lmax_179 = len(st_179)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_179 = [ st_179 for st_179 in STC_179 if len(st_179) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_179 = []\n",
    "for n in range(len(STC5_179)):\n",
    "    tc_179 = [ u for u in STC5_179[n][0] ]\n",
    "    for k in range(1, len(STC5_179[n])):\n",
    "        tc_179 = [ u+v for u in tc_179 for v in STC5_179[n][k] ]\n",
    "    TC5_179 = TC5_179 + tc_179\n",
    "setTC5_179 = list(set(TC5_179))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_179 = [ TC5_179.count(setTC5_179[l]) for l in range(len(setTC5_179)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_179 = [ [] for l in range(len(setTC5_179)) ]\n",
    "for s in range(179):\n",
    "    STC5null_179 = [ list(st_179) for st_179 in STC5_179]\n",
    "    for st_179 in STC5null_179:\n",
    "        np.random.shuffle(st_179)\n",
    "    TC5null_179= []\n",
    "    for n in range(len(STC5null_179)):\n",
    "        tc_179 = [ u for u in STC5null_179[n][0] ]\n",
    "        for k in range(1, len(STC5null_179[n])):\n",
    "            tc_179 = [ u+v for u in tc_179 for v in STC5null_179[n][k] ]\n",
    "        TC5null_179= TC5null_179+ tc_179\n",
    "    for l in range(len(setTC5_179)):\n",
    "        if TC5null_179.count(setTC5_179[l]) > 0:\n",
    "            fTC5null_179[l].append(TC5null_179.count(setTC5_179[l]))\n",
    "        else:\n",
    "            fTC5null_179[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a00dd86f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "WVVCW\n",
      "TVCTW\n",
      "QTQVQ\n",
      "QTWVQ\n",
      "QWQC\n",
      "VVCTW\n",
      "CVTCW\n",
      "TVTCW\n",
      "WVCCW\n",
      "WVCTW\n",
      "WVTTW\n",
      "TVVCV\n",
      "WVVQW\n",
      "QQWTW\n",
      "TVCTV\n",
      "QVCCW\n",
      "CVCCW\n",
      "WVTCW\n",
      "QCWVQ\n",
      "CVCTW\n",
      "CVQTW\n",
      "QVWVQ\n",
      "QTTVQ\n",
      "QCQVQ\n",
      "TVCCW\n",
      "TVVCW\n",
      "VVCCW\n",
      "QCTVQ\n",
      "QVCTW\n",
      "QQWVQ\n",
      "WVVTW\n",
      "QVQVQ\n",
      "QCWVW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_179)):\n",
    "    if sum(freq >= fTC5_179[l] for freq in fTC5null_179[l]) < 5:\n",
    "        print(setTC5_179[l], fTC5_179[l], sum(freq >= fTC5_179[l] for freq in fTC5null_179[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4eb7d8db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "WVVCW\n",
      "QTWVQ\n",
      "WVCCW\n",
      "TVVCV\n",
      "WVTCW\n",
      "QCWVQ\n",
      "QVWVQ\n",
      "QCQVQ\n",
      "QQWVQ\n",
      "QVQVQ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_179)):\n",
    "    if sum(freq >= fTC5_179[l] for freq in fTC5null_179[l]) < 1:\n",
    "        print(setTC5_179[l], fTC5_179[l], sum(freq >= fTC5_179[l] for freq in fTC5null_179[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8400f9",
   "metadata": {},
   "source": [
    "# 180 (C) AGI - (Q) MER - (T) MBT - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ebb4654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_180 = max(min(Date_AGI), min(Date_MER), min(Date_MBT), min(Date_URC), min(Date_PGOLD))\n",
    "end_180 = min(max(Date_AGI), max(Date_MER), max(Date_MBT), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "AGI_180_1 = Date_AGI.index(start_180)\n",
    "AGI_180_2 = Date_AGI.index(end_180)\n",
    "\n",
    "MER_180_1 = Date_MER.index(start_180)\n",
    "MER_180_2 = Date_MER.index(end_180)\n",
    "\n",
    "MBT_180_1 = Date_MBT.index(start_180)\n",
    "MBT_180_2 = Date_MBT.index(end_180)\n",
    "\n",
    "URC_180_1 = Date_URC.index(start_180)\n",
    "URC_180_2 = Date_URC.index(end_180)\n",
    "\n",
    "PGOLD_180_1 = Date_PGOLD.index(start_180)\n",
    "PGOLD_180_2 = Date_PGOLD.index(end_180)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "C180 = np.save('AGIshortPrices.npy', ClosePrice_AGI[AGI_180_1:AGI_180_2])\n",
    "Q180 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_180_1:MER_180_2])\n",
    "T180 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_180_1:MBT_180_2])\n",
    "ε180 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_180_1:URC_180_2])\n",
    "W180 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_180_1:PGOLD_180_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "C180 = np.load('AGIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q180 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "T180 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε180 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W180 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0493d6a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_180 = []\n",
    "st_180 = []\n",
    "n = 1\n",
    "while n < len(C180):\n",
    "    sc_180 = ''\n",
    "    if C180[n] > C180[n-1]:\n",
    "        sc_180 = sc_180 + 'C'\n",
    "    if Q180[n] > Q180[n-1]:\n",
    "        sc_180 = sc_180 + 'Q'\n",
    "    if T180[n] > T180[n-1]:\n",
    "        sc_180 = sc_180 + 'T'\n",
    "    if ε180[n] > ε180[n-1]:\n",
    "        sc_180 = sc_180 + 'ε'\n",
    "    if W180[n] > W180[n-1]:\n",
    "        sc_180 = sc_180 + 'W'\n",
    "    if len(sc_180) > 0:\n",
    "        st_180.append(sc_180)\n",
    "    else:\n",
    "        STC_180.append(st_180)\n",
    "        st_180 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_180 = STC_180.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_180 = [ st_180 for st_180 in STC_180 if len(st_180) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_180 = len(C180)\n",
    "lmax_180 = 0\n",
    "for st_180 in STC_180:\n",
    "    if len(st_180) < lmin_180:\n",
    "        lmin_180 = len(st_180)\n",
    "    if len(st_180) > lmax_180:\n",
    "        lmax_180 = len(st_180)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_180 = [ st_180 for st_180 in STC_180 if len(st_180) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_180 = []\n",
    "for n in range(len(STC5_180)):\n",
    "    tc_180 = [ u for u in STC5_180[n][0] ]\n",
    "    for k in range(1, len(STC5_180[n])):\n",
    "        tc_180 = [ u+v for u in tc_180 for v in STC5_180[n][k] ]\n",
    "    TC5_180 = TC5_180 + tc_180\n",
    "setTC5_180 = list(set(TC5_180))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_180 = [ TC5_180.count(setTC5_180[l]) for l in range(len(setTC5_180)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_180 = [ [] for l in range(len(setTC5_180)) ]\n",
    "for s in range(180):\n",
    "    STC5null_180 = [ list(st_180) for st_180 in STC5_180]\n",
    "    for st_180 in STC5null_180:\n",
    "        np.random.shuffle(st_180)\n",
    "    TC5null_180= []\n",
    "    for n in range(len(STC5null_180)):\n",
    "        tc_180 = [ u for u in STC5null_180[n][0] ]\n",
    "        for k in range(1, len(STC5null_180[n])):\n",
    "            tc_180 = [ u+v for u in tc_180 for v in STC5null_180[n][k] ]\n",
    "        TC5null_180= TC5null_180+ tc_180\n",
    "    for l in range(len(setTC5_180)):\n",
    "        if TC5null_180.count(setTC5_180[l]) > 0:\n",
    "            fTC5null_180[l].append(TC5null_180.count(setTC5_180[l]))\n",
    "        else:\n",
    "            fTC5null_180[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4383ea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "QCεεT\n",
      "WQεWW\n",
      "CCTεW\n",
      "TCWεT\n",
      "CCCQW\n",
      "CCεεW\n",
      "TCWεC\n",
      "QεεεT\n",
      "CCQQW\n",
      "QQQT\n",
      "CCWεT\n",
      "QεεQQ\n",
      "CCWεC\n",
      "CCTεT\n",
      "TCTεT\n",
      "TCεεT\n",
      "QεεQC\n",
      "CCTεC\n",
      "CWεQ\n",
      "εCQ\n",
      "CCεQW\n",
      "CWεε\n",
      "CεTεW\n",
      "QεTεT\n",
      "TCTεC\n",
      "QεεQT\n",
      "TCWεW\n",
      "εWT\n",
      "QεQQC\n",
      "CCWQW\n",
      "QQWTT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_180)):\n",
    "    if sum(freq >= fTC5_180[l] for freq in fTC5null_180[l]) < 5:\n",
    "        print(setTC5_180[l], fTC5_180[l], sum(freq >= fTC5_180[l] for freq in fTC5null_180[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31eef048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "QQQT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_180)):\n",
    "    if sum(freq >= fTC5_180[l] for freq in fTC5null_180[l]) < 1:\n",
    "        print(setTC5_180[l], fTC5_180[l], sum(freq >= fTC5_180[l] for freq in fTC5null_180[l]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
