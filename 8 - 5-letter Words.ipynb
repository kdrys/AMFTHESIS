{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad73c97",
   "metadata": {},
   "source": [
    "# One-Letter Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a33f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the csv files\n",
    "GTCAP = open('GTCAP.csv')\n",
    "AGI = open('AGI.csv')\n",
    "SM = open('SM.csv')\n",
    "MER = open('MER.csv')\n",
    "ALI = open('ALI.csv')\n",
    "SECB = open('SECB.csv')\n",
    "MBT = open('MBT.csv')\n",
    "TEL = open('TEL.csv')\n",
    "URC = open('URC.csv')\n",
    "PGOLD = open('PGOLD.csv')\n",
    "\n",
    "#initialize the lists\n",
    "Date_GTCAP = []\n",
    "ClosePrice_GTCAP = []\n",
    "Date_AGI = []\n",
    "ClosePrice_AGI = []\n",
    "Date_SM = []\n",
    "ClosePrice_SM = []\n",
    "Date_MER = []\n",
    "ClosePrice_MER = []\n",
    "Date_ALI = []\n",
    "ClosePrice_ALI = []\n",
    "Date_SECB = []\n",
    "ClosePrice_SECB = []\n",
    "Date_MBT = []\n",
    "ClosePrice_MBT = []\n",
    "Date_TEL = []\n",
    "ClosePrice_TEL = []\n",
    "Date_URC = []\n",
    "ClosePrice_URC = []\n",
    "Date_PGOLD = []\n",
    "ClosePrice_PGOLD = []\n",
    "\n",
    "#skip the header line\n",
    "GTCAP.readline()\n",
    "AGI.readline()\n",
    "SM.readline()\n",
    "MER.readline()\n",
    "ALI.readline()\n",
    "SECB.readline()\n",
    "MBT.readline()\n",
    "TEL.readline()\n",
    "URC.readline()\n",
    "PGOLD.readline()\n",
    "\n",
    "#go through the files line by line\n",
    "for line in GTCAP:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_GTCAP.append(sline[0])\n",
    "    ClosePrice_GTCAP.append(float(sline[1]))\n",
    "    \n",
    "for line in AGI:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_AGI.append(sline[0])\n",
    "    ClosePrice_AGI.append(float(sline[1]))\n",
    "    \n",
    "for line in SM:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_SM.append(sline[0])\n",
    "    ClosePrice_SM.append(float(sline[1]))\n",
    "    \n",
    "for line in MER:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_MER.append(sline[0])\n",
    "    ClosePrice_MER.append(float(sline[1]))\n",
    "    \n",
    "for line in ALI:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_ALI.append(sline[0])\n",
    "    ClosePrice_ALI.append(float(sline[1]))\n",
    "    \n",
    "for line in SECB:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_SECB.append(sline[0])\n",
    "    ClosePrice_SECB.append(float(sline[1]))\n",
    "    \n",
    "for line in MBT:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_MBT.append(sline[0])\n",
    "    ClosePrice_MBT.append(float(sline[1]))\n",
    "    \n",
    "for line in TEL:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_TEL.append(sline[0])\n",
    "    ClosePrice_TEL.append(float(sline[1]))\n",
    "    \n",
    "for line in URC:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_URC.append(sline[0])\n",
    "    ClosePrice_URC.append(float(sline[1]))\n",
    "        \n",
    "for line in PGOLD:\n",
    "    sline = line.strip().split(',')\n",
    "    Date_PGOLD.append(sline[0])\n",
    "    ClosePrice_PGOLD.append(float(sline[1]))\n",
    "\n",
    "\n",
    "#close files\n",
    "GTCAP.close()\n",
    "AGI.close()\n",
    "SM.close()\n",
    "MER.close()\n",
    "ALI.close()\n",
    "SECB.close()\n",
    "MBT.close()\n",
    "TEL.close()\n",
    "URC.close()\n",
    "PGOLD.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129e31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c47f9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates into datetime structure\n",
    "for n in range(len(Date_GTCAP)):\n",
    "    Date_GTCAP[n] = datetime.datetime.strptime(Date_GTCAP[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_AGI)):\n",
    "    Date_AGI[n] = datetime.datetime.strptime(Date_AGI[n], '%m/%d/%y').date()\n",
    "    \n",
    "for n in range(len(Date_SM)):\n",
    "    Date_SM[n] = datetime.datetime.strptime(Date_SM[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_MER)):\n",
    "    Date_MER[n] = datetime.datetime.strptime(Date_MER[n], '%m/%d/%y').date()\n",
    "    \n",
    "for n in range(len(Date_ALI)):\n",
    "    Date_ALI[n] = datetime.datetime.strptime(Date_ALI[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_SECB)):\n",
    "    Date_SECB[n] = datetime.datetime.strptime(Date_SECB[n], '%m/%d/%y').date()\n",
    "    \n",
    "for n in range(len(Date_MBT)):\n",
    "    Date_MBT[n] = datetime.datetime.strptime(Date_MBT[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_TEL)):\n",
    "    Date_TEL[n] = datetime.datetime.strptime(Date_TEL[n], '%m/%d/%y').date()\n",
    "    \n",
    "for n in range(len(Date_URC)):\n",
    "    Date_URC[n] = datetime.datetime.strptime(Date_URC[n], '%m/%d/%y').date()\n",
    "\n",
    "for n in range(len(Date_PGOLD)):\n",
    "    Date_PGOLD[n] = datetime.datetime.strptime(Date_PGOLD[n], '%m/%d/%y').date()\n",
    "    \n",
    "# save Date and ClosePrice\n",
    "np.save('GTCAPDate.npy', Date_GTCAP)\n",
    "np.save('GTCAPClosePrice.npy', ClosePrice_GTCAP)\n",
    "np.save('AGIDate.npy', Date_AGI)\n",
    "np.save('AGIClosePrice.npy', ClosePrice_AGI)\n",
    "np.save('SMDate.npy', Date_SM)\n",
    "np.save('SMClosePrice.npy', ClosePrice_SM)\n",
    "np.save('MERDate.npy', Date_MER)\n",
    "np.save('MERClosePrice.npy', ClosePrice_MER)\n",
    "np.save('ALIDate.npy', Date_ALI)\n",
    "np.save('ALIClosePrice.npy', ClosePrice_ALI)\n",
    "np.save('SECBDate.npy', Date_SECB)\n",
    "np.save('SECBClosePrice.npy', ClosePrice_SECB)\n",
    "np.save('MBTDate.npy', Date_MBT)\n",
    "np.save('MBTClosePrice.npy', ClosePrice_MBT)\n",
    "np.save('TELDate.npy', Date_TEL)\n",
    "np.save('TELClosePrice.npy', ClosePrice_TEL)\n",
    "np.save('URCDate.npy', Date_URC)\n",
    "np.save('URCClosePrice.npy', ClosePrice_URC)\n",
    "np.save('PGOLDDate.npy', Date_PGOLD)\n",
    "np.save('PGOLDClosePrice.npy', ClosePrice_PGOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d00fcad",
   "metadata": {},
   "source": [
    "# Five-letter Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5304aeea",
   "metadata": {},
   "source": [
    "# 106 (L) GTCAP - (Q) MER - (Z) SECB - (V) TEL - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28eb0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_106 = max(min(Date_GTCAP), min(Date_MER), min(Date_SECB), min(Date_TEL), min(Date_PGOLD))\n",
    "end_106 = min(max(Date_GTCAP), max(Date_MER), max(Date_SECB), max(Date_TEL), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "GTCAP_106_1 = Date_GTCAP.index(start_106)\n",
    "GTCAP_106_2 = Date_GTCAP.index(end_106)\n",
    "\n",
    "MER_106_1 = Date_MER.index(start_106)\n",
    "MER_106_2 = Date_MER.index(end_106)\n",
    "\n",
    "SECB_106_1 = Date_SECB.index(start_106)\n",
    "SECB_106_2 = Date_SECB.index(end_106)\n",
    "\n",
    "TEL_106_1 = Date_TEL.index(start_106)\n",
    "TEL_106_2 = Date_TEL.index(end_106)\n",
    "\n",
    "PGOLD_106_1 = Date_PGOLD.index(start_106)\n",
    "PGOLD_106_2 = Date_PGOLD.index(end_106)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "L106 = np.save('GTCAPshortPrices.npy', ClosePrice_GTCAP[GTCAP_106_1:GTCAP_106_2])\n",
    "Q106 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_106_1:MER_106_2])\n",
    "Z106 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_106_1:SECB_106_2])\n",
    "V106 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_106_1:TEL_106_2])\n",
    "W106 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_106_1:PGOLD_106_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "L106 = np.load('GTCAPshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q106 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z106 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "V106 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "W106 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa9191d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_106 = []\n",
    "st_106 = []\n",
    "n = 1\n",
    "while n < len(L106):\n",
    "    sc_106 = ''\n",
    "    if L106[n] > L106[n-1]:\n",
    "        sc_106 = sc_106 + 'L'\n",
    "    if Q106[n] > Q106[n-1]:\n",
    "        sc_106 = sc_106 + 'Q'\n",
    "    if Z106[n] > Z106[n-1]:\n",
    "        sc_106 = sc_106 + 'Z'\n",
    "    if V106[n] > V106[n-1]:\n",
    "        sc_106 = sc_106 + 'V'\n",
    "    if W106[n] > W106[n-1]:\n",
    "        sc_106 = sc_106 + 'W'\n",
    "    if len(sc_106) > 0:\n",
    "        st_106.append(sc_106)\n",
    "    else:\n",
    "        STC_106.append(st_106)\n",
    "        st_106 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_106 = STC_106.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_106 = [ st_106 for st_106 in STC_106 if len(st_106) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_106 = len(L106)\n",
    "lmax_106 = 0\n",
    "for st_106 in STC_106:\n",
    "    if len(st_106) < lmin_106:\n",
    "        lmin_106 = len(st_106)\n",
    "    if len(st_106) > lmax_106:\n",
    "        lmax_106 = len(st_106)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_106 = [ st_106 for st_106 in STC_106 if len(st_106) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_106 = []\n",
    "for n in range(len(STC5_106)):\n",
    "    tc_106 = [ u for u in STC5_106[n][0] ]\n",
    "    for k in range(1, len(STC5_106[n])):\n",
    "        tc_106 = [ u+v for u in tc_106 for v in STC5_106[n][k] ]\n",
    "    TC5_106 = TC5_106 + tc_106\n",
    "setTC5_106 = list(set(TC5_106))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_106 = [ TC5_106.count(setTC5_106[l]) for l in range(len(setTC5_106)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_106 = [ [] for l in range(len(setTC5_106)) ]\n",
    "for s in range(106):\n",
    "    STC5null_106 = [ list(st_106) for st_106 in STC5_106]\n",
    "    for st_106 in STC5null_106:\n",
    "        np.random.shuffle(st_106)\n",
    "    TC5null_106= []\n",
    "    for n in range(len(STC5null_106)):\n",
    "        tc_106 = [ u for u in STC5null_106[n][0] ]\n",
    "        for k in range(1, len(STC5null_106[n])):\n",
    "            tc_106 = [ u+v for u in tc_106 for v in STC5null_106[n][k] ]\n",
    "        TC5null_106= TC5null_106+ tc_106\n",
    "    for l in range(len(setTC5_106)):\n",
    "        if TC5null_106.count(setTC5_106[l]) > 0:\n",
    "            fTC5null_106[l].append(TC5null_106.count(setTC5_106[l]))\n",
    "        else:\n",
    "            fTC5null_106[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d45fa5ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "VQLLL\n",
      "QLVZW\n",
      "VQVZV\n",
      "VVVW\n",
      "VVWZW\n",
      "WVQZW\n",
      "QZQZ\n",
      "VQQLW\n",
      "VWLW\n",
      "ZWVZ\n",
      "VVLZW\n",
      "QVLVW\n",
      "QVZW\n",
      "QVZLW\n",
      "QQZLW\n",
      "QLLV\n",
      "QVZZW\n",
      "QVWZW\n",
      "VVQLL\n",
      "QLZZW\n",
      "QVVW\n",
      "WVLZW\n",
      "LZZW\n",
      "WZWZW\n",
      "WQVZW\n",
      "QZZLZ\n",
      "QVQZW\n",
      "LQLLZ\n",
      "VWVW\n",
      "LLVW\n",
      "ZVLLQ\n",
      "VVQZW\n",
      "QZZVW\n",
      "WVWLW\n",
      "WVZLW\n",
      "QQLLZ\n",
      "VZV\n",
      "WVQLW\n",
      "ZVQZV\n",
      "ZQLWZ\n",
      "VVZZW\n",
      "LVVQ\n",
      "WVWZW\n",
      "VVQZV\n",
      "VVZLW\n",
      "WQWLW\n",
      "VVVZW\n",
      "QZLVW\n",
      "WVZZW\n",
      "QZLLZ\n",
      "WVVZW\n",
      "QVVLW\n",
      "QVQLW\n",
      "VVLLW\n",
      "QVVQW\n",
      "WQLZW\n",
      "WZLZW\n",
      "ZVLLW\n",
      "VVVWW\n",
      "LZLZ\n",
      "QVZWW\n",
      "WVLLW\n",
      "WZWLW\n",
      "VVVLW\n",
      "WQQZW\n",
      "VVLZL\n",
      "VWQZW\n",
      "VLQLW\n",
      "VVLVW\n",
      "VVVZV\n",
      "LZVW\n",
      "VLLV\n",
      "QZVLW\n",
      "LVVW\n",
      "VVWLW\n",
      "QZZLW\n",
      "ZQLLZ\n",
      "QVQW\n",
      "VWLZW\n",
      "ZQLWQ\n",
      "QZVZW\n",
      "VVQVW\n",
      "VVQZQ\n",
      "QZZWW\n",
      "ZVVQ\n",
      "QZZZW\n",
      "QVZVW\n",
      "VVQZL\n",
      "VQLZL\n",
      "VQLLZ\n",
      "WQLLW\n",
      "QZWZ\n",
      "ZVLLZ\n",
      "QVVWW\n",
      "WZLLW\n",
      "QZLLW\n",
      "QZVWW\n",
      "QVVZW\n",
      "QQQLW\n",
      "VVQLW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_106)):\n",
    "    if sum(freq >= fTC5_106[l] for freq in fTC5null_106[l]) < 5:\n",
    "        print(setTC5_106[l], fTC5_106[l], sum(freq >= fTC5_106[l] for freq in fTC5null_106[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e068fe61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "VVWZW\n",
      "WVQZW\n",
      "ZWVZ\n",
      "VVLZW\n",
      "QVZLW\n",
      "QVZZW\n",
      "QVVW\n",
      "WVLZW\n",
      "ZVLLQ\n",
      "VVQZW\n",
      "QZZVW\n",
      "WVWLW\n",
      "WVWZW\n",
      "VVVZW\n",
      "VVLLW\n",
      "WVLLW\n",
      "WZWLW\n",
      "LVVW\n",
      "QZZZW\n",
      "QVVZW\n",
      "VVQLW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_106)):\n",
    "    if sum(freq >= fTC5_106[l] for freq in fTC5null_106[l]) < 1:\n",
    "        print(setTC5_106[l],fTC5_106[l], sum(freq >= fTC5_106[l] for freq in fTC5null_106[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa4076",
   "metadata": {},
   "source": [
    "# 107 (L) GTCAP - (Q) MER - (Z) SECB - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17aa2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_107 = max(min(Date_GTCAP), min(Date_MER), min(Date_SECB), min(Date_URC), min(Date_PGOLD))\n",
    "end_107 = min(max(Date_GTCAP), max(Date_MER), max(Date_SECB), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "GTCAP_107_1 = Date_GTCAP.index(start_107)\n",
    "GTCAP_107_2 = Date_GTCAP.index(end_107)\n",
    "\n",
    "MER_107_1 = Date_MER.index(start_107)\n",
    "MER_107_2 = Date_MER.index(end_107)\n",
    "\n",
    "SECB_107_1 = Date_SECB.index(start_107)\n",
    "SECB_107_2 = Date_SECB.index(end_107)\n",
    "\n",
    "URC_107_1 = Date_URC.index(start_107)\n",
    "URC_107_2 = Date_URC.index(end_107)\n",
    "\n",
    "PGOLD_107_1 = Date_PGOLD.index(start_107)\n",
    "PGOLD_107_2 = Date_PGOLD.index(end_107)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "L107 = np.save('GTCAPshortPrices.npy', ClosePrice_GTCAP[GTCAP_107_1:GTCAP_107_2])\n",
    "Q107 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_107_1:MER_107_2])\n",
    "Z107 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_107_1:SECB_107_2])\n",
    "ε107 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_107_1:URC_107_2])\n",
    "W107 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_107_1:PGOLD_107_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "L107 = np.load('GTCAPshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q107 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z107 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε107 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W107 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7856c060",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_107 = []\n",
    "st_107 = []\n",
    "n = 1\n",
    "while n < len(L107):\n",
    "    sc_107 = ''\n",
    "    if L107[n] > L107[n-1]:\n",
    "        sc_107 = sc_107 + 'L'\n",
    "    if Q107[n] > Q107[n-1]:\n",
    "        sc_107 = sc_107 + 'Q'\n",
    "    if Z107[n] > Z107[n-1]:\n",
    "        sc_107 = sc_107 + 'Z'\n",
    "    if ε107[n] > ε107[n-1]:\n",
    "        sc_107 = sc_107 + 'ε'\n",
    "    if W107[n] > W107[n-1]:\n",
    "        sc_107 = sc_107 + 'W'\n",
    "    if len(sc_107) > 0:\n",
    "        st_107.append(sc_107)\n",
    "    else:\n",
    "        STC_107.append(st_107)\n",
    "        st_107 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_107 = STC_107.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_107 = [ st_107 for st_107 in STC_107 if len(st_107) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_107 = len(L107)\n",
    "lmax_107 = 0\n",
    "for st_107 in STC_107:\n",
    "    if len(st_107) < lmin_107:\n",
    "        lmin_107 = len(st_107)\n",
    "    if len(st_107) > lmax_107:\n",
    "        lmax_107 = len(st_107)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_107 = [ st_107 for st_107 in STC_107 if len(st_107) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_107 = []\n",
    "for n in range(len(STC5_107)):\n",
    "    tc_107 = [ u for u in STC5_107[n][0] ]\n",
    "    for k in range(1, len(STC5_107[n])):\n",
    "        tc_107 = [ u+v for u in tc_107 for v in STC5_107[n][k] ]\n",
    "    TC5_107 = TC5_107 + tc_107\n",
    "setTC5_107 = list(set(TC5_107))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_107 = [ TC5_107.count(setTC5_107[l]) for l in range(len(setTC5_107)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_107 = [ [] for l in range(len(setTC5_107)) ]\n",
    "for s in range(107):\n",
    "    STC5null_107 = [ list(st_107) for st_107 in STC5_107]\n",
    "    for st_107 in STC5null_107:\n",
    "        np.random.shuffle(st_107)\n",
    "    TC5null_107= []\n",
    "    for n in range(len(STC5null_107)):\n",
    "        tc_107 = [ u for u in STC5null_107[n][0] ]\n",
    "        for k in range(1, len(STC5null_107[n])):\n",
    "            tc_107 = [ u+v for u in tc_107 for v in STC5null_107[n][k] ]\n",
    "        TC5null_107= TC5null_107+ tc_107\n",
    "    for l in range(len(setTC5_107)):\n",
    "        if TC5null_107.count(setTC5_107[l]) > 0:\n",
    "            fTC5null_107[l].append(TC5null_107.count(setTC5_107[l]))\n",
    "        else:\n",
    "            fTC5null_107[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aca3a267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "εQLLQ\n",
      "WLW\n",
      "ZLWLW\n",
      "LεLQ\n",
      "ZεLLZ\n",
      "QW\n",
      "LZεW\n",
      "εZεW\n",
      "LZWQ\n",
      "WQεWW\n",
      "WεQ\n",
      "QLZZW\n",
      "εQεLW\n",
      "εLεZW\n",
      "WQWZW\n",
      "WQεZW\n",
      "QLZLW\n",
      "εQεZW\n",
      "εLεW\n",
      "WLεW\n",
      "QLεZW\n",
      "LZWW\n",
      "εεLLQ\n",
      "WQεLW\n",
      "εZLLQ\n",
      "LZεWQ\n",
      "WLWZW\n",
      "ZQWLW\n",
      "WQWLW\n",
      "ZZLLZ\n",
      "QZLZ\n",
      "ZεLLQ\n",
      "ZZLLQ\n",
      "LεQQ\n",
      "εεLWQ\n",
      "εLWZW\n",
      "εQWLW\n",
      "εLεLW\n",
      "εLWLW\n",
      "LZLZ\n",
      "ZLLLW\n",
      "WQQZε\n",
      "εLεQ\n",
      "WQQZW\n",
      "LZLQ\n",
      "ZQWQQ\n",
      "εQWZW\n",
      "ZQLLZ\n",
      "WLWLW\n",
      "WLεZW\n",
      "WQQQ\n",
      "QZZZW\n",
      "εZWW\n",
      "QLLZ\n",
      "LεεQ\n",
      "εZWε\n",
      "ZQLLQ\n",
      "LLεQ\n",
      "WLZZW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_107)):\n",
    "    if sum(freq >= fTC5_107[l] for freq in fTC5null_107[l]) < 5:\n",
    "        print(setTC5_107[l], fTC5_107[l], sum(freq >= fTC5_107[l] for freq in fTC5null_107[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cebf5f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "LεLQ\n",
      "QLZZW\n",
      "WQWZW\n",
      "εQεZW\n",
      "WLWZW\n",
      "ZZLLZ\n",
      "ZZLLQ\n",
      "LZLZ\n",
      "WLWLW\n",
      "QLLZ\n",
      "LεεQ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_107)):\n",
    "    if sum(freq >= fTC5_107[l] for freq in fTC5null_107[l]) < 1:\n",
    "        print(setTC5_107[l], fTC5_107[l], sum(freq >= fTC5_107[l] for freq in fTC5null_107[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5474b859",
   "metadata": {},
   "source": [
    "# 108 (L) GTCAP - (Q) MER - (T) MBT - (V) TEL - (ε) URC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e27161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_108 = max(min(Date_GTCAP), min(Date_MER), min(Date_MBT), min(Date_TEL), min(Date_URC))\n",
    "end_108 = min(max(Date_GTCAP), max(Date_MER), max(Date_MBT), max(Date_TEL), max(Date_URC))\n",
    "\n",
    "#shorten the closing prices\n",
    "GTCAP_108_1 = Date_GTCAP.index(start_108)\n",
    "GTCAP_108_2 = Date_GTCAP.index(end_108)\n",
    "\n",
    "MER_108_1 = Date_MER.index(start_108)\n",
    "MER_108_2 = Date_MER.index(end_108)\n",
    "\n",
    "MBT_108_1 = Date_MBT.index(start_108)\n",
    "MBT_108_2 = Date_MBT.index(end_108)\n",
    "\n",
    "TEL_108_1 = Date_TEL.index(start_108)\n",
    "TEL_108_2 = Date_TEL.index(end_108)\n",
    "\n",
    "URC_108_1 = Date_URC.index(start_108)\n",
    "URC_108_2 = Date_URC.index(end_108)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "L108 = np.save('GTCAPshortPrices.npy', ClosePrice_GTCAP[GTCAP_108_1:GTCAP_108_2])\n",
    "Q108 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_108_1:MER_108_2])\n",
    "T108 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_108_1:MBT_108_2])\n",
    "V108 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_108_1:TEL_108_2])\n",
    "ε108 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_108_1:URC_108_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "L108 = np.load('GTCAPshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q108 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "T108 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V108 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε108 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58a3c1aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_108 = []\n",
    "st_108 = []\n",
    "n = 1\n",
    "while n < len(L108):\n",
    "    sc_108 = ''\n",
    "    if L108[n] > L108[n-1]:\n",
    "        sc_108 = sc_108 + 'L'\n",
    "    if Q108[n] > Q108[n-1]:\n",
    "        sc_108 = sc_108 + 'Q'\n",
    "    if T108[n] > T108[n-1]:\n",
    "        sc_108 = sc_108 + 'T'\n",
    "    if V108[n] > V108[n-1]:\n",
    "        sc_108 = sc_108 + 'V'\n",
    "    if ε108[n] > ε108[n-1]:\n",
    "        sc_108 = sc_108 + 'ε'\n",
    "    if len(sc_108) > 0:\n",
    "        st_108.append(sc_108)\n",
    "    else:\n",
    "        STC_108.append(st_108)\n",
    "        st_108 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_108 = STC_108.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_108 = [ st_108 for st_108 in STC_108 if len(st_108) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_108 = len(L108)\n",
    "lmax_108 = 0\n",
    "for st_108 in STC_108:\n",
    "    if len(st_108) < lmin_108:\n",
    "        lmin_108 = len(st_108)\n",
    "    if len(st_108) > lmax_108:\n",
    "        lmax_108 = len(st_108)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_108 = [ st_108 for st_108 in STC_108 if len(st_108) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_108 = []\n",
    "for n in range(len(STC5_108)):\n",
    "    tc_108 = [ u for u in STC5_108[n][0] ]\n",
    "    for k in range(1, len(STC5_108[n])):\n",
    "        tc_108 = [ u+v for u in tc_108 for v in STC5_108[n][k] ]\n",
    "    TC5_108 = TC5_108 + tc_108\n",
    "setTC5_108 = list(set(TC5_108))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_108 = [ TC5_108.count(setTC5_108[l]) for l in range(len(setTC5_108)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_108 = [ [] for l in range(len(setTC5_108)) ]\n",
    "for s in range(108):\n",
    "    STC5null_108 = [ list(st_108) for st_108 in STC5_108]\n",
    "    for st_108 in STC5null_108:\n",
    "        np.random.shuffle(st_108)\n",
    "    TC5null_108= []\n",
    "    for n in range(len(STC5null_108)):\n",
    "        tc_108 = [ u for u in STC5null_108[n][0] ]\n",
    "        for k in range(1, len(STC5null_108[n])):\n",
    "            tc_108 = [ u+v for u in tc_108 for v in STC5null_108[n][k] ]\n",
    "        TC5null_108= TC5null_108+ tc_108\n",
    "    for l in range(len(setTC5_108)):\n",
    "        if TC5null_108.count(setTC5_108[l]) > 0:\n",
    "            fTC5null_108[l].append(TC5null_108.count(setTC5_108[l]))\n",
    "        else:\n",
    "            fTC5null_108[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92ff4566",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "εLTLT\n",
      "εLTLV\n",
      "VLVεL\n",
      "QεLLT\n",
      "εQVTV\n",
      "QLVLT\n",
      "QQLLT\n",
      "QVVTT\n",
      "QεLεQ\n",
      "LVTLT\n",
      "QεLTT\n",
      "εQVTε\n",
      "QVVεT\n",
      "TVεLT\n",
      "TVεTT\n",
      "VLQLε\n",
      "LLLLT\n",
      "QVTQT\n",
      "LεLεT\n",
      "QVεεT\n",
      "QLLεT\n",
      "TεεTT\n",
      "VQVεL\n",
      "LVVTT\n",
      "εVTLT\n",
      "QVVLT\n",
      "LVVLT\n",
      "QVεLT\n",
      "QVVQT\n",
      "QLLLT\n",
      "QQLεT\n",
      "QQQLT\n",
      "QVεTT\n",
      "VLQLT\n",
      "εLVLT\n",
      "TVTLT\n",
      "TLQTT\n",
      "VTQL\n",
      "TVVTT\n",
      "LVTLV\n",
      "TεεεT\n",
      "LLVTT\n",
      "QLLQT\n",
      "QVQLT\n",
      "QLTLT\n",
      "LLεT\n",
      "QεεLT\n",
      "εLVTT\n",
      "LTεε\n",
      "QεLεT\n",
      "QVTTT\n",
      "εVVTT\n",
      "εVVLT\n",
      "QLεT\n",
      "QVTLT\n",
      "εVTLV\n",
      "QQεTT\n",
      "QVLεT\n",
      "QLQLT\n",
      "QεεεT\n",
      "LVTTT\n",
      "εQεTε\n",
      "TLQLT\n",
      "εQVTT\n",
      "TVTTT\n",
      "QLQT\n",
      "LLQT\n",
      "VVQV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_108)):\n",
    "    if sum(freq >= fTC5_108[l] for freq in fTC5null_108[l]) < 5:\n",
    "        print(setTC5_108[l], fTC5_108[l], sum(freq >= fTC5_108[l] for freq in fTC5null_108[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39a8f442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "LLLLT\n",
      "QVVLT\n",
      "QVεLT\n",
      "QεLεT\n",
      "εVVTT\n",
      "QVTLT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_108)):\n",
    "    if sum(freq >= fTC5_108[l] for freq in fTC5null_108[l]) < 1:\n",
    "        print(setTC5_108[l], fTC5_108[l], sum(freq >= fTC5_108[l] for freq in fTC5null_108[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe31b10",
   "metadata": {},
   "source": [
    "# 109 (L) GTCAP - (Q) MER - (T) MBT - (V) TEL - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bced236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_109 = max(min(Date_GTCAP), min(Date_MER), min(Date_MBT), min(Date_TEL), min(Date_PGOLD))\n",
    "end_109 = min(max(Date_GTCAP), max(Date_MER), max(Date_MBT), max(Date_TEL), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "GTCAP_109_1 = Date_GTCAP.index(start_109)\n",
    "GTCAP_109_2 = Date_GTCAP.index(end_109)\n",
    "\n",
    "MER_109_1 = Date_MER.index(start_109)\n",
    "MER_109_2 = Date_MER.index(end_109)\n",
    "\n",
    "MBT_109_1 = Date_MBT.index(start_109)\n",
    "MBT_109_2 = Date_MBT.index(end_109)\n",
    "\n",
    "TEL_109_1 = Date_TEL.index(start_109)\n",
    "TEL_109_2 = Date_TEL.index(end_109)\n",
    "\n",
    "PGOLD_109_1 = Date_PGOLD.index(start_109)\n",
    "PGOLD_109_2 = Date_PGOLD.index(end_109)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "L109 = np.save('GTCAPshortPrices.npy', ClosePrice_GTCAP[GTCAP_109_1:GTCAP_109_2])\n",
    "Q109 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_109_1:MER_109_2])\n",
    "T109 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_109_1:MBT_109_2])\n",
    "V109 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_109_1:TEL_109_2])\n",
    "W109 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_109_1:PGOLD_109_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "L109 = np.load('GTCAPshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q109 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "T109 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V109 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "W109 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bcdb2d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_109 = []\n",
    "st_109 = []\n",
    "n = 1\n",
    "while n < len(L109):\n",
    "    sc_109 = ''\n",
    "    if L109[n] > L109[n-1]:\n",
    "        sc_109 = sc_109 + 'L'\n",
    "    if Q109[n] > Q109[n-1]:\n",
    "        sc_109 = sc_109 + 'Q'\n",
    "    if T109[n] > T109[n-1]:\n",
    "        sc_109 = sc_109 + 'T'\n",
    "    if V109[n] > V109[n-1]:\n",
    "        sc_109 = sc_109 + 'V'\n",
    "    if W109[n] > W109[n-1]:\n",
    "        sc_109 = sc_109 + 'W'\n",
    "    if len(sc_109) > 0:\n",
    "        st_109.append(sc_109)\n",
    "    else:\n",
    "        STC_109.append(st_109)\n",
    "        st_109 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_109 = STC_109.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_109 = [ st_109 for st_109 in STC_109 if len(st_109) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_109 = len(L109)\n",
    "lmax_109 = 0\n",
    "for st_109 in STC_109:\n",
    "    if len(st_109) < lmin_109:\n",
    "        lmin_109 = len(st_109)\n",
    "    if len(st_109) > lmax_109:\n",
    "        lmax_109 = len(st_109)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_109 = [ st_109 for st_109 in STC_109 if len(st_109) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_109 = []\n",
    "for n in range(len(STC5_109)):\n",
    "    tc_109 = [ u for u in STC5_109[n][0] ]\n",
    "    for k in range(1, len(STC5_109[n])):\n",
    "        tc_109 = [ u+v for u in tc_109 for v in STC5_109[n][k] ]\n",
    "    TC5_109 = TC5_109 + tc_109\n",
    "setTC5_109 = list(set(TC5_109))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_109 = [ TC5_109.count(setTC5_109[l]) for l in range(len(setTC5_109)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_109 = [ [] for l in range(len(setTC5_109)) ]\n",
    "for s in range(109):\n",
    "    STC5null_109 = [ list(st_109) for st_109 in STC5_109]\n",
    "    for st_109 in STC5null_109:\n",
    "        np.random.shuffle(st_109)\n",
    "    TC5null_109= []\n",
    "    for n in range(len(STC5null_109)):\n",
    "        tc_109 = [ u for u in STC5null_109[n][0] ]\n",
    "        for k in range(1, len(STC5null_109[n])):\n",
    "            tc_109 = [ u+v for u in tc_109 for v in STC5null_109[n][k] ]\n",
    "        TC5null_109= TC5null_109+ tc_109\n",
    "    for l in range(len(setTC5_109)):\n",
    "        if TC5null_109.count(setTC5_109[l]) > 0:\n",
    "            fTC5null_109[l].append(TC5null_109.count(setTC5_109[l]))\n",
    "        else:\n",
    "            fTC5null_109[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adddeb3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "WVLTW\n",
      "QVLTQ\n",
      "QLVTW\n",
      "WVTLW\n",
      "QVWTW\n",
      "QLWT\n",
      "TVWW\n",
      "QVQVQ\n",
      "TLTTT\n",
      "LVTTW\n",
      "VLQTW\n",
      "TLWTT\n",
      "TVQTW\n",
      "QVTWT\n",
      "QLVLT\n",
      "QQLLT\n",
      "QQTLW\n",
      "QQQTW\n",
      "QVVTT\n",
      "WVWTW\n",
      "QQQWW\n",
      "VVWTW\n",
      "WVVWW\n",
      "WQVLW\n",
      "QVLVW\n",
      "QQLWW\n",
      "QLWQW\n",
      "QQWLW\n",
      "QVQVW\n",
      "QLVLW\n",
      "TVVQ\n",
      "WQVTW\n",
      "QVTVW\n",
      "QLWTW\n",
      "QVVW\n",
      "QLVQW\n",
      "QQWTW\n",
      "VTVT\n",
      "QVWWW\n",
      "LVLTW\n",
      "QLVWW\n",
      "TQQTW\n",
      "QTTVW\n",
      "QLTTW\n",
      "QVTQT\n",
      "QQLTW\n",
      "QVTLW\n",
      "TVWTW\n",
      "TLQTW\n",
      "QQQTT\n",
      "TQQTT\n",
      "LVWTW\n",
      "WVTTW\n",
      "QLLQW\n",
      "VVTTW\n",
      "QQWLT\n",
      "WVWLW\n",
      "QQVTT\n",
      "QVVLT\n",
      "QLLLW\n",
      "WQTTW\n",
      "VTWT\n",
      "WVQLW\n",
      "WVVLW\n",
      "WLQLW\n",
      "LVQTW\n",
      "VVTLW\n",
      "WQTLW\n",
      "QQTTW\n",
      "WVTTT\n",
      "QQVQW\n",
      "LVVQ\n",
      "WVTLT\n",
      "QVVQT\n",
      "WQWLW\n",
      "QVLLW\n",
      "QQWWW\n",
      "VLLT\n",
      "WVTWW\n",
      "LQQTT\n",
      "TVTTW\n",
      "QQQQW\n",
      "LVWW\n",
      "QLTQW\n",
      "QVTWW\n",
      "WVVTW\n",
      "QQQLT\n",
      "QVVLW\n",
      "QLQQW\n",
      "WVTLV\n",
      "QVQLW\n",
      "QTVQW\n",
      "QVQQW\n",
      "QVVQW\n",
      "VLWT\n",
      "QVLTT\n",
      "TVQTT\n",
      "VVVWW\n",
      "QQVLW\n",
      "QVTQW\n",
      "TLQTT\n",
      "LVTLW\n",
      "QLQLW\n",
      "WVLLW\n",
      "QQQVW\n",
      "VQQLL\n",
      "QQLLW\n",
      "QVQTW\n",
      "QQLTQ\n",
      "VVVLW\n",
      "VVLTW\n",
      "VLQVW\n",
      "VLQLW\n",
      "VVQTV\n",
      "WVQTW\n",
      "LLQTW\n",
      "QLLTW\n",
      "VLLV\n",
      "QLTLT\n",
      "QQLTT\n",
      "TVVW\n",
      "LVVW\n",
      "QVVTW\n",
      "TVVTW\n",
      "QVWLW\n",
      "VVQTW\n",
      "QVTTW\n",
      "QLTLW\n",
      "QLQTW\n",
      "LQQTW\n",
      "QLQWW\n",
      "QQWQW\n",
      "QLWWW\n",
      "QVWQW\n",
      "QVLWW\n",
      "QQLWT\n",
      "VVVTW\n",
      "QVTTT\n",
      "WQVTT\n",
      "QVVWT\n",
      "QTQVW\n",
      "QVTLT\n",
      "QLWLW\n",
      "QQVTW\n",
      "QQLQW\n",
      "QLQLT\n",
      "QLLWW\n",
      "WLQTW\n",
      "TVTTT\n",
      "QVLTW\n",
      "QVLLT\n",
      "QLQT\n",
      "QVVWW\n",
      "VTTT\n",
      "WVLVW\n",
      "WQQLW\n",
      "QWVWW\n",
      "TVTLW\n",
      "QQQLW\n",
      "TVVLW\n",
      "QLTWW\n",
      "VVQLW\n",
      "QVQWW\n",
      "QWTWW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_109)):\n",
    "    if sum(freq >= fTC5_109[l] for freq in fTC5null_109[l]) < 5:\n",
    "        print(setTC5_109[l], fTC5_109[l], sum(freq >= fTC5_109[l] for freq in fTC5null_109[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5499c87c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "WVTLW\n",
      "QVWTW\n",
      "LVTTW\n",
      "TVQTW\n",
      "QQLLT\n",
      "QQQTW\n",
      "QVVTT\n",
      "WVWTW\n",
      "QQQWW\n",
      "QVLVW\n",
      "QQWLW\n",
      "QLVLW\n",
      "WQVTW\n",
      "QLWTW\n",
      "QQWTW\n",
      "QVWWW\n",
      "QQLTW\n",
      "QVTLW\n",
      "WVTTW\n",
      "VVTTW\n",
      "WVWLW\n",
      "QVVLT\n",
      "WVQLW\n",
      "WVVLW\n",
      "LVQTW\n",
      "QQTTW\n",
      "QVVQT\n",
      "QVLLW\n",
      "TVTTW\n",
      "QQQQW\n",
      "QVTWW\n",
      "WVVTW\n",
      "QVVLW\n",
      "QVQLW\n",
      "QVVQW\n",
      "QQVLW\n",
      "TLQTT\n",
      "LVTLW\n",
      "QLQLW\n",
      "WVLLW\n",
      "QVQTW\n",
      "WVQTW\n",
      "LVVW\n",
      "QVVTW\n",
      "TVVTW\n",
      "QVWLW\n",
      "VVQTW\n",
      "QVTTW\n",
      "QLTLW\n",
      "QLQTW\n",
      "QQWQW\n",
      "VVVTW\n",
      "QLWLW\n",
      "QQVTW\n",
      "QVLTW\n",
      "QVVWW\n",
      "QQQLW\n",
      "VVQLW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_109)):\n",
    "    if sum(freq >= fTC5_109[l] for freq in fTC5null_109[l]) < 1:\n",
    "        print(setTC5_109[l], fTC5_109[l], sum(freq >= fTC5_109[l] for freq in fTC5null_109[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a2e80",
   "metadata": {},
   "source": [
    "# 110 (L) GTCAP - (Q) MER - (T) MBT - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0229a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_110 = max(min(Date_GTCAP), min(Date_MER), min(Date_MBT), min(Date_URC), min(Date_PGOLD))\n",
    "end_110 = min(max(Date_GTCAP), max(Date_MER), max(Date_MBT), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "GTCAP_110_1 = Date_GTCAP.index(start_110)\n",
    "GTCAP_110_2 = Date_GTCAP.index(end_110)\n",
    "\n",
    "MER_110_1 = Date_MER.index(start_110)\n",
    "MER_110_2 = Date_MER.index(end_110)\n",
    "\n",
    "MBT_110_1 = Date_MBT.index(start_110)\n",
    "MBT_110_2 = Date_MBT.index(end_110)\n",
    "\n",
    "URC_110_1 = Date_URC.index(start_110)\n",
    "URC_110_2 = Date_URC.index(end_110)\n",
    "\n",
    "PGOLD_110_1 = Date_PGOLD.index(start_110)\n",
    "PGOLD_110_2 = Date_PGOLD.index(end_110)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "L110 = np.save('GTCAPshortPrices.npy', ClosePrice_GTCAP[GTCAP_110_1:GTCAP_110_2])\n",
    "Q110 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_110_1:MER_110_2])\n",
    "T110 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_110_1:MBT_110_2])\n",
    "ε110 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_110_1:URC_110_2])\n",
    "W110 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_110_1:PGOLD_110_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "L110 = np.load('GTCAPshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q110 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "T110 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε110 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W110 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c0b133c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_110 = []\n",
    "st_110 = []\n",
    "n = 1\n",
    "while n < len(L110):\n",
    "    sc_110 = ''\n",
    "    if L110[n] > L110[n-1]:\n",
    "        sc_110 = sc_110 + 'L'\n",
    "    if Q110[n] > Q110[n-1]:\n",
    "        sc_110 = sc_110 + 'Q'\n",
    "    if T110[n] > T110[n-1]:\n",
    "        sc_110 = sc_110 + 'T'\n",
    "    if ε110[n] > ε110[n-1]:\n",
    "        sc_110 = sc_110 + 'ε'\n",
    "    if W110[n] > W110[n-1]:\n",
    "        sc_110 = sc_110 + 'W'\n",
    "    if len(sc_110) > 0:\n",
    "        st_110.append(sc_110)\n",
    "    else:\n",
    "        STC_110.append(st_110)\n",
    "        st_110 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_110 = STC_110.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_110 = [ st_110 for st_110 in STC_110 if len(st_110) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_110 = len(L110)\n",
    "lmax_110 = 0\n",
    "for st_110 in STC_110:\n",
    "    if len(st_110) < lmin_110:\n",
    "        lmin_110 = len(st_110)\n",
    "    if len(st_110) > lmax_110:\n",
    "        lmax_110 = len(st_110)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_110 = [ st_110 for st_110 in STC_110 if len(st_110) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_110 = []\n",
    "for n in range(len(STC5_110)):\n",
    "    tc_110 = [ u for u in STC5_110[n][0] ]\n",
    "    for k in range(1, len(STC5_110[n])):\n",
    "        tc_110 = [ u+v for u in tc_110 for v in STC5_110[n][k] ]\n",
    "    TC5_110 = TC5_110 + tc_110\n",
    "setTC5_110 = list(set(TC5_110))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_110 = [ TC5_110.count(setTC5_110[l]) for l in range(len(setTC5_110)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_110 = [ [] for l in range(len(setTC5_110)) ]\n",
    "for s in range(110):\n",
    "    STC5null_110 = [ list(st_110) for st_110 in STC5_110]\n",
    "    for st_110 in STC5null_110:\n",
    "        np.random.shuffle(st_110)\n",
    "    TC5null_110= []\n",
    "    for n in range(len(STC5null_110)):\n",
    "        tc_110 = [ u for u in STC5null_110[n][0] ]\n",
    "        for k in range(1, len(STC5null_110[n])):\n",
    "            tc_110 = [ u+v for u in tc_110 for v in STC5null_110[n][k] ]\n",
    "        TC5null_110= TC5null_110+ tc_110\n",
    "    for l in range(len(setTC5_110)):\n",
    "        if TC5null_110.count(setTC5_110[l]) > 0:\n",
    "            fTC5null_110[l].append(TC5null_110.count(setTC5_110[l]))\n",
    "        else:\n",
    "            fTC5null_110[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4fe8ebd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "LLQTT\n",
      "QεεWT\n",
      "QεLLT\n",
      "QLWεW\n",
      "εQTW\n",
      "QLεQW\n",
      "QQLεW\n",
      "TLWTT\n",
      "LLT\n",
      "QQLLT\n",
      "QQTLW\n",
      "QεεTW\n",
      "QQQTW\n",
      "QQQWW\n",
      "εLWW\n",
      "TLWεW\n",
      "QεLTT\n",
      "QQLWW\n",
      "QQWLW\n",
      "QLQεW\n",
      "QLQTT\n",
      "TLQεW\n",
      "TLTLT\n",
      "LLWTT\n",
      "QεεTT\n",
      "QLWTW\n",
      "QWεεT\n",
      "QεTεT\n",
      "QQWTW\n",
      "εQεLT\n",
      "QεWεW\n",
      "TQQTW\n",
      "QLTTW\n",
      "TLWLT\n",
      "QεεLW\n",
      "QQQTT\n",
      "TQQTT\n",
      "LεLWT\n",
      "QQLεε\n",
      "QQWLT\n",
      "QεTWW\n",
      "TLWTW\n",
      "WQεLW\n",
      "QLLLW\n",
      "TLεεT\n",
      "QLWTT\n",
      "QWεLT\n",
      "QεTεW\n",
      "LεεWT\n",
      "LQεLT\n",
      "QQTTW\n",
      "QQεεT\n",
      "QLLT\n",
      "LTT\n",
      "TWεεT\n",
      "QLεLW\n",
      "QQWWW\n",
      "QεTQW\n",
      "QεεQW\n",
      "QQLεT\n",
      "LQQTT\n",
      "QLTεW\n",
      "QQQQW\n",
      "TLQLW\n",
      "TWεLT\n",
      "TLTεW\n",
      "QεLWW\n",
      "εWT\n",
      "TLεLW\n",
      "εLTW\n",
      "QεT\n",
      "TLQTT\n",
      "Tε\n",
      "QLQLW\n",
      "QLεWW\n",
      "QQLLW\n",
      "QLQ\n",
      "QQLTQ\n",
      "TLεLT\n",
      "QLεTW\n",
      "QεLεW\n",
      "QεLTQ\n",
      "LLQTW\n",
      "QLLTW\n",
      "QLTLT\n",
      "QQLTT\n",
      "QεTTW\n",
      "QWεWW\n",
      "QLLεW\n",
      "WLT\n",
      "LLεT\n",
      "LεT\n",
      "QQεTW\n",
      "QQLεQ\n",
      "QQεεW\n",
      "QεεLT\n",
      "QQWεW\n",
      "QLWLT\n",
      "WLWTW\n",
      "QLTLW\n",
      "QLQTW\n",
      "QQWQW\n",
      "QQεLT\n",
      "QLWWW\n",
      "LεεεT\n",
      "QεLεT\n",
      "QQLWT\n",
      "QLεεW\n",
      "WLTTW\n",
      "TLεTT\n",
      "TLQεT\n",
      "QLεεT\n",
      "QLεT\n",
      "QQεTT\n",
      "QLWLW\n",
      "QεεεW\n",
      "QQQεW\n",
      "QεεWW\n",
      "QεTLW\n",
      "QεεTQ\n",
      "QQεLW\n",
      "QQLQW\n",
      "QLεLT\n",
      "QLQLT\n",
      "QεεεT\n",
      "QLLWW\n",
      "QεTLT\n",
      "εεT\n",
      "TLQLT\n",
      "QQQT\n",
      "TLWLW\n",
      "QLQT\n",
      "WLεTW\n",
      "WQεTW\n",
      "LLQT\n",
      "LLεQ\n",
      "TLWεT\n",
      "QQQLW\n",
      "QLTWW\n",
      "QWεWT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_110)):\n",
    "    if sum(freq >= fTC5_110[l] for freq in fTC5null_110[l]) < 5:\n",
    "        print(setTC5_110[l], fTC5_110[l], sum(freq >= fTC5_110[l] for freq in fTC5null_110[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdd675e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "TLWTT\n",
      "QQWLW\n",
      "TLTLT\n",
      "QLWTW\n",
      "QQWTW\n",
      "QεTεW\n",
      "TWεεT\n",
      "QQWWW\n",
      "TWεLT\n",
      "QLQLW\n",
      "LLεT\n",
      "QεεLT\n",
      "QQWεW\n",
      "QLTLW\n",
      "QLQTW\n",
      "QLεεW\n",
      "QLWLW\n",
      "QεεεW\n",
      "QQQεW\n",
      "QεεWW\n",
      "QεTLW\n",
      "QεεεT\n",
      "QLQT\n",
      "WLεTW\n",
      "LLQT\n",
      "QQQLW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_110)):\n",
    "    if sum(freq >= fTC5_110[l] for freq in fTC5null_110[l]) < 1:\n",
    "        print(setTC5_110[l], fTC5_110[l], sum(freq >= fTC5_110[l] for freq in fTC5null_110[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea76b8a",
   "metadata": {},
   "source": [
    "# 111 (L) GTCAP - (Q) MER - (V) TEL - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f0abdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_111 = max(min(Date_GTCAP), min(Date_MER), min(Date_TEL), min(Date_URC), min(Date_PGOLD))\n",
    "end_111 = min(max(Date_GTCAP), max(Date_MER), max(Date_TEL), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "GTCAP_111_1 = Date_GTCAP.index(start_111)\n",
    "GTCAP_111_2 = Date_GTCAP.index(end_111)\n",
    "\n",
    "MER_111_1 = Date_MER.index(start_111)\n",
    "MER_111_2 = Date_MER.index(end_111)\n",
    "\n",
    "TEL_111_1 = Date_TEL.index(start_111)\n",
    "TEL_111_2 = Date_TEL.index(end_111)\n",
    "\n",
    "URC_111_1 = Date_URC.index(start_111)\n",
    "URC_111_2 = Date_URC.index(end_111)\n",
    "\n",
    "PGOLD_111_1 = Date_PGOLD.index(start_111)\n",
    "PGOLD_111_2 = Date_PGOLD.index(end_111)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "L111 = np.save('GTCAPshortPrices.npy', ClosePrice_GTCAP[GTCAP_111_1:GTCAP_111_2])\n",
    "Q111 = np.save('MERshortPrices.npy', ClosePrice_MER[MER_111_1:MER_111_2])\n",
    "V111 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_111_1:TEL_111_2])\n",
    "ε111 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_111_1:URC_111_2])\n",
    "W111 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_111_1:PGOLD_111_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "L111 = np.load('GTCAPshortPrices.npy', allow_pickle=True).tolist()\n",
    "Q111 = np.load('MERshortPrices.npy', allow_pickle=True).tolist()\n",
    "V111 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε111 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W111 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e9ef458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_111 = []\n",
    "st_111 = []\n",
    "n = 1\n",
    "while n < len(L111):\n",
    "    sc_111 = ''\n",
    "    if L111[n] > L111[n-1]:\n",
    "        sc_111 = sc_111 + 'L'\n",
    "    if Q111[n] > Q111[n-1]:\n",
    "        sc_111 = sc_111 + 'Q'\n",
    "    if V111[n] > V111[n-1]:\n",
    "        sc_111 = sc_111 + 'V'\n",
    "    if ε111[n] > ε111[n-1]:\n",
    "        sc_111 = sc_111 + 'ε'\n",
    "    if W111[n] > W111[n-1]:\n",
    "        sc_111 = sc_111 + 'W'\n",
    "    if len(sc_111) > 0:\n",
    "        st_111.append(sc_111)\n",
    "    else:\n",
    "        STC_111.append(st_111)\n",
    "        st_111 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_111 = STC_111.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_111 = [ st_111 for st_111 in STC_111 if len(st_111) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_111 = len(L111)\n",
    "lmax_111 = 0\n",
    "for st_111 in STC_111:\n",
    "    if len(st_111) < lmin_111:\n",
    "        lmin_111 = len(st_111)\n",
    "    if len(st_111) > lmax_111:\n",
    "        lmax_111 = len(st_111)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_111 = [ st_111 for st_111 in STC_111 if len(st_111) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_111 = []\n",
    "for n in range(len(STC5_111)):\n",
    "    tc_111 = [ u for u in STC5_111[n][0] ]\n",
    "    for k in range(1, len(STC5_111[n])):\n",
    "        tc_111 = [ u+v for u in tc_111 for v in STC5_111[n][k] ]\n",
    "    TC5_111 = TC5_111 + tc_111\n",
    "setTC5_111 = list(set(TC5_111))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_111 = [ TC5_111.count(setTC5_111[l]) for l in range(len(setTC5_111)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_111 = [ [] for l in range(len(setTC5_111)) ]\n",
    "for s in range(111):\n",
    "    STC5null_111 = [ list(st_111) for st_111 in STC5_111]\n",
    "    for st_111 in STC5null_111:\n",
    "        np.random.shuffle(st_111)\n",
    "    TC5null_111= []\n",
    "    for n in range(len(STC5null_111)):\n",
    "        tc_111 = [ u for u in STC5null_111[n][0] ]\n",
    "        for k in range(1, len(STC5null_111[n])):\n",
    "            tc_111 = [ u+v for u in tc_111 for v in STC5null_111[n][k] ]\n",
    "        TC5null_111= TC5null_111+ tc_111\n",
    "    for l in range(len(setTC5_111)):\n",
    "        if TC5null_111.count(setTC5_111[l]) > 0:\n",
    "            fTC5null_111[l].append(TC5null_111.count(setTC5_111[l]))\n",
    "        else:\n",
    "            fTC5null_111[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f3b91c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "QVεQW\n",
      "QLWεW\n",
      "QεVWW\n",
      "LW\n",
      "QLεQW\n",
      "LεLQ\n",
      "WεεLW\n",
      "εQεLV\n",
      "QVεLW\n",
      "LεVW\n",
      "QQQWW\n",
      "QεQVW\n",
      "QQWLW\n",
      "WVVεW\n",
      "QLQεW\n",
      "εVLεQ\n",
      "WQεWW\n",
      "QLVLW\n",
      "LVQW\n",
      "εVWLW\n",
      "QVLLQ\n",
      "QLVQW\n",
      "WLQ\n",
      "QLVWW\n",
      "εWLW\n",
      "εVLLQ\n",
      "QεεLW\n",
      "LWLW\n",
      "QVεεW\n",
      "LLLW\n",
      "LVLLQ\n",
      "QLLQW\n",
      "VVVQε\n",
      "WVWLW\n",
      "LεVQ\n",
      "WQεLW\n",
      "WVεWW\n",
      "WVQ\n",
      "WVVLW\n",
      "WLεWW\n",
      "QLεLW\n",
      "QεεQW\n",
      "LεQQ\n",
      "QQQQW\n",
      "VQLQε\n",
      "QVVLW\n",
      "QLQQW\n",
      "QVQLW\n",
      "QLQVW\n",
      "QVQQW\n",
      "QVVQW\n",
      "QVLεW\n",
      "WVεLW\n",
      "QVεWW\n",
      "QLQLW\n",
      "QLεWW\n",
      "QQLLW\n",
      "QLQ\n",
      "εWVW\n",
      "LQεQ\n",
      "VLLV\n",
      "εVεLW\n",
      "WVεQW\n",
      "WLεLW\n",
      "QLLεW\n",
      "LVVW\n",
      "QVVεW\n",
      "WVL\n",
      "VVWLW\n",
      "LVεW\n",
      "QεVQW\n",
      "QεVεW\n",
      "QLVεW\n",
      "QVWLW\n",
      "WLWLW\n",
      "QLQWW\n",
      "QQWQW\n",
      "LεεW\n",
      "QVQεW\n",
      "QLεεW\n",
      "WVVQW\n",
      "LWQVε\n",
      "QLWLW\n",
      "QεεεW\n",
      "WεεWW\n",
      "QQQεW\n",
      "QεεWW\n",
      "QQLQW\n",
      "WεLWW\n",
      "LεεQ\n",
      "εQVLV\n",
      "εLLV\n",
      "QVVWW\n",
      "WVV\n",
      "VVLLL\n",
      "QQQLW\n",
      "εQεQ\n",
      "VVQLW\n",
      "LεLV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_111)):\n",
    "    if sum(freq >= fTC5_111[l] for freq in fTC5null_111[l]) < 5:\n",
    "        print(setTC5_111[l], fTC5_111[l], sum(freq >= fTC5_111[l] for freq in fTC5null_111[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46c0c567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "QVεQW\n",
      "QVεLW\n",
      "WVVεW\n",
      "WLQ\n",
      "QVεεW\n",
      "QLεLW\n",
      "QQQQW\n",
      "QVVLW\n",
      "QVVQW\n",
      "WVεLW\n",
      "QVεWW\n",
      "QLQ\n",
      "εVεLW\n",
      "QVVεW\n",
      "LVεW\n",
      "QLVεW\n",
      "QεεεW\n",
      "WεεWW\n",
      "QQQLW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_111)):\n",
    "    if sum(freq >= fTC5_111[l] for freq in fTC5null_111[l]) < 1:\n",
    "        print(setTC5_111[l], fTC5_111[l], sum(freq >= fTC5_111[l] for freq in fTC5null_111[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dcaf7d",
   "metadata": {},
   "source": [
    "# 112 (L) GTCAP - (E) ALI - (Z) SECB - (T) MBT - (V) TEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48136a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_112 = max(min(Date_GTCAP), min(Date_ALI), min(Date_SECB), min(Date_MBT), min(Date_TEL))\n",
    "end_112 = min(max(Date_GTCAP), max(Date_ALI), max(Date_SECB), max(Date_MBT), max(Date_TEL))\n",
    "\n",
    "#shorten the closing prices\n",
    "GTCAP_112_1 = Date_GTCAP.index(start_112)\n",
    "GTCAP_112_2 = Date_GTCAP.index(end_112)\n",
    "\n",
    "ALI_112_1 = Date_ALI.index(start_112)\n",
    "ALI_112_2 = Date_ALI.index(end_112)\n",
    "\n",
    "SECB_112_1 = Date_SECB.index(start_112)\n",
    "SECB_112_2 = Date_SECB.index(end_112)\n",
    "\n",
    "MBT_112_1 = Date_MBT.index(start_112)\n",
    "MBT_112_2 = Date_MBT.index(end_112)\n",
    "\n",
    "TEL_112_1 = Date_TEL.index(start_112)\n",
    "TEL_112_2 = Date_TEL.index(end_112)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "L112 = np.save('GTCAPshortPrices.npy', ClosePrice_GTCAP[GTCAP_112_1:GTCAP_112_2])\n",
    "E112 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_112_1:ALI_112_2])\n",
    "Z112 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_112_1:SECB_112_2])\n",
    "T112 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_112_1:MBT_112_2])\n",
    "V112 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_112_1:TEL_112_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "L112 = np.load('GTCAPshortPrices.npy', allow_pickle=True).tolist()\n",
    "E112 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z112 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T112 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V112 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37ea33de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_112 = []\n",
    "st_112 = []\n",
    "n = 1\n",
    "while n < len(L112):\n",
    "    sc_112 = ''\n",
    "    if L112[n] > L112[n-1]:\n",
    "        sc_112 = sc_112 + 'L'\n",
    "    if E112[n] > E112[n-1]:\n",
    "        sc_112 = sc_112 + 'E'\n",
    "    if Z112[n] > Z112[n-1]:\n",
    "        sc_112 = sc_112 + 'Z'\n",
    "    if T112[n] > T112[n-1]:\n",
    "        sc_112 = sc_112 + 'T'\n",
    "    if V112[n] > V112[n-1]:\n",
    "        sc_112 = sc_112 + 'V'\n",
    "    if len(sc_112) > 0:\n",
    "        st_112.append(sc_112)\n",
    "    else:\n",
    "        STC_112.append(st_112)\n",
    "        st_112 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_112 = STC_112.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_112 = [ st_112 for st_112 in STC_112 if len(st_112) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_112 = len(L112)\n",
    "lmax_112 = 0\n",
    "for st_112 in STC_112:\n",
    "    if len(st_112) < lmin_112:\n",
    "        lmin_112 = len(st_112)\n",
    "    if len(st_112) > lmax_112:\n",
    "        lmax_112 = len(st_112)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_112 = [ st_112 for st_112 in STC_112 if len(st_112) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_112 = []\n",
    "for n in range(len(STC5_112)):\n",
    "    tc_112 = [ u for u in STC5_112[n][0] ]\n",
    "    for k in range(1, len(STC5_112[n])):\n",
    "        tc_112 = [ u+v for u in tc_112 for v in STC5_112[n][k] ]\n",
    "    TC5_112 = TC5_112 + tc_112\n",
    "setTC5_112 = list(set(TC5_112))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_112 = [ TC5_112.count(setTC5_112[l]) for l in range(len(setTC5_112)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_112 = [ [] for l in range(len(setTC5_112)) ]\n",
    "for s in range(112):\n",
    "    STC5null_112 = [ list(st_112) for st_112 in STC5_112]\n",
    "    for st_112 in STC5null_112:\n",
    "        np.random.shuffle(st_112)\n",
    "    TC5null_112= []\n",
    "    for n in range(len(STC5null_112)):\n",
    "        tc_112 = [ u for u in STC5null_112[n][0] ]\n",
    "        for k in range(1, len(STC5null_112[n])):\n",
    "            tc_112 = [ u+v for u in tc_112 for v in STC5null_112[n][k] ]\n",
    "        TC5null_112= TC5null_112+ tc_112\n",
    "    for l in range(len(setTC5_112)):\n",
    "        if TC5null_112.count(setTC5_112[l]) > 0:\n",
    "            fTC5null_112[l].append(TC5null_112.count(setTC5_112[l]))\n",
    "        else:\n",
    "            fTC5null_112[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "451f6993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "ZLLTV\n",
      "LZLZE\n",
      "ZVZTV\n",
      "LTLVE\n",
      "ELLVE\n",
      "TEVE\n",
      "ELLVV\n",
      "VLL\n",
      "EVEVV\n",
      "ZVLTE\n",
      "ZVZVV\n",
      "LZLT\n",
      "ELTVL\n",
      "ZVLLE\n",
      "ELEVL\n",
      "LEEE\n",
      "ZVZLV\n",
      "ELZ\n",
      "TEEE\n",
      "ZVZZV\n",
      "TVVEV\n",
      "EVZVV\n",
      "LVLT\n",
      "LZLEE\n",
      "LVTTV\n",
      "ZVLVV\n",
      "EVVVV\n",
      "ZLLLV\n",
      "TVVEL\n",
      "ETLVE\n",
      "ZVZTT\n",
      "EVTVV\n",
      "TLL\n",
      "ZETTV\n",
      "ZVTTV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_112)):\n",
    "    if sum(freq >= fTC5_112[l] for freq in fTC5null_112[l]) < 5:\n",
    "        print(setTC5_112[l], fTC5_112[l], sum(freq >= fTC5_112[l] for freq in fTC5null_112[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3f0bf4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "ZVZTV\n",
      "EVEVV\n",
      "ZVLTE\n",
      "ZVZLV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_112)):\n",
    "    if sum(freq >= fTC5_112[l] for freq in fTC5null_112[l]) < 1:\n",
    "        print(setTC5_112[l], fTC5_112[l], sum(freq >= fTC5_112[l] for freq in fTC5null_112[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7fb08",
   "metadata": {},
   "source": [
    "# 113 (L) GTCAP - (E) ALI - (Z) SECB - (T) MBT - (ε) URC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4acbb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_113 = max(min(Date_GTCAP), min(Date_ALI), min(Date_SECB), min(Date_MBT), min(Date_URC))\n",
    "end_113 = min(max(Date_GTCAP), max(Date_ALI), max(Date_SECB), max(Date_MBT), max(Date_URC))\n",
    "\n",
    "#shorten the closing prices\n",
    "GTCAP_113_1 = Date_GTCAP.index(start_113)\n",
    "GTCAP_113_2 = Date_GTCAP.index(end_113)\n",
    "\n",
    "ALI_113_1 = Date_ALI.index(start_113)\n",
    "ALI_113_2 = Date_ALI.index(end_113)\n",
    "\n",
    "SECB_113_1 = Date_SECB.index(start_113)\n",
    "SECB_113_2 = Date_SECB.index(end_113)\n",
    "\n",
    "MBT_113_1 = Date_MBT.index(start_113)\n",
    "MBT_113_2 = Date_MBT.index(end_113)\n",
    "\n",
    "URC_113_1 = Date_URC.index(start_113)\n",
    "URC_113_2 = Date_URC.index(end_113)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "L113 = np.save('GTCAPshortPrices.npy', ClosePrice_GTCAP[GTCAP_113_1:GTCAP_113_2])\n",
    "E113 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_113_1:ALI_113_2])\n",
    "Z113 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_113_1:SECB_113_2])\n",
    "T113 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_113_1:MBT_113_2])\n",
    "ε113 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_113_1:URC_113_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "L113 = np.load('GTCAPshortPrices.npy', allow_pickle=True).tolist()\n",
    "E113 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z113 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T113 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε113 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "009b5a60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_113 = []\n",
    "st_113 = []\n",
    "n = 1\n",
    "while n < len(L113):\n",
    "    sc_113 = ''\n",
    "    if L113[n] > L113[n-1]:\n",
    "        sc_113 = sc_113 + 'L'\n",
    "    if E113[n] > E113[n-1]:\n",
    "        sc_113 = sc_113 + 'E'\n",
    "    if Z113[n] > Z113[n-1]:\n",
    "        sc_113 = sc_113 + 'Z'\n",
    "    if T113[n] > T113[n-1]:\n",
    "        sc_113 = sc_113 + 'T'\n",
    "    if ε113[n] > ε113[n-1]:\n",
    "        sc_113 = sc_113 + 'ε'\n",
    "    if len(sc_113) > 0:\n",
    "        st_113.append(sc_113)\n",
    "    else:\n",
    "        STC_113.append(st_113)\n",
    "        st_113 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_113 = STC_113.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_113 = [ st_113 for st_113 in STC_113 if len(st_113) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_113 = len(L113)\n",
    "lmax_113 = 0\n",
    "for st_113 in STC_113:\n",
    "    if len(st_113) < lmin_113:\n",
    "        lmin_113 = len(st_113)\n",
    "    if len(st_113) > lmax_113:\n",
    "        lmax_113 = len(st_113)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_113 = [ st_113 for st_113 in STC_113 if len(st_113) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_113 = []\n",
    "for n in range(len(STC5_113)):\n",
    "    tc_113 = [ u for u in STC5_113[n][0] ]\n",
    "    for k in range(1, len(STC5_113[n])):\n",
    "        tc_113 = [ u+v for u in tc_113 for v in STC5_113[n][k] ]\n",
    "    TC5_113 = TC5_113 + tc_113\n",
    "setTC5_113 = list(set(TC5_113))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_113 = [ TC5_113.count(setTC5_113[l]) for l in range(len(setTC5_113)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_113 = [ [] for l in range(len(setTC5_113)) ]\n",
    "for s in range(113):\n",
    "    STC5null_113 = [ list(st_113) for st_113 in STC5_113]\n",
    "    for st_113 in STC5null_113:\n",
    "        np.random.shuffle(st_113)\n",
    "    TC5null_113= []\n",
    "    for n in range(len(STC5null_113)):\n",
    "        tc_113 = [ u for u in STC5null_113[n][0] ]\n",
    "        for k in range(1, len(STC5null_113[n])):\n",
    "            tc_113 = [ u+v for u in tc_113 for v in STC5null_113[n][k] ]\n",
    "        TC5null_113= TC5null_113+ tc_113\n",
    "    for l in range(len(setTC5_113)):\n",
    "        if TC5null_113.count(setTC5_113[l]) > 0:\n",
    "            fTC5null_113[l].append(TC5null_113.count(setTC5_113[l]))\n",
    "        else:\n",
    "            fTC5null_113[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4cb1465e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "εLZET\n",
      "ZZεEE\n",
      "LZEZ\n",
      "LLεE\n",
      "TELTZ\n",
      "LZLT\n",
      "LELTε\n",
      "TZεTL\n",
      "ZZLEE\n",
      "LEEE\n",
      "εLZ\n",
      "TεεTε\n",
      "LTLEE\n",
      "LLLE\n",
      "ZLLTE\n",
      "LZLZ\n",
      "LLLT\n",
      "ZZεεE\n",
      "εZLεL\n",
      "TεLTε\n",
      "LZLEE\n",
      "TZεTZ\n",
      "ELLEE\n",
      "εLTE\n",
      "LTLT\n",
      "LZεEE\n",
      "ELETE\n",
      "LTEE\n",
      "ZεLTE\n",
      "εETZ\n",
      "εTZTZ\n",
      "εLLT\n",
      "ZZεTE\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_113)):\n",
    "    if sum(freq >= fTC5_113[l] for freq in fTC5null_113[l]) < 5:\n",
    "        print(setTC5_113[l], fTC5_113[l], sum(freq >= fTC5_113[l] for freq in fTC5null_113[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f341d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "ZZεEE\n",
      "LELTε\n",
      "LLLE\n",
      "TZεTZ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_113)):\n",
    "    if sum(freq >= fTC5_113[l] for freq in fTC5null_113[l]) < 1:\n",
    "        print(setTC5_113[l], fTC5_113[l], sum(freq >= fTC5_113[l] for freq in fTC5null_113[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d17f2f",
   "metadata": {},
   "source": [
    "# 114 (L) GTCAP - (E) ALI - (Z) SECB - (T) MBT - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e71e0201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_114 = max(min(Date_GTCAP), min(Date_ALI), min(Date_SECB), min(Date_MBT), min(Date_PGOLD))\n",
    "end_114 = min(max(Date_GTCAP), max(Date_ALI), max(Date_SECB), max(Date_MBT), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "GTCAP_114_1 = Date_GTCAP.index(start_114)\n",
    "GTCAP_114_2 = Date_GTCAP.index(end_114)\n",
    "\n",
    "ALI_114_1 = Date_ALI.index(start_114)\n",
    "ALI_114_2 = Date_ALI.index(end_114)\n",
    "\n",
    "SECB_114_1 = Date_SECB.index(start_114)\n",
    "SECB_114_2 = Date_SECB.index(end_114)\n",
    "\n",
    "MBT_114_1 = Date_MBT.index(start_114)\n",
    "MBT_114_2 = Date_MBT.index(end_114)\n",
    "\n",
    "PGOLD_114_1 = Date_PGOLD.index(start_114)\n",
    "PGOLD_114_2 = Date_PGOLD.index(end_114)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "L114 = np.save('GTCAPshortPrices.npy', ClosePrice_GTCAP[GTCAP_114_1:GTCAP_114_2])\n",
    "E114 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_114_1:ALI_114_2])\n",
    "Z114 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_114_1:SECB_114_2])\n",
    "T114 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_114_1:MBT_114_2])\n",
    "W114 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_114_1:PGOLD_114_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "L114 = np.load('GTCAPshortPrices.npy', allow_pickle=True).tolist()\n",
    "E114 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z114 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "T114 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "W114 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9168e69e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_114 = []\n",
    "st_114 = []\n",
    "n = 1\n",
    "while n < len(L114):\n",
    "    sc_114 = ''\n",
    "    if L114[n] > L114[n-1]:\n",
    "        sc_114 = sc_114 + 'L'\n",
    "    if E114[n] > E114[n-1]:\n",
    "        sc_114 = sc_114 + 'E'\n",
    "    if Z114[n] > Z114[n-1]:\n",
    "        sc_114 = sc_114 + 'Z'\n",
    "    if T114[n] > T114[n-1]:\n",
    "        sc_114 = sc_114 + 'T'\n",
    "    if W114[n] > W114[n-1]:\n",
    "        sc_114 = sc_114 + 'W'\n",
    "    if len(sc_114) > 0:\n",
    "        st_114.append(sc_114)\n",
    "    else:\n",
    "        STC_114.append(st_114)\n",
    "        st_114 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_114 = STC_114.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_114 = [ st_114 for st_114 in STC_114 if len(st_114) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_114 = len(L114)\n",
    "lmax_114 = 0\n",
    "for st_114 in STC_114:\n",
    "    if len(st_114) < lmin_114:\n",
    "        lmin_114 = len(st_114)\n",
    "    if len(st_114) > lmax_114:\n",
    "        lmax_114 = len(st_114)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_114 = [ st_114 for st_114 in STC_114 if len(st_114) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_114 = []\n",
    "for n in range(len(STC5_114)):\n",
    "    tc_114 = [ u for u in STC5_114[n][0] ]\n",
    "    for k in range(1, len(STC5_114[n])):\n",
    "        tc_114 = [ u+v for u in tc_114 for v in STC5_114[n][k] ]\n",
    "    TC5_114 = TC5_114 + tc_114\n",
    "setTC5_114 = list(set(TC5_114))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_114 = [ TC5_114.count(setTC5_114[l]) for l in range(len(setTC5_114)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_114 = [ [] for l in range(len(setTC5_114)) ]\n",
    "for s in range(114):\n",
    "    STC5null_114 = [ list(st_114) for st_114 in STC5_114]\n",
    "    for st_114 in STC5null_114:\n",
    "        np.random.shuffle(st_114)\n",
    "    TC5null_114= []\n",
    "    for n in range(len(STC5null_114)):\n",
    "        tc_114 = [ u for u in STC5null_114[n][0] ]\n",
    "        for k in range(1, len(STC5null_114[n])):\n",
    "            tc_114 = [ u+v for u in tc_114 for v in STC5null_114[n][k] ]\n",
    "        TC5null_114= TC5null_114+ tc_114\n",
    "    for l in range(len(setTC5_114)):\n",
    "        if TC5null_114.count(setTC5_114[l]) > 0:\n",
    "            fTC5null_114[l].append(TC5null_114.count(setTC5_114[l]))\n",
    "        else:\n",
    "            fTC5null_114[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57a26933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "LEWTW\n",
      "WEZZW\n",
      "LELEE\n",
      "WEWLW\n",
      "LELTZ\n",
      "WTLT\n",
      "LELWE\n",
      "WWWLW\n",
      "LELLZ\n",
      "TTLTZ\n",
      "WELT\n",
      "TELTZ\n",
      "WZLZ\n",
      "ZELL\n",
      "LZLTZ\n",
      "WELZ\n",
      "WZLT\n",
      "WLLE\n",
      "WWLZW\n",
      "TZLTZ\n",
      "WLELW\n",
      "WLWZW\n",
      "WLLLW\n",
      "WZELW\n",
      "TZWZZ\n",
      "WEZT\n",
      "WWLT\n",
      "WLLT\n",
      "WEEZW\n",
      "WLEZW\n",
      "WZWLW\n",
      "ZTZ\n",
      "LZLEE\n",
      "LELWZ\n",
      "WETZW\n",
      "LZEWE\n",
      "WLTLW\n",
      "WEEWE\n",
      "WEZLW\n",
      "WEWZW\n",
      "EEL\n",
      "LZLWE\n",
      "LTWTW\n",
      "LELEZ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_114)):\n",
    "    if sum(freq >= fTC5_114[l] for freq in fTC5null_114[l]) < 5:\n",
    "        print(setTC5_114[l], fTC5_114[l], sum(freq >= fTC5_114[l] for freq in fTC5null_114[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cf7e337",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "LELTZ\n",
      "WLLE\n",
      "WLLT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_114)):\n",
    "    if sum(freq >= fTC5_114[l] for freq in fTC5null_114[l]) < 1:\n",
    "        print(setTC5_114[l], fTC5_114[l], sum(freq >= fTC5_114[l] for freq in fTC5null_114[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9041dedd",
   "metadata": {},
   "source": [
    "# 115 (L) GTCAP - (E) ALI - (Z) SECB - (V) TEL - (ε) URC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "697620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_115 = max(min(Date_GTCAP), min(Date_ALI), min(Date_SECB), min(Date_TEL), min(Date_URC))\n",
    "end_115 = min(max(Date_GTCAP), max(Date_ALI), max(Date_SECB), max(Date_TEL), max(Date_URC))\n",
    "\n",
    "#shorten the closing prices\n",
    "GTCAP_115_1 = Date_GTCAP.index(start_115)\n",
    "GTCAP_115_2 = Date_GTCAP.index(end_115)\n",
    "\n",
    "ALI_115_1 = Date_ALI.index(start_115)\n",
    "ALI_115_2 = Date_ALI.index(end_115)\n",
    "\n",
    "SECB_115_1 = Date_SECB.index(start_115)\n",
    "SECB_115_2 = Date_SECB.index(end_115)\n",
    "\n",
    "TEL_115_1 = Date_TEL.index(start_115)\n",
    "TEL_115_2 = Date_TEL.index(end_115)\n",
    "\n",
    "URC_115_1 = Date_URC.index(start_115)\n",
    "URC_115_2 = Date_URC.index(end_115)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "L115 = np.save('GTCAPshortPrices.npy', ClosePrice_GTCAP[GTCAP_115_1:GTCAP_115_2])\n",
    "E115 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_115_1:ALI_115_2])\n",
    "Z115 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_115_1:SECB_115_2])\n",
    "V115 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_115_1:TEL_115_2])\n",
    "ε115 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_115_1:URC_115_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "L115 = np.load('GTCAPshortPrices.npy', allow_pickle=True).tolist()\n",
    "E115 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z115 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "V115 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε115 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec803a65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_115 = []\n",
    "st_115 = []\n",
    "n = 1\n",
    "while n < len(L115):\n",
    "    sc_115 = ''\n",
    "    if L115[n] > L115[n-1]:\n",
    "        sc_115 = sc_115 + 'L'\n",
    "    if E115[n] > E115[n-1]:\n",
    "        sc_115 = sc_115 + 'E'\n",
    "    if Z115[n] > Z115[n-1]:\n",
    "        sc_115 = sc_115 + 'Z'\n",
    "    if V115[n] > V115[n-1]:\n",
    "        sc_115 = sc_115 + 'V'\n",
    "    if ε115[n] > ε115[n-1]:\n",
    "        sc_115 = sc_115 + 'ε'\n",
    "    if len(sc_115) > 0:\n",
    "        st_115.append(sc_115)\n",
    "    else:\n",
    "        STC_115.append(st_115)\n",
    "        st_115 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_115 = STC_115.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_115 = [ st_115 for st_115 in STC_115 if len(st_115) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_115 = len(L115)\n",
    "lmax_115 = 0\n",
    "for st_115 in STC_115:\n",
    "    if len(st_115) < lmin_115:\n",
    "        lmin_115 = len(st_115)\n",
    "    if len(st_115) > lmax_115:\n",
    "        lmax_115 = len(st_115)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_115 = [ st_115 for st_115 in STC_115 if len(st_115) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_115 = []\n",
    "for n in range(len(STC5_115)):\n",
    "    tc_115 = [ u for u in STC5_115[n][0] ]\n",
    "    for k in range(1, len(STC5_115[n])):\n",
    "        tc_115 = [ u+v for u in tc_115 for v in STC5_115[n][k] ]\n",
    "    TC5_115 = TC5_115 + tc_115\n",
    "setTC5_115 = list(set(TC5_115))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_115 = [ TC5_115.count(setTC5_115[l]) for l in range(len(setTC5_115)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_115 = [ [] for l in range(len(setTC5_115)) ]\n",
    "for s in range(115):\n",
    "    STC5null_115 = [ list(st_115) for st_115 in STC5_115]\n",
    "    for st_115 in STC5null_115:\n",
    "        np.random.shuffle(st_115)\n",
    "    TC5null_115= []\n",
    "    for n in range(len(STC5null_115)):\n",
    "        tc_115 = [ u for u in STC5null_115[n][0] ]\n",
    "        for k in range(1, len(STC5null_115[n])):\n",
    "            tc_115 = [ u+v for u in tc_115 for v in STC5null_115[n][k] ]\n",
    "        TC5null_115= TC5null_115+ tc_115\n",
    "    for l in range(len(setTC5_115)):\n",
    "        if TC5null_115.count(setTC5_115[l]) > 0:\n",
    "            fTC5null_115[l].append(TC5null_115.count(setTC5_115[l]))\n",
    "        else:\n",
    "            fTC5null_115[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "634dc250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "VεLE\n",
      "εLVEV\n",
      "LLZ\n",
      "LZLZE\n",
      "εLVεZ\n",
      "LZEZE\n",
      "εLVVV\n",
      "ELLVE\n",
      "ZZεEE\n",
      "εLVVL\n",
      "εLVEL\n",
      "εVVVL\n",
      "εVVZV\n",
      "VLZEV\n",
      "εELEε\n",
      "εLZEV\n",
      "LεLEE\n",
      "εLVεL\n",
      "εEVZV\n",
      "LVVZV\n",
      "εVVEV\n",
      "εEεEε\n",
      "εZZEV\n",
      "εVVZE\n",
      "εZLLE\n",
      "εLZVZ\n",
      "εLVεε\n",
      "εZZVZ\n",
      "εZVεL\n",
      "εVVEL\n",
      "εVVZL\n",
      "εVεLE\n",
      "εVLLE\n",
      "εLZEL\n",
      "εLVEZ\n",
      "εEεEV\n",
      "εLVεV\n",
      "εLZVL\n",
      "LEεZV\n",
      "εVLZE\n",
      "εLZVV\n",
      "εVEZE\n",
      "εLVLL\n",
      "εVZEV\n",
      "εVεεL\n",
      "LZLEE\n",
      "εEεZV\n",
      "εVVVV\n",
      "εELZV\n",
      "εVεEE\n",
      "εZZVV\n",
      "ELLEE\n",
      "εVVεL\n",
      "VZZEV\n",
      "εZEVL\n",
      "εEVEV\n",
      "LZεEE\n",
      "εLEεZ\n",
      "εLεZV\n",
      "εVZZZ\n",
      "EZLVE\n",
      "ELVεL\n",
      "εVεεE\n",
      "εLEVL\n",
      "εVEZV\n",
      "εVZZV\n",
      "LLE\n",
      "εVεZV\n",
      "εEεEE\n",
      "EZVεL\n",
      "εLVZL\n",
      "VLVEV\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_115)):\n",
    "    if sum(freq >= fTC5_115[l] for freq in fTC5null_115[l]) < 5:\n",
    "        print(setTC5_115[l], fTC5_115[l], sum(freq >= fTC5_115[l] for freq in fTC5null_115[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8727fab5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "εLVEV\n",
      "LZLZE\n",
      "ELLVE\n",
      "εLVEL\n",
      "εLVεL\n",
      "εEVZV\n",
      "εVLLE\n",
      "εEεEV\n",
      "εVLZE\n",
      "εEεZV\n",
      "εVεEE\n",
      "LZεEE\n",
      "εLεZV\n",
      "ELVεL\n",
      "EZVεL\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_115)):\n",
    "    if sum(freq >= fTC5_115[l] for freq in fTC5null_115[l]) < 1:\n",
    "        print(setTC5_115[l], fTC5_115[l], sum(freq >= fTC5_115[l] for freq in fTC5null_115[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73841e0c",
   "metadata": {},
   "source": [
    "# 116 (L) GTCAP - (E) ALI - (Z) SECB - (V) TEL - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19a21a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_116 = max(min(Date_GTCAP), min(Date_ALI), min(Date_SECB), min(Date_TEL), min(Date_PGOLD))\n",
    "end_116 = min(max(Date_GTCAP), max(Date_ALI), max(Date_SECB), max(Date_TEL), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "GTCAP_116_1 = Date_GTCAP.index(start_116)\n",
    "GTCAP_116_2 = Date_GTCAP.index(end_116)\n",
    "\n",
    "ALI_116_1 = Date_ALI.index(start_116)\n",
    "ALI_116_2 = Date_ALI.index(end_116)\n",
    "\n",
    "SECB_116_1 = Date_SECB.index(start_116)\n",
    "SECB_116_2 = Date_SECB.index(end_116)\n",
    "\n",
    "TEL_116_1 = Date_TEL.index(start_116)\n",
    "TEL_116_2 = Date_TEL.index(end_116)\n",
    "\n",
    "PGOLD_116_1 = Date_PGOLD.index(start_116)\n",
    "PGOLD_116_2 = Date_PGOLD.index(end_116)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "L116 = np.save('GTCAPshortPrices.npy', ClosePrice_GTCAP[GTCAP_116_1:GTCAP_116_2])\n",
    "E116 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_116_1:ALI_116_2])\n",
    "Z116 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_116_1:SECB_116_2])\n",
    "V116 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_116_1:TEL_116_2])\n",
    "W116 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_116_1:PGOLD_116_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "L116 = np.load('GTCAPshortPrices.npy', allow_pickle=True).tolist()\n",
    "E116 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z116 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "V116 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "W116 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "850145b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_116 = []\n",
    "st_116 = []\n",
    "n = 1\n",
    "while n < len(L116):\n",
    "    sc_116 = ''\n",
    "    if L116[n] > L116[n-1]:\n",
    "        sc_116 = sc_116 + 'L'\n",
    "    if E116[n] > E116[n-1]:\n",
    "        sc_116 = sc_116 + 'E'\n",
    "    if Z116[n] > Z116[n-1]:\n",
    "        sc_116 = sc_116 + 'Z'\n",
    "    if V116[n] > V116[n-1]:\n",
    "        sc_116 = sc_116 + 'V'\n",
    "    if W116[n] > W116[n-1]:\n",
    "        sc_116 = sc_116 + 'W'\n",
    "    if len(sc_116) > 0:\n",
    "        st_116.append(sc_116)\n",
    "    else:\n",
    "        STC_116.append(st_116)\n",
    "        st_116 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_116 = STC_116.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_116 = [ st_116 for st_116 in STC_116 if len(st_116) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_116 = len(L116)\n",
    "lmax_116 = 0\n",
    "for st_116 in STC_116:\n",
    "    if len(st_116) < lmin_116:\n",
    "        lmin_116 = len(st_116)\n",
    "    if len(st_116) > lmax_116:\n",
    "        lmax_116 = len(st_116)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_116 = [ st_116 for st_116 in STC_116 if len(st_116) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_116 = []\n",
    "for n in range(len(STC5_116)):\n",
    "    tc_116 = [ u for u in STC5_116[n][0] ]\n",
    "    for k in range(1, len(STC5_116[n])):\n",
    "        tc_116 = [ u+v for u in tc_116 for v in STC5_116[n][k] ]\n",
    "    TC5_116 = TC5_116 + tc_116\n",
    "setTC5_116 = list(set(TC5_116))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_116 = [ TC5_116.count(setTC5_116[l]) for l in range(len(setTC5_116)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_116 = [ [] for l in range(len(setTC5_116)) ]\n",
    "for s in range(116):\n",
    "    STC5null_116 = [ list(st_116) for st_116 in STC5_116]\n",
    "    for st_116 in STC5null_116:\n",
    "        np.random.shuffle(st_116)\n",
    "    TC5null_116= []\n",
    "    for n in range(len(STC5null_116)):\n",
    "        tc_116 = [ u for u in STC5null_116[n][0] ]\n",
    "        for k in range(1, len(STC5null_116[n])):\n",
    "            tc_116 = [ u+v for u in tc_116 for v in STC5null_116[n][k] ]\n",
    "        TC5null_116= TC5null_116+ tc_116\n",
    "    for l in range(len(setTC5_116)):\n",
    "        if TC5null_116.count(setTC5_116[l]) > 0:\n",
    "            fTC5null_116[l].append(TC5null_116.count(setTC5_116[l]))\n",
    "        else:\n",
    "            fTC5null_116[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e74cf98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "WEELW\n",
      "ZWLZV\n",
      "LZLZE\n",
      "WEWZV\n",
      "WEZZW\n",
      "ZLLVV\n",
      "WEVZW\n",
      "ZVZ\n",
      "ELLVE\n",
      "EELVW\n",
      "WEWLW\n",
      "ELVVE\n",
      "EELVE\n",
      "ELLVV\n",
      "ZLWZV\n",
      "ZEZVV\n",
      "ZLWLV\n",
      "ZWLVV\n",
      "WVVEW\n",
      "ZEWLV\n",
      "WVELW\n",
      "VZLV\n",
      "WLLZW\n",
      "WVLZW\n",
      "WEZLV\n",
      "ZEWZV\n",
      "EVZW\n",
      "ZLZZV\n",
      "WVWLW\n",
      "WLZLW\n",
      "WLELW\n",
      "WLWZW\n",
      "VZWW\n",
      "WVWZW\n",
      "ZEZZV\n",
      "WVZZW\n",
      "WVWLV\n",
      "ZELVV\n",
      "ZEZZW\n",
      "WVELV\n",
      "EEZVW\n",
      "ZLZVV\n",
      "WEEZW\n",
      "WLEZW\n",
      "WEZZV\n",
      "WZWLW\n",
      "LZLEE\n",
      "WEEZV\n",
      "LZLVE\n",
      "VLLV\n",
      "ELLEE\n",
      "ZLZLV\n",
      "ZZLVV\n",
      "ZLLZV\n",
      "ELLZE\n",
      "WLWLW\n",
      "WVEZW\n",
      "ZLLLV\n",
      "EZLVE\n",
      "WEZLW\n",
      "WEWZW\n",
      "LZLWE\n",
      "ZEEZW\n",
      "EEWVW\n",
      "VVWEW\n",
      "WLZZW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_116)):\n",
    "    if sum(freq >= fTC5_116[l] for freq in fTC5null_116[l]) < 5:\n",
    "        print(setTC5_116[l], fTC5_116[l], sum(freq >= fTC5_116[l] for freq in fTC5null_116[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f11f3baf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "LZLZE\n",
      "WEZZW\n",
      "ELLVE\n",
      "WEZLV\n",
      "WVWLW\n",
      "WVWLV\n",
      "WEEZW\n",
      "ZLLLV\n",
      "WLZZW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_116)):\n",
    "    if sum(freq >= fTC5_116[l] for freq in fTC5null_116[l]) < 1:\n",
    "        print(setTC5_116[l], fTC5_116[l], sum(freq >= fTC5_116[l] for freq in fTC5null_116[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3735e4",
   "metadata": {},
   "source": [
    "# 117 (L) GTCAP - (E) ALI - (Z) SECB - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfd8124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_117 = max(min(Date_GTCAP), min(Date_ALI), min(Date_SECB), min(Date_URC), min(Date_PGOLD))\n",
    "end_117 = min(max(Date_GTCAP), max(Date_ALI), max(Date_SECB), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "GTCAP_117_1 = Date_GTCAP.index(start_117)\n",
    "GTCAP_117_2 = Date_GTCAP.index(end_117)\n",
    "\n",
    "ALI_117_1 = Date_ALI.index(start_117)\n",
    "ALI_117_2 = Date_ALI.index(end_117)\n",
    "\n",
    "SECB_117_1 = Date_SECB.index(start_117)\n",
    "SECB_117_2 = Date_SECB.index(end_117)\n",
    "\n",
    "URC_117_1 = Date_URC.index(start_117)\n",
    "URC_117_2 = Date_URC.index(end_117)\n",
    "\n",
    "PGOLD_117_1 = Date_PGOLD.index(start_117)\n",
    "PGOLD_117_2 = Date_PGOLD.index(end_117)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "L117 = np.save('GTCAPshortPrices.npy', ClosePrice_GTCAP[GTCAP_117_1:GTCAP_117_2])\n",
    "E117 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_117_1:ALI_117_2])\n",
    "Z117 = np.save('SECBshortPrices.npy', ClosePrice_SECB[SECB_117_1:SECB_117_2])\n",
    "ε117 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_117_1:URC_117_2])\n",
    "W117 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_117_1:PGOLD_117_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "L117 = np.load('GTCAPshortPrices.npy', allow_pickle=True).tolist()\n",
    "E117 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "Z117 = np.load('SECBshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε117 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W117 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57679c19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_117 = []\n",
    "st_117 = []\n",
    "n = 1\n",
    "while n < len(L117):\n",
    "    sc_117 = ''\n",
    "    if L117[n] > L117[n-1]:\n",
    "        sc_117 = sc_117 + 'L'\n",
    "    if E117[n] > E117[n-1]:\n",
    "        sc_117 = sc_117 + 'E'\n",
    "    if Z117[n] > Z117[n-1]:\n",
    "        sc_117 = sc_117 + 'Z'\n",
    "    if ε117[n] > ε117[n-1]:\n",
    "        sc_117 = sc_117 + 'ε'\n",
    "    if W117[n] > W117[n-1]:\n",
    "        sc_117 = sc_117 + 'W'\n",
    "    if len(sc_117) > 0:\n",
    "        st_117.append(sc_117)\n",
    "    else:\n",
    "        STC_117.append(st_117)\n",
    "        st_117 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_117 = STC_117.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_117 = [ st_117 for st_117 in STC_117 if len(st_117) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_117 = len(L117)\n",
    "lmax_117 = 0\n",
    "for st_117 in STC_117:\n",
    "    if len(st_117) < lmin_117:\n",
    "        lmin_117 = len(st_117)\n",
    "    if len(st_117) > lmax_117:\n",
    "        lmax_117 = len(st_117)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_117 = [ st_117 for st_117 in STC_117 if len(st_117) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_117 = []\n",
    "for n in range(len(STC5_117)):\n",
    "    tc_117 = [ u for u in STC5_117[n][0] ]\n",
    "    for k in range(1, len(STC5_117[n])):\n",
    "        tc_117 = [ u+v for u in tc_117 for v in STC5_117[n][k] ]\n",
    "    TC5_117 = TC5_117 + tc_117\n",
    "setTC5_117 = list(set(TC5_117))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_117 = [ TC5_117.count(setTC5_117[l]) for l in range(len(setTC5_117)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_117 = [ [] for l in range(len(setTC5_117)) ]\n",
    "for s in range(117):\n",
    "    STC5null_117 = [ list(st_117) for st_117 in STC5_117]\n",
    "    for st_117 in STC5null_117:\n",
    "        np.random.shuffle(st_117)\n",
    "    TC5null_117= []\n",
    "    for n in range(len(STC5null_117)):\n",
    "        tc_117 = [ u for u in STC5null_117[n][0] ]\n",
    "        for k in range(1, len(STC5null_117[n])):\n",
    "            tc_117 = [ u+v for u in tc_117 for v in STC5null_117[n][k] ]\n",
    "        TC5null_117= TC5null_117+ tc_117\n",
    "    for l in range(len(setTC5_117)):\n",
    "        if TC5null_117.count(setTC5_117[l]) > 0:\n",
    "            fTC5null_117[l].append(TC5null_117.count(setTC5_117[l]))\n",
    "        else:\n",
    "            fTC5null_117[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce6d3e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "LZLZE\n",
      "εEWW\n",
      "LELLZ\n",
      "εELEε\n",
      "LεLEE\n",
      "εEWLW\n",
      "εLεZW\n",
      "WLWZW\n",
      "LεZZE\n",
      "εεLE\n",
      "WEZW\n",
      "εELεE\n",
      "εεWW\n",
      "εLWZW\n",
      "εLWLW\n",
      "εELεε\n",
      "LZLEE\n",
      "εEWZW\n",
      "εEWEW\n",
      "ZLZ\n",
      "WEWZW\n",
      "εLWEW\n",
      "εEεW\n",
      "εZWW\n",
      "εELWZ\n",
      "εEεZW\n",
      "εELEE\n",
      "ZεWW\n",
      "εεZE\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_117)):\n",
    "    if sum(freq >= fTC5_117[l] for freq in fTC5null_117[l]) < 5:\n",
    "        print(setTC5_117[l], fTC5_117[l], sum(freq >= fTC5_117[l] for freq in fTC5null_117[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4eed105a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "εEWW\n",
      "εEWEW\n",
      "εLWEW\n",
      "εELWZ\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_117)):\n",
    "    if sum(freq >= fTC5_117[l] for freq in fTC5null_117[l]) < 1:\n",
    "        print(setTC5_117[l], fTC5_117[l], sum(freq >= fTC5_117[l] for freq in fTC5null_117[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4438e770",
   "metadata": {},
   "source": [
    "# 118 (L) GTCAP - (E) ALI - (T) MBT - (V) TEL - (ε) URC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b8123b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_118 = max(min(Date_GTCAP), min(Date_ALI), min(Date_MBT), min(Date_TEL), min(Date_URC))\n",
    "end_118 = min(max(Date_GTCAP), max(Date_ALI), max(Date_MBT), max(Date_TEL), max(Date_URC))\n",
    "\n",
    "#shorten the closing prices\n",
    "GTCAP_118_1 = Date_GTCAP.index(start_118)\n",
    "GTCAP_118_2 = Date_GTCAP.index(end_118)\n",
    "\n",
    "ALI_118_1 = Date_ALI.index(start_118)\n",
    "ALI_118_2 = Date_ALI.index(end_118)\n",
    "\n",
    "MBT_118_1 = Date_MBT.index(start_118)\n",
    "MBT_118_2 = Date_MBT.index(end_118)\n",
    "\n",
    "TEL_118_1 = Date_TEL.index(start_118)\n",
    "TEL_118_2 = Date_TEL.index(end_118)\n",
    "\n",
    "URC_118_1 = Date_URC.index(start_118)\n",
    "URC_118_2 = Date_URC.index(end_118)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "L118 = np.save('GTCAPshortPrices.npy', ClosePrice_GTCAP[GTCAP_118_1:GTCAP_118_2])\n",
    "E118 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_118_1:ALI_118_2])\n",
    "T118 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_118_1:MBT_118_2])\n",
    "V118 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_118_1:TEL_118_2])\n",
    "ε118 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_118_1:URC_118_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "L118 = np.load('GTCAPshortPrices.npy', allow_pickle=True).tolist()\n",
    "E118 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "T118 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V118 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε118 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2facde29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_118 = []\n",
    "st_118 = []\n",
    "n = 1\n",
    "while n < len(L118):\n",
    "    sc_118 = ''\n",
    "    if L118[n] > L118[n-1]:\n",
    "        sc_118 = sc_118 + 'L'\n",
    "    if E118[n] > E118[n-1]:\n",
    "        sc_118 = sc_118 + 'E'\n",
    "    if T118[n] > T118[n-1]:\n",
    "        sc_118 = sc_118 + 'T'\n",
    "    if V118[n] > V118[n-1]:\n",
    "        sc_118 = sc_118 + 'V'\n",
    "    if ε118[n] > ε118[n-1]:\n",
    "        sc_118 = sc_118 + 'ε'\n",
    "    if len(sc_118) > 0:\n",
    "        st_118.append(sc_118)\n",
    "    else:\n",
    "        STC_118.append(st_118)\n",
    "        st_118 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_118 = STC_118.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_118 = [ st_118 for st_118 in STC_118 if len(st_118) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_118 = len(L118)\n",
    "lmax_118 = 0\n",
    "for st_118 in STC_118:\n",
    "    if len(st_118) < lmin_118:\n",
    "        lmin_118 = len(st_118)\n",
    "    if len(st_118) > lmax_118:\n",
    "        lmax_118 = len(st_118)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_118 = [ st_118 for st_118 in STC_118 if len(st_118) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_118 = []\n",
    "for n in range(len(STC5_118)):\n",
    "    tc_118 = [ u for u in STC5_118[n][0] ]\n",
    "    for k in range(1, len(STC5_118[n])):\n",
    "        tc_118 = [ u+v for u in tc_118 for v in STC5_118[n][k] ]\n",
    "    TC5_118 = TC5_118 + tc_118\n",
    "setTC5_118 = list(set(TC5_118))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_118 = [ TC5_118.count(setTC5_118[l]) for l in range(len(setTC5_118)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_118 = [ [] for l in range(len(setTC5_118)) ]\n",
    "for s in range(118):\n",
    "    STC5null_118 = [ list(st_118) for st_118 in STC5_118]\n",
    "    for st_118 in STC5null_118:\n",
    "        np.random.shuffle(st_118)\n",
    "    TC5null_118= []\n",
    "    for n in range(len(STC5null_118)):\n",
    "        tc_118 = [ u for u in STC5null_118[n][0] ]\n",
    "        for k in range(1, len(STC5null_118[n])):\n",
    "            tc_118 = [ u+v for u in tc_118 for v in STC5null_118[n][k] ]\n",
    "        TC5null_118= TC5null_118+ tc_118\n",
    "    for l in range(len(setTC5_118)):\n",
    "        if TC5null_118.count(setTC5_118[l]) > 0:\n",
    "            fTC5null_118[l].append(TC5null_118.count(setTC5_118[l]))\n",
    "        else:\n",
    "            fTC5null_118[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d217eebe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "TVVεV\n",
      "TLεεE\n",
      "LLT\n",
      "LVεET\n",
      "TVεTE\n",
      "LLLEE\n",
      "εVT\n",
      "TLEET\n",
      "TVεEE\n",
      "TVTET\n",
      "LLLLE\n",
      "TVεLT\n",
      "LεLEE\n",
      "TVεTT\n",
      "εVεTT\n",
      "εLVεL\n",
      "TEεET\n",
      "ELεεE\n",
      "VVεT\n",
      "LLEE\n",
      "TVVEV\n",
      "VLLT\n",
      "LLLεE\n",
      "VEET\n",
      "VLVT\n",
      "LLLT\n",
      "LVLT\n",
      "LLεεE\n",
      "VEεE\n",
      "VELT\n",
      "LLET\n",
      "εVEVT\n",
      "ELLEE\n",
      "VTεT\n",
      "LLεT\n",
      "εVVεL\n",
      "LVεεE\n",
      "LVEε\n",
      "VVεE\n",
      "LVεE\n",
      "TVεET\n",
      "LεεEE\n",
      "VLεT\n",
      "LVεT\n",
      "εEεTε\n",
      "LVT\n",
      "LVεTT\n",
      "TLεTT\n",
      "εVTLV\n",
      "TVVεL\n",
      "VVLT\n",
      "VEεT\n",
      "TVεεE\n",
      "εεEVT\n",
      "TEεTT\n",
      "εVEET\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_118)):\n",
    "    if sum(freq >= fTC5_118[l] for freq in fTC5null_118[l]) < 5:\n",
    "        print(setTC5_118[l], fTC5_118[l], sum(freq >= fTC5_118[l] for freq in fTC5null_118[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25868180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "VVεT\n",
      "VLLT\n",
      "LLLT\n",
      "VTεT\n",
      "TVεεE\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_118)):\n",
    "    if sum(freq >= fTC5_118[l] for freq in fTC5null_118[l]) < 1:\n",
    "        print(setTC5_118[l], fTC5_118[l], sum(freq >= fTC5_118[l] for freq in fTC5null_118[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f470ad",
   "metadata": {},
   "source": [
    "# 119 (L) GTCAP - (E) ALI - (T) MBT - (V) TEL - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c6b98ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_119 = max(min(Date_GTCAP), min(Date_ALI), min(Date_MBT), min(Date_TEL), min(Date_PGOLD))\n",
    "end_119 = min(max(Date_GTCAP), max(Date_ALI), max(Date_MBT), max(Date_TEL), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "GTCAP_119_1 = Date_GTCAP.index(start_119)\n",
    "GTCAP_119_2 = Date_GTCAP.index(end_119)\n",
    "\n",
    "ALI_119_1 = Date_ALI.index(start_119)\n",
    "ALI_119_2 = Date_ALI.index(end_119)\n",
    "\n",
    "MBT_119_1 = Date_MBT.index(start_119)\n",
    "MBT_119_2 = Date_MBT.index(end_119)\n",
    "\n",
    "TEL_119_1 = Date_TEL.index(start_119)\n",
    "TEL_119_2 = Date_TEL.index(end_119)\n",
    "\n",
    "PGOLD_119_1 = Date_PGOLD.index(start_119)\n",
    "PGOLD_119_2 = Date_PGOLD.index(end_119)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "L119 = np.save('GTCAPshortPrices.npy', ClosePrice_GTCAP[GTCAP_119_1:GTCAP_119_2])\n",
    "E119 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_119_1:ALI_119_2])\n",
    "T119 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_119_1:MBT_119_2])\n",
    "V119 = np.save('TELshortPrices.npy', ClosePrice_TEL[TEL_119_1:TEL_119_2])\n",
    "W119 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_119_1:PGOLD_119_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "L119 = np.load('GTCAPshortPrices.npy', allow_pickle=True).tolist()\n",
    "E119 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "T119 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "V119 = np.load('TELshortPrices.npy', allow_pickle=True).tolist()\n",
    "W119 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "195bfde7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_119 = []\n",
    "st_119 = []\n",
    "n = 1\n",
    "while n < len(L119):\n",
    "    sc_119 = ''\n",
    "    if L119[n] > L119[n-1]:\n",
    "        sc_119 = sc_119 + 'L'\n",
    "    if E119[n] > E119[n-1]:\n",
    "        sc_119 = sc_119 + 'E'\n",
    "    if T119[n] > T119[n-1]:\n",
    "        sc_119 = sc_119 + 'T'\n",
    "    if V119[n] > V119[n-1]:\n",
    "        sc_119 = sc_119 + 'V'\n",
    "    if W119[n] > W119[n-1]:\n",
    "        sc_119 = sc_119 + 'W'\n",
    "    if len(sc_119) > 0:\n",
    "        st_119.append(sc_119)\n",
    "    else:\n",
    "        STC_119.append(st_119)\n",
    "        st_119 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_119 = STC_119.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_119 = [ st_119 for st_119 in STC_119 if len(st_119) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_119 = len(L119)\n",
    "lmax_119 = 0\n",
    "for st_119 in STC_119:\n",
    "    if len(st_119) < lmin_119:\n",
    "        lmin_119 = len(st_119)\n",
    "    if len(st_119) > lmax_119:\n",
    "        lmax_119 = len(st_119)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_119 = [ st_119 for st_119 in STC_119 if len(st_119) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_119 = []\n",
    "for n in range(len(STC5_119)):\n",
    "    tc_119 = [ u for u in STC5_119[n][0] ]\n",
    "    for k in range(1, len(STC5_119[n])):\n",
    "        tc_119 = [ u+v for u in tc_119 for v in STC5_119[n][k] ]\n",
    "    TC5_119 = TC5_119 + tc_119\n",
    "setTC5_119 = list(set(TC5_119))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_119 = [ TC5_119.count(setTC5_119[l]) for l in range(len(setTC5_119)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_119 = [ [] for l in range(len(setTC5_119)) ]\n",
    "for s in range(119):\n",
    "    STC5null_119 = [ list(st_119) for st_119 in STC5_119]\n",
    "    for st_119 in STC5null_119:\n",
    "        np.random.shuffle(st_119)\n",
    "    TC5null_119= []\n",
    "    for n in range(len(STC5null_119)):\n",
    "        tc_119 = [ u for u in STC5null_119[n][0] ]\n",
    "        for k in range(1, len(STC5null_119[n])):\n",
    "            tc_119 = [ u+v for u in tc_119 for v in STC5null_119[n][k] ]\n",
    "        TC5null_119= TC5null_119+ tc_119\n",
    "    for l in range(len(setTC5_119)):\n",
    "        if TC5null_119.count(setTC5_119[l]) > 0:\n",
    "            fTC5null_119[l].append(TC5null_119.count(setTC5_119[l]))\n",
    "        else:\n",
    "            fTC5null_119[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aca8d042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "LLVVE\n",
      "WEELW\n",
      "LLVEW\n",
      "EVWW\n",
      "WVTLW\n",
      "VEVT\n",
      "TLTTT\n",
      "LVTTW\n",
      "LLTTW\n",
      "WLTLV\n",
      "WVVEV\n",
      "TEWEW\n",
      "LLELT\n",
      "TELWE\n",
      "LLLEE\n",
      "LVLWE\n",
      "TVWWW\n",
      "WWWLW\n",
      "VVLE\n",
      "TLTLT\n",
      "TLEET\n",
      "LVWEW\n",
      "WEVET\n",
      "WVVEW\n",
      "TLETW\n",
      "WVELW\n",
      "WVVET\n",
      "LLTLW\n",
      "TVETW\n",
      "WLVWT\n",
      "TVWTW\n",
      "LVWTW\n",
      "LLVTW\n",
      "TEEEW\n",
      "TLVLT\n",
      "WVWLW\n",
      "VVWT\n",
      "WEVLW\n",
      "TLWTW\n",
      "LLVWE\n",
      "LVVLT\n",
      "WLELW\n",
      "VEWW\n",
      "TVLEE\n",
      "TVVEE\n",
      "WLLLW\n",
      "WVVLW\n",
      "TLVTT\n",
      "TLEWW\n",
      "WLLLV\n",
      "LEEEW\n",
      "LLTEW\n",
      "WVTLT\n",
      "WVWLV\n",
      "WLWLV\n",
      "LVLEE\n",
      "VLLT\n",
      "WLVET\n",
      "LVVEW\n",
      "WLEEW\n",
      "TLVLW\n",
      "LEVEW\n",
      "WVVTW\n",
      "WVTLV\n",
      "TVWEW\n",
      "WVELV\n",
      "TVLWE\n",
      "WLLT\n",
      "LLETT\n",
      "WLVTT\n",
      "TVEEW\n",
      "VLLLV\n",
      "WVLLW\n",
      "LVEEW\n",
      "LLEEW\n",
      "TLTTW\n",
      "WLVLT\n",
      "WLVTW\n",
      "TVEWW\n",
      "LLVLT\n",
      "WLTTT\n",
      "LLVTT\n",
      "WEVTW\n",
      "LEWEW\n",
      "WEVEW\n",
      "TVVEW\n",
      "LVEEE\n",
      "TLTET\n",
      "TLTEW\n",
      "WLTLW\n",
      "WLVLW\n",
      "LVVEE\n",
      "LLTTT\n",
      "LLVWW\n",
      "TLETT\n",
      "WEVTT\n",
      "WVVEE\n",
      "VLLE\n",
      "LLVET\n",
      "WLVEW\n",
      "VEWT\n",
      "TLVET\n",
      "LLTLT\n",
      "VWVT\n",
      "TLVEE\n",
      "TLEEW\n",
      "WVVWT\n",
      "VVLT\n",
      "WVVTT\n",
      "TLVEW\n",
      "TEVEW\n",
      "LLTEE\n",
      "TLELT\n",
      "TLVTW\n",
      "TLWEW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_119)):\n",
    "    if sum(freq >= fTC5_119[l] for freq in fTC5null_119[l]) < 5:\n",
    "        print(setTC5_119[l], fTC5_119[l], sum(freq >= fTC5_119[l] for freq in fTC5null_119[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5afc2405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "LLVEW\n",
      "WVVEW\n",
      "TLETW\n",
      "TVWTW\n",
      "WVVLW\n",
      "TLVTT\n",
      "LLTEW\n",
      "TVWEW\n",
      "WLVTT\n",
      "TVEEW\n",
      "VLLLV\n",
      "LLEEW\n",
      "WLVTW\n",
      "WEVEW\n",
      "TVVEW\n",
      "TLETT\n",
      "WEVTT\n",
      "WLVEW\n",
      "TLEEW\n",
      "TLVEW\n",
      "TLWEW\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_119)):\n",
    "    if sum(freq >= fTC5_119[l] for freq in fTC5null_119[l]) < 1:\n",
    "        print(setTC5_119[l], fTC5_119[l], sum(freq >= fTC5_119[l] for freq in fTC5null_119[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c21c8",
   "metadata": {},
   "source": [
    "# 120 (L) GTCAP - (E) ALI - (T) MBT - (ε) URC - (W) PGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1435b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the overlapping dates\n",
    "\n",
    "start_120 = max(min(Date_GTCAP), min(Date_ALI), min(Date_MBT), min(Date_URC), min(Date_PGOLD))\n",
    "end_120 = min(max(Date_GTCAP), max(Date_ALI), max(Date_MBT), max(Date_URC), max(Date_PGOLD))\n",
    "\n",
    "#shorten the closing prices\n",
    "GTCAP_120_1 = Date_GTCAP.index(start_120)\n",
    "GTCAP_120_2 = Date_GTCAP.index(end_120)\n",
    "\n",
    "ALI_120_1 = Date_ALI.index(start_120)\n",
    "ALI_120_2 = Date_ALI.index(end_120)\n",
    "\n",
    "MBT_120_1 = Date_MBT.index(start_120)\n",
    "MBT_120_2 = Date_MBT.index(end_120)\n",
    "\n",
    "URC_120_1 = Date_URC.index(start_120)\n",
    "URC_120_2 = Date_URC.index(end_120)\n",
    "\n",
    "PGOLD_120_1 = Date_PGOLD.index(start_120)\n",
    "PGOLD_120_2 = Date_PGOLD.index(end_120)\n",
    "\n",
    "#save the shortened versions of closing prices\n",
    "L120 = np.save('GTCAPshortPrices.npy', ClosePrice_GTCAP[GTCAP_120_1:GTCAP_120_2])\n",
    "E120 = np.save('ALIshortPrices.npy', ClosePrice_ALI[ALI_120_1:ALI_120_2])\n",
    "T120 = np.save('MBTshortPrices.npy', ClosePrice_MBT[MBT_120_1:MBT_120_2])\n",
    "ε120 = np.save('URCshortPrices.npy', ClosePrice_URC[URC_120_1:URC_120_2])\n",
    "W120 = np.save('PGOLDshortPrices.npy', ClosePrice_PGOLD[PGOLD_120_1:PGOLD_120_2])\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "# import prices\n",
    "L120 = np.load('GTCAPshortPrices.npy', allow_pickle=True).tolist()\n",
    "E120 = np.load('ALIshortPrices.npy', allow_pickle=True).tolist()\n",
    "T120 = np.load('MBTshortPrices.npy', allow_pickle=True).tolist()\n",
    "ε120 = np.load('URCshortPrices.npy', allow_pickle=True).tolist()\n",
    "W120 = np.load('PGOLDshortPrices.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a108d9aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract spatio-temporal sequences\n",
    "STC_120 = []\n",
    "st_120 = []\n",
    "n = 1\n",
    "while n < len(L120):\n",
    "    sc_120 = ''\n",
    "    if L120[n] > L120[n-1]:\n",
    "        sc_120 = sc_120 + 'L'\n",
    "    if E120[n] > E120[n-1]:\n",
    "        sc_120 = sc_120 + 'E'\n",
    "    if T120[n] > T120[n-1]:\n",
    "        sc_120 = sc_120 + 'T'\n",
    "    if ε120[n] > ε120[n-1]:\n",
    "        sc_120 = sc_120 + 'ε'\n",
    "    if W120[n] > W120[n-1]:\n",
    "        sc_120 = sc_120 + 'W'\n",
    "    if len(sc_120) > 0:\n",
    "        st_120.append(sc_120)\n",
    "    else:\n",
    "        STC_120.append(st_120)\n",
    "        st_120 = []\n",
    "    n = n + 1\n",
    "\n",
    "\n",
    "# record the number of empty spatio-temporal sequences\n",
    "nSTCempty_120 = STC_120.count([])\n",
    "# keep only non-empty spatio-temporal sequences\n",
    "STC_120 = [ st_120 for st_120 in STC_120 if len(st_120) > 0 ]\n",
    "\n",
    "# record the length of the longest spatio-temporal sequence\n",
    "lmin_120 = len(L120)\n",
    "lmax_120 = 0\n",
    "for st_120 in STC_120:\n",
    "    if len(st_120) < lmin_120:\n",
    "        lmin_120 = len(st_120)\n",
    "    if len(st_120) > lmax_120:\n",
    "        lmax_120 = len(st_120)\n",
    "        \n",
    "# restrict spatio-temporal sequences to length-5\n",
    "STC5_120 = [ st_120 for st_120 in STC_120 if len(st_120) <= 5 ]\n",
    "\n",
    "# unpack spatio-temporal sequences to temporal sequences\n",
    "TC5_120 = []\n",
    "for n in range(len(STC5_120)):\n",
    "    tc_120 = [ u for u in STC5_120[n][0] ]\n",
    "    for k in range(1, len(STC5_120[n])):\n",
    "        tc_120 = [ u+v for u in tc_120 for v in STC5_120[n][k] ]\n",
    "    TC5_120 = TC5_120 + tc_120\n",
    "setTC5_120 = list(set(TC5_120))\n",
    "\n",
    "# get empirical frequencies\n",
    "fTC5_120 = [ TC5_120.count(setTC5_120[l]) for l in range(len(setTC5_120)) ]\n",
    "\n",
    "# statistical testing against null model\n",
    "np.random.seed(0)\n",
    "fTC5null_120 = [ [] for l in range(len(setTC5_120)) ]\n",
    "for s in range(120):\n",
    "    STC5null_120 = [ list(st_120) for st_120 in STC5_120]\n",
    "    for st_120 in STC5null_120:\n",
    "        np.random.shuffle(st_120)\n",
    "    TC5null_120= []\n",
    "    for n in range(len(STC5null_120)):\n",
    "        tc_120 = [ u for u in STC5null_120[n][0] ]\n",
    "        for k in range(1, len(STC5null_120[n])):\n",
    "            tc_120 = [ u+v for u in tc_120 for v in STC5null_120[n][k] ]\n",
    "        TC5null_120= TC5null_120+ tc_120\n",
    "    for l in range(len(setTC5_120)):\n",
    "        if TC5null_120.count(setTC5_120[l]) > 0:\n",
    "            fTC5null_120[l].append(TC5null_120.count(setTC5_120[l]))\n",
    "        else:\n",
    "            fTC5null_120[l].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6f43fbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.05\n",
      "WLLWW\n",
      "WεWWE\n",
      "LεWWT\n",
      "WLEET\n",
      "TLEεW\n",
      "WεWEE\n",
      "TW\n",
      "LεεWE\n",
      "TLTTT\n",
      "WLεEE\n",
      "WεWεT\n",
      "LLELT\n",
      "LLLEE\n",
      "WTLT\n",
      "εEWW\n",
      "εELW\n",
      "WεWWT\n",
      "WLεεW\n",
      "TLTLT\n",
      "TLEET\n",
      "WELT\n",
      "εεεW\n",
      "WLLεT\n",
      "LEWW\n",
      "LLLLE\n",
      "WLLWE\n",
      "TLELW\n",
      "WEWW\n",
      "LεLWT\n",
      "TLTεT\n",
      "LELT\n",
      "WLTLE\n",
      "LεWWE\n",
      "LεεWT\n",
      "WLεεE\n",
      "LTT\n",
      "WLWEE\n",
      "WLεWW\n",
      "WεWET\n",
      "LLTεE\n",
      "WLEEW\n",
      "WLTET\n",
      "TWεεE\n",
      "ELTεE\n",
      "WLLWT\n",
      "WLLET\n",
      "WLTEW\n",
      "TLTεW\n",
      "WLLT\n",
      "ELT\n",
      "LLLT\n",
      "TLεLW\n",
      "WεεWE\n",
      "WεεWT\n",
      "LεεET\n",
      "WεεεE\n",
      "WLWEW\n",
      "TLTLW\n",
      "WLTTT\n",
      "TLεLT\n",
      "LLTLE\n",
      "LεLT\n",
      "WLTLT\n",
      "WLELT\n",
      "WLεLW\n",
      "εLTE\n",
      "TLTET\n",
      "WLETT\n",
      "WLTLW\n",
      "LεεEE\n",
      "WεεEE\n",
      "WεWεE\n",
      "WLWεE\n",
      "TLETT\n",
      "TEELT\n",
      "WLεET\n",
      "LεεεT\n",
      "WLLEE\n",
      "WLLLE\n",
      "εEεW\n",
      "WLLεE\n",
      "WELW\n",
      "LLTLT\n",
      "εLLT\n",
      "WLTεE\n",
      "εεT\n",
      "WLεTW\n",
      "WLεEW\n",
      "TLELT\n",
      "WLEWE\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.05\")\n",
    "\n",
    "#statistical significance testing at p < 0.05 level\n",
    "for l in range(len(setTC5_120)):\n",
    "    if sum(freq >= fTC5_120[l] for freq in fTC5null_120[l]) < 5:\n",
    "        print(setTC5_120[l], fTC5_120[l], sum(freq >= fTC5_120[l] for freq in fTC5null_120[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d63b1f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Statistically Significant Sequences at α = 0.01\n",
      "WLεEE\n",
      "TLTLT\n",
      "WLLWE\n",
      "LELT\n",
      "LLLT\n",
      "WεεWE\n",
      "LεεET\n",
      "WLWEW\n",
      "LεεEE\n",
      "WLLEE\n",
      "WLεEW\n",
      "TLELT\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Statistically Significant Sequences at α = 0.01\")\n",
    "\n",
    "#statistical significance testing at p < 0.01 level\n",
    "for l in range(len(setTC5_120)):\n",
    "    if sum(freq >= fTC5_120[l] for freq in fTC5null_120[l]) < 1:\n",
    "        print(setTC5_120[l], fTC5_120[l], sum(freq >= fTC5_120[l] for freq in fTC5null_120[l]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
